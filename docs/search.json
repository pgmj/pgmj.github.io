[
  {
    "objectID": "raschrvignette/RaschRvign.html",
    "href": "raschrvignette/RaschRvign.html",
    "title": "RISEkbmRasch vignette",
    "section": "",
    "text": "This is an introduction to using the RISEkbmRasch R package. A changelog for package updates is available here.\nDetails on package installation are available at the package GitHub page.\nIf you are new to Rasch Measurement Theory, you may find this intro presentation useful: https://pgmj.github.io/RaschIRTlecture/slides.html\nThis vignette will walk through a sample analysis using an open dataset with polytomous questionnaire data. This will include some data wrangling to structure the item data and itemlabels, then provide examples of the different functions. The full source code of this document can be found either in this repository or by clicking on &lt;/&gt; CODE at the top of this page. You should be able to use the source code “as is” and reproduce this document locally, as long as you have the required packages installed. This page and this website are built using the open source publishing tool Quarto.\nOne of the aims with this package is to simplify reproducible psychometric analysis to shed light on the measurement properties of a scale, questionnaire or test. In a paper recently made available as a preprint (Johansson et al., 2023), our research group propose that the basic aspects of a psychometric analysis should include information about:\nWe’ll include several ways to investigate these measurement properties, using Rasch Measurement Theory. There are also functions in the package less directly related to the criteria above, that will be demonstrated in this vignette.\nPlease note that this is just a sample analysis to showcase the R package. It is not intended as a “best practice” psychometric analysis example.\nYou can skip ahead to the Rasch analysis part in Section 3 if you are eager to look at the package output :)\nThere is a separate GitHub repository containing a suggested template to simplify using the RISEkbmRasch package when conducting a reproducible Rasch analysis in R: https://github.com/pgmj/RISEraschTemplate"
  },
  {
    "objectID": "raschrvignette/RaschRvign.html#getting-started",
    "href": "raschrvignette/RaschRvign.html#getting-started",
    "title": "RISEkbmRasch vignette",
    "section": "\n1 Getting started",
    "text": "1 Getting started\nSince the package is intended for use with Quarto, this vignette has also been created with Quarto. A “template” .qmd file is available that can be useful to have handy for copy&paste when running a new analysis. You can also download a complete copy of the Quarto/R code to produce this document here.\nLoading the RISEkbmRasch package will automatically load all the packages it depends on. However, it could be desirable to explicitly load all packages used, to simplify the automatic creation of citations for them, using the grateful package (see Section 12).\n\nCodelibrary(RISEkbmRasch) # devtools::install_github(\"pgmj/RISEkbmRasch\")\nlibrary(grateful)\nlibrary(ggrepel)\nlibrary(car)\nlibrary(kableExtra)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(eRm)\nlibrary(mirt)\nlibrary(psych)\nlibrary(ggplot2)\nlibrary(psychotree)\nlibrary(matrixStats)\nlibrary(reshape)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(formattable) \nlibrary(glue)\nlibrary(foreach)\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuarto automatically adds links to R packages and functions throughout this document. However, this feature only works properly for packages available on CRAN. Since the RISEkbmRasch package is not on CRAN the links related to functions starting with RI will not work.\n\n\n\n1.1 Loading data\nWe will use data from a recent paper investigating the “initial elevation effect” (Anvari et al., 2022), and focus on the 10 negative items from the PANAS. The data is available at the OSF website.\n\nCodedf.all &lt;- read_csv(\"https://osf.io/download/6fbr5/\")\n# if you have issues with the link, please try downloading manually using the same URL as above\n# and read the file from your local drive.\n\n# subset items and demographic variables\ndf &lt;- df.all %&gt;% \n  select(starts_with(\"PANASD2_1\"),\n         starts_with(\"PANASD2_20\"),\n         age,Sex,Group) %&gt;% \n  select(!PANASD2_10_Active) %&gt;% \n  select(!PANASD2_1_Attentive)\n\n\nThe glimpse() function provides a quick overview of our dataframe.\n\nCodeglimpse(df)\n\nRows: 1,856\nColumns: 13\n$ PANASD2_11_Distressed &lt;dbl&gt; 2, 2, 2, 1, 2, 2, 4, 1, 1, 3, 1, 4, 2, 4, 4, 1, …\n$ PANASD2_12_Upset      &lt;dbl&gt; 1, 1, 4, 1, 1, 5, 2, 1, 2, 2, 2, 3, 1, 3, 5, 1, …\n$ PANASD2_13_Hostile    &lt;dbl&gt; 1, 1, 2, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, …\n$ PANASD2_14_Irritable  &lt;dbl&gt; 1, 1, 3, 1, 2, 5, 3, 1, 2, 4, 2, 3, 1, 2, 3, 1, …\n$ PANASD2_15_Scared     &lt;dbl&gt; 1, 1, 3, 1, 1, 4, 1, 1, 1, 2, 2, 2, 1, 4, 4, 1, …\n$ PANASD2_16_Afraid     &lt;dbl&gt; 1, 1, 4, 1, 1, 3, 1, 1, 1, 3, 1, 2, 1, 4, 4, 1, …\n$ PANASD2_17_Ashamed    &lt;dbl&gt; 1, 1, 2, 1, 1, 3, 1, 1, 1, 2, 1, 4, 1, 1, 3, 1, …\n$ PANASD2_18_Guilty     &lt;dbl&gt; 2, 1, 2, 1, 1, 3, 3, 1, 1, 3, 1, 4, 1, 1, 3, 1, …\n$ PANASD2_19_Nervous    &lt;dbl&gt; 1, 1, 2, 1, 2, 4, 4, 1, 1, 4, 2, 4, 2, 1, 5, 1, …\n$ PANASD2_20_Jittery    &lt;dbl&gt; 1, 2, 3, 1, 1, 2, 3, 3, 2, 1, 2, 2, 1, 1, 4, 1, …\n$ age                   &lt;dbl&gt; 27, 32, 21, 27, 20, 22, 23, 25, 21, 26, 38, 36, …\n$ Sex                   &lt;chr&gt; \"Male\", \"Male\", \"Female\", \"Male\", \"Male\", \"Male\"…\n$ Group                 &lt;chr&gt; \"Later Start\", \"Later Start\", \"Later Start\", \"La…\n\n\nWe have 1856 rows, ie. respondents. All variables except Sex and Group are of class dbl, which means they are numeric and can have decimals. Integer (numeric with no decimals) would also be fine for our purposes. The two demographic variables currently of class chr (character) will need to be converted to factors (fct), and we will do that later on.\n(If you import a dataset where item variables are of class character, you will need to recode to numeric.)\n\n1.2 Itemlabels\nThen we set up the itemlabels dataframe. This could also be done using the free LibreOffice Calc or MS Excel. Just make sure the file has the same structure, with two variables named itemnr and item that contain the item variable names and item description. The item variable names have to match the variable names in the item dataframe.\n\nCodeitemlabels &lt;- df %&gt;% \n  select(starts_with(\"PAN\")) %&gt;% \n  names() %&gt;% \n  as_tibble() %&gt;% \n  separate(value, c(NA, \"item\"), sep =\"_[0-9][0-9]_\") %&gt;% \n  mutate(itemnr = paste0(\"PANAS_\",c(11:20)), .before = \"item\")\n\n\nThe itemlabels dataframe looks like this.\n\nCodeitemlabels\n\n# A tibble: 10 × 2\n   itemnr   item      \n   &lt;chr&gt;    &lt;chr&gt;     \n 1 PANAS_11 Distressed\n 2 PANAS_12 Upset     \n 3 PANAS_13 Hostile   \n 4 PANAS_14 Irritable \n 5 PANAS_15 Scared    \n 6 PANAS_16 Afraid    \n 7 PANAS_17 Ashamed   \n 8 PANAS_18 Guilty    \n 9 PANAS_19 Nervous   \n10 PANAS_20 Jittery   \n\n\n\n1.3 Demographics\nVariables for invariance tests such as Differential Item Functioning (DIF) need to be separated into vectors (ideally as factors with specified levels and labels) with the same length as the number of rows in the dataset. This means that any kind of removal of respondents/rows with missing data needs to be done before separating the DIF variables.\nWe need to check how the Sex variable has been coded and which responses are present in the data.\n\nCodetable(df$Sex)\n\n\n  CONSENT REVOKED      DATA EXPIRED            Female              Male \n                2                 1               896               955 \nPrefer not to say \n                2 \n\n\nSince there are only 5 respondents using labels outside of Female/Male (too few for meaningful statistical analysis), we will remove them to have a complete dataset for all variables in this example.\n\nCodedf &lt;- df %&gt;% \n  filter(Sex %in% c(\"Female\",\"Male\"))\n\n\nLet’s make the variable a factor (instead of class “character”) and put in in a vector separate from the item dataframe.\n\nCodedif.sex &lt;- factor(df$Sex)\n\n\nAnd remove our DIF demographic variable from the item dataset.\n\nCodedf$Sex &lt;- NULL\n\n\nWe can now make use of a very simple function included in this package!\n\nCodeRIdemographics(dif.sex, \"Sex\")\n\n\n\n Sex \n    n \n    Percent \n  \n\n\n Female \n    896 \n    48.4 \n  \n\n Male \n    955 \n    51.6 \n  \n\n\n\n\nLet’s move on to the age variable.\n\nCodeglimpse(df$age)\n\n num [1:1851] 27 32 21 27 20 22 23 25 21 26 ...\n\n\nSometimes age is provided in categories, but here we have a numeric variable with age in years. Let’s have a quick look at the age distribution using a histogram, and calculate mean, sd and range.\n\nCode### simpler version of the ggplot below using base R function hist()\n# hist(df$age, col = \"#009ca6\")\n# abline(v = mean(age, na.rm = TRUE))\n# \n# df %&gt;% \n#   summarise(Mean = round(mean(age, na.rm = T),1),\n#             StDev = round(sd(age, na.rm = T),1)\n#             )\n\nggplot(df) +\n  geom_histogram(aes(x = age), \n                 fill = \"#009ca6\",\n                 col = \"black\") +\n  # add the average as a vertical line\n  geom_vline(xintercept = mean(df$age), \n             linewidth = 1.5,\n             linetype = 2,\n             col = \"orange\") +\n  # add a light grey field indicating the standard deviation\n  annotate(\"rect\", ymin = 0, ymax = Inf, \n           xmin = (mean(df$age, na.rm = TRUE) - sd(df$age, na.rm = TRUE)), xmax = (mean(df$age, na.rm = TRUE) + sd(df$age, na.rm = TRUE)), \n           alpha = .2) +\n  labs(title = \"\",\n       x = \"Age in years\",\n       y = \"Number of respondents\",\n       caption = glue(\"Note. Mean age is {round(mean(df$age, na.rm = T),1)} years with a standard deviation of {round(sd(df$age, na.rm = T),1)}. Age range is {min(df$age)} to {max(df$age)}.\")\n       ) +\n  theme(plot.caption = element_text(hjust = 0, face = \"italic\"))\n\n\n\n\n\n\n\nAge also needs to be a separate vector, and removed from the item dataframe.\n\nCodedif.age &lt;- df$age\ndf$age &lt;- NULL\n\n\nThere is also a grouping variable which needs to be converted to a factor.\n\nCodedif.group &lt;- factor(df$Group)\ndf$Group &lt;- NULL\nRIdemographics(dif.group, \"Group\")\n\n\n\n Group \n    n \n    Percent \n  \n\n\n Earlier Start \n    901 \n    48.7 \n  \n\n Later Start \n    950 \n    51.3 \n  \n\n\n\n\nWith only item data remaining in the dataframe, we can easily rename the items in the item dataframe. These names match the itemlabels variable itemnr.\n\nCodenames(df) &lt;- itemlabels$itemnr\n\n\nNow we are all set for the psychometric analysis!"
  },
  {
    "objectID": "raschrvignette/RaschRvign.html#descriptives",
    "href": "raschrvignette/RaschRvign.html#descriptives",
    "title": "RISEkbmRasch vignette",
    "section": "\n2 Descriptives",
    "text": "2 Descriptives\nLet’s familiarize ourselves with the data before diving into the analysis.\n\n2.1 Missing data\nFirst, we visualize the proportion of missing data on item level.\n\nCodeRImissing(df)\n\n\n\n\n\n\n\nNo missing data in this dataset. If we had missing data, we could also use RImissingP() to look at which respondents have missing data and how much.\n\n2.2 Overall responses\nThis provides us with an overall picture of the data distribution. As a bonus, any oddities/mistakes in recoding the item data from categories to numbers will be clearly visible.\n\nCodeRIallresp(df)\n\n\n\n\nResponse category\n\n\nNumber of responses\n\n\nPercent\n\n\n\n\n\n1\n\n\n9430\n\n\n50.9\n\n\n\n\n2\n\n\n4136\n\n\n22.3\n\n\n\n\n3\n\n\n2676\n\n\n14.5\n\n\n\n\n4\n\n\n1722\n\n\n9.3\n\n\n\n\n5\n\n\n546\n\n\n2.9\n\n\n\n\n\n\nMost R packages for Rasch analysis require the lowest response category to be zero, which makes it necessary for us to recode our data, from using the range of 1-5 to 0-4.\n\nCodedf &lt;- df %&gt;% \n  mutate(across(everything(), ~ car::recode(.x, \"1=0;2=1;3=2;4=3;5=4\", as.factor = F)))\n\n# always check that your recoding worked as intended.\nRIallresp(df)\n\n\n\n\nResponse category\n\n\nNumber of responses\n\n\nPercent\n\n\n\n\n\n0\n\n\n9430\n\n\n50.9\n\n\n\n\n1\n\n\n4136\n\n\n22.3\n\n\n\n\n2\n\n\n2676\n\n\n14.5\n\n\n\n\n3\n\n\n1722\n\n\n9.3\n\n\n\n\n4\n\n\n546\n\n\n2.9\n\n\n\n\n\n\n\n2.2.1 Floor/ceiling effects\nNow, we can also look at the raw distribution of sum scores. The RIrawdist() function is a bit crude, since it requires responses in all response categories to accurately calculate max and min scores.\n\nCodeRIrawdist(df)\n\n\n\n\n\n\n\nWe can see a floor effect with 11.8% of participants responding in the lowest category for all items.\n\n2.2.2 Guttman structure\nWhile not really necessary, it could be interesting to see whether the response patterns follow a Guttman-like structure. Items and persons are sorted based on lower-&gt;higher responses, and we should see the color move from yellow in the lower left corner to blue in the upper right corner.\n\nCodeRIheatmap(df) +\n  theme(axis.text.x = element_blank())\n\n\n\n\n\n\n\nIn this data, we see the floor effect on the left, with 11.8% of respondents all yellow, and a rather weak Guttman structure. This could also be due to a low variation in item locations/difficulties. Since we have a very large sample I added a theme() option to remove the x-axis text, which would anyway just be a blur of the 1851 respondent row numbers. Each thin vertical slice in the figure is one respondent.\n\n2.3 Item level descriptives\nThere are many ways to look at the item level data, and we’ll get them all together in the tab-panel below. The RItileplot() is probably most informative, since it provides the number of responses in each response category for each item. It is usually recommended to have at least ~10 responses in each category for psychometric analysis, no matter which methodology is used.\nKudos to Solomon Kurz for providing the idea and code on which the tile plot function is built!\nMost people will be familiar with the barplot, and this is probably most intuitive to understand the response distribution within each item. However, if there are many items it will take a while to review, and does not provide the same overview as a tileplot or stacked bars.\n\nCode```{r}\n#| column: margin\n#| code-fold: true\n\n# This code chunk creates a small table in the margin beside the panel-tabset output below, showing all items currently in the df dataframe.\n# The Quarto code chunk option \"#| column: margin\" is necessary for the layout to work as intended.\nRIlistItemsMargin(df, fontsize = 13)\n```\n\n\n\n\n\nitemnr\n\n\nitem\n\n\n\n\n\nPANAS_11\n\n\nDistressed\n\n\n\n\nPANAS_12\n\n\nUpset\n\n\n\n\nPANAS_13\n\n\nHostile\n\n\n\n\nPANAS_14\n\n\nIrritable\n\n\n\n\nPANAS_15\n\n\nScared\n\n\n\n\nPANAS_16\n\n\nAfraid\n\n\n\n\nPANAS_17\n\n\nAshamed\n\n\n\n\nPANAS_18\n\n\nGuilty\n\n\n\n\nPANAS_19\n\n\nNervous\n\n\n\n\nPANAS_20\n\n\nJittery\n\n\n\n\n\n\n\n\nTile plot\nStacked bars\nBarplots\n\n\n\n\nCodeRItileplot(df)\n\n\n\n\n\n\n\nWhile response patterns are skewed for all items, there are more than 10 responses in each category for all items which is helpful for the analysis.\n\n\n\nCodeRIbarstack(df) +\n  theme_minimal() + # theming is optional, see section 11 for more on this\n  theme_rise() \n\n\n\n\n\n\n\n\n\nCodeRIbarplot(df)"
  },
  {
    "objectID": "raschrvignette/RaschRvign.html#sec-rasch",
    "href": "raschrvignette/RaschRvign.html#sec-rasch",
    "title": "RISEkbmRasch vignette",
    "section": "\n3 Rasch analysis 1",
    "text": "3 Rasch analysis 1\nThe eRm package and Conditional Maximum Likelihood (CML) estimation will be used primarily, with the Partial Credit Model since this is polytomous data.\nThis is also where the five basic psychometric aspects are good to recall.\n\nUnidimensionality\nResponse categories\nInvariance\nTargeting\nMeasurement uncertainties (reliability)\n\nWe will begin by looking at unidimensionality, response categories, and targeting in parallel below. For unidimensionality, we are mostly interested in item fit and residual correlations, as well as PCA of residuals and loadings on the first residual contrast. At the same time, disordered response categories can influence item fit, and targeting can be useful if it is necessary to remove items due to residual correlations.\nWhen unidimensionality and response categories are found to work adequately, we will move on to invariance testing (Differential Item Functioning, DIF). It should be noted that DIF should be evaluated in parallel with all other psychometric aspects, but since it is rather complex it is kept in a separate section in this vignette (as is person fit). Finally, when/if invariance also looks acceptable, we can investigate reliability/measurement uncertainties.\n\n\n\n\n\n\nNote\n\n\n\nIn the tabset-panel below, each tab contains explanatory text, which is sometimes a bit lengthy. Remember to scroll back up and click on all tabs.\n\n\n\n\n\n\n\n\nitemnr\n\n\nitem\n\n\n\n\n\nPANAS_11\n\n\nDistressed\n\n\n\n\nPANAS_12\n\n\nUpset\n\n\n\n\nPANAS_13\n\n\nHostile\n\n\n\n\nPANAS_14\n\n\nIrritable\n\n\n\n\nPANAS_15\n\n\nScared\n\n\n\n\nPANAS_16\n\n\nAfraid\n\n\n\n\nPANAS_17\n\n\nAshamed\n\n\n\n\nPANAS_18\n\n\nGuilty\n\n\n\n\nPANAS_19\n\n\nNervous\n\n\n\n\nPANAS_20\n\n\nJittery\n\n\n\n\n\n\n\nItem fit\nItem fit curves\nPCA\nResidual correlations\n1st contrast loadings\nAnalysis of response categories\nResponse categories MIRT\nTargeting\nItem hierarchy\n\n\n\n\nCodesimfit1 &lt;- RIgetfit(df, iterations = 1000, cpu = 8) # save simulation output to object `simfit1`\nRIitemfit(df, simfit1)\n\n\n\n Item \n    InfitMSQ \n    Infit thresholds \n    OutfitMSQ \n    Outfit thresholds \n    Infit diff \n    Outfit diff \n  \n\n\n PANAS_11 \n    1.198 \n    [0.921, 1.073] \n    1.255 \n    [0.92, 1.082] \n    0.125 \n    0.173 \n  \n\n PANAS_12 \n    0.842 \n    [0.909, 1.081] \n    0.852 \n    [0.884, 1.108] \n    0.067 \n    0.032 \n  \n\n PANAS_13 \n    1.174 \n    [0.924, 1.085] \n    1.346 \n    [0.877, 1.131] \n    0.089 \n    0.215 \n  \n\n PANAS_14 \n    1.064 \n    [0.93, 1.067] \n    1.11 \n    [0.919, 1.081] \n    no misfit \n    0.029 \n  \n\n PANAS_15 \n    0.783 \n    [0.923, 1.091] \n    0.725 \n    [0.89, 1.144] \n    0.14 \n    0.165 \n  \n\n PANAS_16 \n    0.798 \n    [0.919, 1.091] \n    0.781 \n    [0.885, 1.12] \n    0.121 \n    0.104 \n  \n\n PANAS_17 \n    0.953 \n    [0.919, 1.087] \n    0.92 \n    [0.865, 1.139] \n    no misfit \n    no misfit \n  \n\n PANAS_18 \n    1.088 \n    [0.917, 1.09] \n    1.172 \n    [0.869, 1.144] \n    no misfit \n    0.028 \n  \n\n PANAS_19 \n    0.921 \n    [0.932, 1.081] \n    0.933 \n    [0.926, 1.078] \n    0.011 \n    no misfit \n  \n\n PANAS_20 \n    1.205 \n    [0.928, 1.072] \n    1.257 \n    [0.923, 1.08] \n    0.133 \n    0.177 \n  \n\n\nNote: \n\n MSQ values based on conditional calculations (n = 1851).                                Simulation based thresholds based on 1000 simulated datasets.\n\n\n\n\nRIitemfit() works with both dichotomous and polytomous data (no option needed).\nSince the distribution of item fit statistics are not known, we need to make simulations to get appropriate cutoff threshold values for the current sample and items. Important to note is that the new (since version 0.2.2, dated 2024-08-19) RIitemfit() function uses conditional outfit/infit, which is both robust to different sample sizes and makes ZSTD unnecessary (Müller, 2020). RIitemfit() can also use the simulation based cutoff values and use them for conditional highlighting of misfitting items. See the blog post on simulation based cutoffs for some more details on this.\nBriefly stated, the simulation uses the properties of the current sample and items, and simulates n iterations of data that fit the Rasch model to get an empirical distribution of item fit that we can use for comparison with the observed data. This is also known as “parametric bootstrapping”.\nThe simulation will take quite a bit of time to run if you have complex data/many participants, and/or choose to use many iterations. While insufficient testing has been done to make any strong recommendations, I think 1000 iterations is a good starting point, and probably no less than 500.\nFor reference, the simulation above, using 10 items with 5 response categories each and 1851 respondents, takes about 52 seconds to run on 8 cpu cores (Macbook Pro M1 Max).\nI’ll cite Ostini & Nering (2006) on the description of outfit and infit (pages 86-87):\n\nResponse residuals can be summed over respondents to obtain an item fit measure. Generally, the accumulation is done with squared standardized residuals, which are then divided by the total number of respondents to obtain a mean square statistic. In this form, the statistic is referred to as an unweighted mean square (Masters & Wright, 1997; Wright & Masters, 1982) and has also come to be known as “outfit” (Smith, Schumacker, & Bush, 1998; Wu, 1997), perhaps because it is highly sensitive to outlier responses (Adams & Khoo, 1996; Smith et al., 1998; Wright & Masters, 1982).\n\n\nA weighted version of this statistic was developed to counteract its sensitivity to outliers (Smith, 2000). In its weighted form, the squared standardized residual is multiplied by the observed response variance and then divided by the sum of the item response variances. This is sometimes referred to as an information weighted mean square and has become known as “infit” (Smith et al., 1998; Wu, 1997).\n\nA low item fit value (sometimes referred to as “overfitting” the Rasch model) indicates that responses are too predictable and provide little information. This is often the case for items that are very general/broad in scope in relation to the latent variable.\nA high item fit value (sometimes referred to as “underfitting” the Rasch model) can indicate several things, often multidimensionality or a question that is difficult to interpret. This could for instance be a question that asks about two things at the same time or is ambiguous for other reasons.\n\n\nThe iarm package (Mueller & Santiago, 2022) provides several interesting functions for assessing item fit, DIF and other things. Some of these functions may be included in a future version of the RISEkbmRasch package. Below are conditional item characteristic curves (ICC’s) using the estimated theta (factor score).\n\nCodelibrary(iarm)\nICCplot(as.data.frame(df), \n        itemnumber = 1:4, \n        method = \"cut\", \n        cinumber = 6, # number of class intervals to split respondents into\n        itemdescrip = c(\"PANAS_11\",\"PANAS_12\",\"PANAS_13\",\"PANAS_14\"))\n\n\n\n\n\n\n\n[1] \"Please press Zoom on the Plots window to see the plot\"\n\n\nA similar, but even more informative and flexible, visualization has been made available in the RASCHplot package (Buchardt et al., 2023), which needs to be installed from GitHub (see code below). The linked paper is recommended reading, not least for descriptions of the useful options available. Below are some sample plots showing conditional ICC’s using the raw sum score.\n\nCodelibrary(RASCHplot) # devtools::install_github(\"ERRTG/RASCHplot\")\n\nCICCplot(PCM(df),\n         which.item = c(1:4),\n         lower.groups = c(0,7,14,21,28),\n         grid.items = TRUE)\n\n\n\n\n\n\n\n\n\nPrincipal Component Analysis of Rasch model residuals.\n\nCodeRIpcmPCA(df)\n\n\n\n Eigenvalues \n    Proportion of variance \n  \n\n\n 1.79 \n    16.9% \n  \n\n 1.47 \n    15.1% \n  \n\n 1.28 \n    13.6% \n  \n\n 1.14 \n    13.3% \n  \n\n 1.06 \n    11.9% \n  \n\n\n\n\nBased on rule of thumb, the first eigenvalue should be below 2.0 to support unidimensionality. However, this is seldom accurate and needs to be complemented with checking item fit and residual correlations.\n\n\nSimilarly to item fit, we need to run simulations to get a useful cutoff threshold value for when residual correlations amongst item pairs are too large to show model fit (Christensen et al., 2017).\nAnd again, the simulation can take quite a bit of time, but is necessary to set the appropriate cutoff value.\n\nCodesimcor1 &lt;- RIgetResidCor(df, iterations = 1000, cpu = 8)\nRIresidcorr(df, cutoff = simcor1$p99)\n\n\n\n   \n    PANAS_11 \n    PANAS_12 \n    PANAS_13 \n    PANAS_14 \n    PANAS_15 \n    PANAS_16 \n    PANAS_17 \n    PANAS_18 \n    PANAS_19 \n    PANAS_20 \n  \n\n\n PANAS_11 \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n  \n\n PANAS_12 \n    -0.1 \n     \n     \n     \n     \n     \n     \n     \n     \n     \n  \n\n PANAS_13 \n    -0.05 \n    -0.01 \n     \n     \n     \n     \n     \n     \n     \n     \n  \n\n PANAS_14 \n    -0.11 \n    0.09 \n    0.07 \n     \n     \n     \n     \n     \n     \n     \n  \n\n PANAS_15 \n    -0.14 \n    -0.13 \n    -0.22 \n    -0.29 \n     \n     \n     \n     \n     \n     \n  \n\n PANAS_16 \n    -0.17 \n    -0.1 \n    -0.25 \n    -0.27 \n    0.38 \n     \n     \n     \n     \n     \n  \n\n PANAS_17 \n    -0.18 \n    -0.09 \n    -0.09 \n    -0.19 \n    -0.13 \n    -0.08 \n     \n     \n     \n     \n  \n\n PANAS_18 \n    -0.19 \n    -0.15 \n    -0.16 \n    -0.18 \n    -0.15 \n    -0.13 \n    0.32 \n     \n     \n     \n  \n\n PANAS_19 \n    -0.13 \n    -0.13 \n    -0.25 \n    -0.14 \n    0.1 \n    0.08 \n    -0.21 \n    -0.12 \n     \n     \n  \n\n PANAS_20 \n    -0.06 \n    -0.22 \n    -0.07 \n    -0.05 \n    -0.13 \n    -0.19 \n    -0.16 \n    -0.15 \n    -0.07 \n     \n  \n\n\nNote: \n\n Relative cut-off value (highlighted in red) is -0.004, which is 0.098 above the average correlation (-0.102).\n\n\n\n\nThe matrix above shows item-pair correlations of item residuals, with highlights in red showing correlations crossing the threshold compared to the average item-pair correlation (for all item-pairs) (Christensen et al., 2017). Rasch model residual correlations (Yen’s Q3) are calculated using the mirt package.\n\n\n\nCodeRIloadLoc(df)\n\n\n\n\n\n\n\nHere we see item locations and their loadings on the first residual contrast. This figure can be helpful to identify clusters in data or multidimensionality.\n\n\nThe xlims setting changes the x-axis limits for the plots. The default values usually make sense, and we mostly add this option to point out the possibility of doing so. You can also choose to only show plots for only specific items.\nCodeRIitemCats(df, xlims = c(-5,5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEach response category for each item should have a curve that indicates it to be the most probably response at some point on the latent variable (x axis in the figure).\n\n\nFor a more compact figure.\n\nCodemirt(df, model=1, itemtype='Rasch', verbose = FALSE) %&gt;% \n  plot(type=\"trace\", as.table = TRUE, \n       theta_lim = c(-5,5)) # changes x axis limits\n\n\n\n\n\n\n\n\n\n\nCode# increase fig-height in the chunk option above if you have many items\nRItargeting(df, xlim = c(-5,4)) # xlim defaults to c(-4,4) if you omit this option\n\n\n\n\n\n\n\nThis figure shows how well the items fit the respondents/persons. It is a sort of Wright Map that shows person locations and item threshold locations on the same logit scale.\nThe top part shows person location histogram, the middle part an inverted histogram of item threshold locations, and the bottom part shows individual item threshold locations. The histograms also show means and standard deviations.\n\n\nHere the items are sorted on their average threshold location (black diamonds). 84% confidence intervals are shown around each item threshold location. For further details, see the caption text below the figure.\nThe numbers displayed in the plot can be disabled using the option numbers = FALSE.\n\nCodeRIitemHierarchy(df)\n\n\n\n\n\n\n\n\n\n\n\n3.1 Analysis 1 comments\nItem fit shows a lot of issues.\nItem 18 has issues with the second lowest category being disordered. Several other items have very short distances between thresholds 1 and 2, which is also clearly seen in the Item Hierarchy figure above.\nTwo item-pairs show residual correlations far above the cutoff value:\n\n15 and 16 (scared and afraid)\n17 and 18 (ashamed and guilty)\n\nSince item 15 also has a residual correlation with item 19, we will remove it. In the second pair, item 18 will be removed since it also has problems with disordered response categories.\n\n\n\n\n\n\nNote\n\n\n\nWe have multiple “diagnostics” to review when deciding which item to remove if there are strong residual correlations between two items. Here is a list of commonly used criteria:\n\nitem fit\nitem threshold locations compared to sample locations (targeting)\nordering of response categories\nDIF\nand whether there are residual correlations between one item and multiple other items\n\n\n\n\nCoderemoved.items &lt;- c(\"PANAS_15\",\"PANAS_18\")\n\ndf_backup &lt;- df\n\ndf &lt;- df_backup %&gt;% \n  select(!any_of(removed.items))\n\n\nAs seen in the code above, I chose to create a copy of the dataframe with the removed items omitted. This can be useful if, at a later stage in the analysis, I want to be able to quickly “go back” and reinstate an item or undo any other change I have made."
  },
  {
    "objectID": "raschrvignette/RaschRvign.html#rasch-analysis-2",
    "href": "raschrvignette/RaschRvign.html#rasch-analysis-2",
    "title": "RISEkbmRasch vignette",
    "section": "\n4 Rasch analysis 2",
    "text": "4 Rasch analysis 2\nWith items 15 and 18 removed.\n\n\n\n\n\n\nitemnr\n\n\nitem\n\n\n\n\n\nPANAS_11\n\n\nDistressed\n\n\n\n\nPANAS_12\n\n\nUpset\n\n\n\n\nPANAS_13\n\n\nHostile\n\n\n\n\nPANAS_14\n\n\nIrritable\n\n\n\n\nPANAS_16\n\n\nAfraid\n\n\n\n\nPANAS_17\n\n\nAshamed\n\n\n\n\nPANAS_19\n\n\nNervous\n\n\n\n\nPANAS_20\n\n\nJittery\n\n\n\n\n\n\n\nItem fit\nPCA\nResidual correlations\n1st contrast loadings\nTargeting\nItem hierarchy\n\n\n\n\nCodesimfit2 &lt;- RIgetfit(df, iterations = 1000, cpu = 8)\nRIitemfit(df, simcut = simfit2)\n\n\n\n Item \n    InfitMSQ \n    Infit thresholds \n    OutfitMSQ \n    Outfit thresholds \n    Infit diff \n    Outfit diff \n  \n\n\n PANAS_11 \n    1.14 \n    [0.928, 1.072] \n    1.184 \n    [0.924, 1.08] \n    0.068 \n    0.104 \n  \n\n PANAS_12 \n    0.801 \n    [0.923, 1.087] \n    0.799 \n    [0.905, 1.106] \n    0.122 \n    0.106 \n  \n\n PANAS_13 \n    1.108 \n    [0.927, 1.076] \n    1.252 \n    [0.89, 1.144] \n    0.032 \n    0.108 \n  \n\n PANAS_14 \n    0.976 \n    [0.928, 1.074] \n    1.022 \n    [0.922, 1.078] \n    no misfit \n    no misfit \n  \n\n PANAS_16 \n    0.876 \n    [0.926, 1.078] \n    0.854 \n    [0.888, 1.118] \n    0.05 \n    0.034 \n  \n\n PANAS_17 \n    1.04 \n    [0.917, 1.082] \n    1.01 \n    [0.872, 1.135] \n    no misfit \n    no misfit \n  \n\n PANAS_19 \n    0.937 \n    [0.927, 1.066] \n    0.957 \n    [0.923, 1.074] \n    no misfit \n    no misfit \n  \n\n PANAS_20 \n    1.159 \n    [0.924, 1.078] \n    1.194 \n    [0.915, 1.085] \n    0.081 \n    0.109 \n  \n\n\nNote: \n\n MSQ values based on conditional calculations (n = 1851).                                Simulation based thresholds based on 1000 simulated datasets.\n\n\n\n\n\n\n\nCodeRIpcmPCA(df)\n\n\n\n Eigenvalues \n    Proportion of variance \n  \n\n\n 1.52 \n    18.9% \n  \n\n 1.33 \n    17.1% \n  \n\n 1.19 \n    16.6% \n  \n\n 1.15 \n    14.6% \n  \n\n 1.00 \n    13.1% \n  \n\n\n\n\n\n\n\nCodesimcor2 &lt;- RIgetResidCor(df, iterations = 1000, cpu = 8)\nRIresidcorr(df, cutoff = simcor2$p99)\n\n\n\n   \n    PANAS_11 \n    PANAS_12 \n    PANAS_13 \n    PANAS_14 \n    PANAS_16 \n    PANAS_17 \n    PANAS_19 \n    PANAS_20 \n  \n\n\n PANAS_11 \n     \n     \n     \n     \n     \n     \n     \n     \n  \n\n PANAS_12 \n    -0.16 \n     \n     \n     \n     \n     \n     \n     \n  \n\n PANAS_13 \n    -0.11 \n    -0.06 \n     \n     \n     \n     \n     \n     \n  \n\n PANAS_14 \n    -0.19 \n    0.03 \n    0.01 \n     \n     \n     \n     \n     \n  \n\n PANAS_16 \n    -0.16 \n    -0.08 \n    -0.25 \n    -0.28 \n     \n     \n     \n     \n  \n\n PANAS_17 \n    -0.18 \n    -0.06 \n    -0.09 \n    -0.19 \n    0 \n     \n     \n     \n  \n\n PANAS_19 \n    -0.15 \n    -0.15 \n    -0.28 \n    -0.18 \n    0.12 \n    -0.16 \n     \n     \n  \n\n PANAS_20 \n    -0.1 \n    -0.27 \n    -0.13 \n    -0.11 \n    -0.18 \n    -0.15 \n    -0.09 \n     \n  \n\n\nNote: \n\n Relative cut-off value (highlighted in red) is -0.029, which is 0.1 above the average correlation (-0.129).\n\n\n\n\n\n\n\nCodeRIloadLoc(df)\n\n\n\n\n\n\n\n\n\n\nCodeRItargeting(df, xlim = c(-4,4), bins = 45)\n\n\n\n\n\n\n\n\n\n\nCodeRIitemHierarchy(df)\n\n\n\n\n\n\n\n\n\n\n\n4.1 Analysis 2 comments\nItems 16 & 19, and 12 & 14 show problematic residual correlations.\nLet’s look at DIF before taking action upon this information. While we are keeping DIF as a separate section in this vignette, it is recommended to include DIF-analysis in the panel-tabset above (on item fit, PCA, residual correlations, etc)."
  },
  {
    "objectID": "raschrvignette/RaschRvign.html#dif---differential-item-functioning",
    "href": "raschrvignette/RaschRvign.html#dif---differential-item-functioning",
    "title": "RISEkbmRasch vignette",
    "section": "\n5 DIF - differential item functioning",
    "text": "5 DIF - differential item functioning\nWe’ll be looking at whether item (threshold) locations are stable between demographic subgroups.\nThere are several DIF analysis tools available. The first one uses the package psychotree, which relies on statistical significance at p &lt; .05 as an indicator for DIF. This is a criterion that is highly sample size sensitive, and we are always interested in the size/magnitude of DIF as well, since that will inform us about the impact of DIF on the estimated latent variable.\nThe structure of DIF is also an important and complex aspect, particularly for polytomous data. Uniform DIF means that the DIF is similar across the latent continuum. We can test this in R using the lordif package, as demonstrated in Section 5.6.\nA recent preprint (Henninger et al., 2024) does a great job illustrating “differential step functioning” (DSF), which is when item threshold locations in polytomous data show varying levels of DIF. It also describes a forthcoming development of the psychotree where one can use DIF effect size and purification functions to evaluate DIF/DSF. When the updated package is available, I will work to implement these new functions into the RISEkbmRasch package as well.\n\n\n\n\n\n\nNote\n\n\n\nIt is important to ensure that no cells in the data are empty for subgroups when conducting a DIF analysis. Split the data using the DIF-variable and create separate tileplots to review the response distribution in the DIF-groups.\n\n\n\nCodedifPlots &lt;- df %&gt;% # save the output into the `difPlots` object\n  add_column(gender = dif.sex) %&gt;% # add the DIF variable to the dataframe\n  split(.$gender) %&gt;% # split the data using the DIF variable\n  map(~ RItileplot(.x %&gt;% dplyr::select(!gender)) + labs(title = .x$gender)) # create separate tileplots for each group\n\ndifPlots$Female + difPlots$Male # the actual name of the plots (in this case Male/Female) will be determined by the factor labels\n\n\n\n\n\n\n\n\n5.1 Sex\n\n\n\n\n\n\nitemnr\n\n\nitem\n\n\n\n\n\nPANAS_11\n\n\nDistressed\n\n\n\n\nPANAS_12\n\n\nUpset\n\n\n\n\nPANAS_13\n\n\nHostile\n\n\n\n\nPANAS_14\n\n\nIrritable\n\n\n\n\nPANAS_16\n\n\nAfraid\n\n\n\n\nPANAS_17\n\n\nAshamed\n\n\n\n\nPANAS_19\n\n\nNervous\n\n\n\n\nPANAS_20\n\n\nJittery\n\n\n\n\n\n\n\nTable\nFigure items\nFigure thresholds\n\n\n\n\nCodeRIdifTable(df, dif.sex)\n\n\n\n\n\n\n\n\n\n\nItem\n\n\n2\n\n\n3\n\n\nMean location\n\n\nStDev\n\n\nMaxDiff\n\n\n\n\n\nPANAS_11\n\n\n-0.314\n\n\n-0.196\n\n\n-0.255\n\n\n0.083\n\n\n0.117\n\n\n\n\nPANAS_12\n\n\n0.028\n\n\n-0.044\n\n\n-0.008\n\n\n0.051\n\n\n0.073\n\n\n\n\nPANAS_13\n\n\n0.553\n\n\n0.402\n\n\n0.478\n\n\n0.107\n\n\n0.151\n\n\n\n\nPANAS_14\n\n\n-0.328\n\n\n-0.183\n\n\n-0.255\n\n\n0.103\n\n\n0.146\n\n\n\n\nPANAS_16\n\n\n0.004\n\n\n0.114\n\n\n0.059\n\n\n0.078\n\n\n0.111\n\n\n\n\nPANAS_17\n\n\n0.520\n\n\n0.290\n\n\n0.405\n\n\n0.163\n\n\n0.230\n\n\n\n\nPANAS_19\n\n\n-0.495\n\n\n-0.355\n\n\n-0.425\n\n\n0.099\n\n\n0.140\n\n\n\n\nPANAS_20\n\n\n0.032\n\n\n-0.028\n\n\n0.002\n\n\n0.042\n\n\n0.059\n\n\n\n\n\n\n\n\n\nCodeRIdifFigure(df, dif.sex)\n\n\n\n\n\n\n\n\n\n\nCodeRIdifFigThresh(df, dif.sex)\n\n\n\n\n\n\n\n\n\n\nWhile no item shows problematic levels of DIF regarding item location, as shown by the table, there is an interesting pattern in the thresholds figure. The lowest threshold seems to be slightly lower for node 3 (Male) for all items. Also, item 11 shows a much wider spread of item locations for node 3 compared to node 2.\nThe results do not require any action since the difference is small.\n\n5.2 Age\nThe psychotree package uses a model-based recursive partitioning that is particularly useful when you have a continuous variable such as age in years and a large enough sample. It will test different ways to partition the age variable to determine potential group differences (Strobl et al., 2015b, 2021).\n\nCodeRIdifTable(df, dif.age)\n\n[1] \"No significant DIF found.\"\n\n\nNo DIF found for age.\n\n5.3 Group\n\nCodeRIdifTable(df, dif.group)\n\n[1] \"No significant DIF found.\"\n\n\nAnd no DIF for group.\n\n5.4 Sex and age\nThe psychotree package also allows for DIF interaction analysis with multiple DIF variables. We can use RIdifTable2() to input two DIF variables.\n\nCodeRIdifTable2(df, dif.sex, dif.age)\n\n\n\n\n\n\n\n\n\n\nItem\n\n\n2\n\n\n3\n\n\nMean location\n\n\nStDev\n\n\nMaxDiff\n\n\n\n\n\nPANAS_11\n\n\n-0.314\n\n\n-0.196\n\n\n-0.255\n\n\n0.083\n\n\n0.117\n\n\n\n\nPANAS_12\n\n\n0.028\n\n\n-0.044\n\n\n-0.008\n\n\n0.051\n\n\n0.073\n\n\n\n\nPANAS_13\n\n\n0.553\n\n\n0.402\n\n\n0.478\n\n\n0.107\n\n\n0.151\n\n\n\n\nPANAS_14\n\n\n-0.328\n\n\n-0.183\n\n\n-0.255\n\n\n0.103\n\n\n0.146\n\n\n\n\nPANAS_16\n\n\n0.004\n\n\n0.114\n\n\n0.059\n\n\n0.078\n\n\n0.111\n\n\n\n\nPANAS_17\n\n\n0.520\n\n\n0.290\n\n\n0.405\n\n\n0.163\n\n\n0.230\n\n\n\n\nPANAS_19\n\n\n-0.495\n\n\n-0.355\n\n\n-0.425\n\n\n0.099\n\n\n0.140\n\n\n\n\nPANAS_20\n\n\n0.032\n\n\n-0.028\n\n\n0.002\n\n\n0.042\n\n\n0.059\n\n\n\n\n\n\nNo interaction effect found for sex and age. The analysis only shows the previously identified DIF for sex.\n\n5.5 LRT-based DIF\n\n\n\n\n\n\nNote\n\n\n\nAs of RISEkbmRasch package version 0.1.16, there are four new functions for analyzing item location DIF. These are all making use of the function LRtest() from the eRm package. And, since version 0.1.31.0, these are also correctly extracting item locations/threshold locations. Results will not be identical to the results from the previous functions that use the psychotree package, since they make some different choices in estimation. I refer the curious to the respective package’s documentation.\n\n\nWe’ll use the group variable as an example. First, we can simply run the test to get the overall result.\n\nCodeerm.out &lt;- PCM(df)\nLRtest(erm.out, splitcr = dif.group)\n\n\nAndersen LR-test: \nLR-value: 46.864 \nChi-square df: 31 \np-value:  0.034 \n\n\nReview the documentation for further details, using ?LRtest in your R console panel in Rstudio. There is also a plotting function, plotGOF() that may be of interest.\n\n\n\n\n\n\nitemnr\n\n\nitem\n\n\n\n\n\nPANAS_11\n\n\nDistressed\n\n\n\n\nPANAS_12\n\n\nUpset\n\n\n\n\nPANAS_13\n\n\nHostile\n\n\n\n\nPANAS_14\n\n\nIrritable\n\n\n\n\nPANAS_16\n\n\nAfraid\n\n\n\n\nPANAS_17\n\n\nAshamed\n\n\n\n\nPANAS_19\n\n\nNervous\n\n\n\n\nPANAS_20\n\n\nJittery\n\n\n\n\n\n\n\nItem location table\nItem location figure\nItem threshold table\nItem threshold figure\n\n\n\n\nCodeRIdifTableLR(df, dif.group)\n\n\n\n\n\nItem locations\nStandard errors\n\n\n Item \n    Earlier Start \n    Later Start \n    MaxDiff \n    All \n    SE_Earlier Start \n    SE_Later Start \n    SE_All \n  \n\n\n\n PANAS_11 \n    0.069 \n    0.072 \n    0.003 \n    0.073 \n    0.140 \n    0.124 \n    0.093 \n  \n\n PANAS_12 \n    0.33 \n    0.346 \n    0.016 \n    0.342 \n    0.155 \n    0.133 \n    0.101 \n  \n\n PANAS_13 \n    0.69 \n    0.966 \n    0.276 \n    0.826 \n    0.185 \n    0.189 \n    0.129 \n  \n\n PANAS_14 \n    0.118 \n    0.054 \n    0.064 \n    0.084 \n    0.142 \n    0.121 \n    0.092 \n  \n\n PANAS_16 \n    0.447 \n    0.362 \n    0.085 \n    0.401 \n    0.160 \n    0.134 \n    0.102 \n  \n\n PANAS_17 \n    0.66 \n    0.822 \n    0.162 \n    0.751 \n    0.184 \n    0.172 \n    0.125 \n  \n\n PANAS_19 \n    -0.028 \n    -0.122 \n    0.094 \n    -0.083 \n    0.136 \n    0.117 \n    0.088 \n  \n\n PANAS_20 \n    0.351 \n    0.348 \n    0.003 \n    0.352 \n    0.160 \n    0.138 \n    0.104 \n  \n\n\nNote: \n\n Values highlighted in red are above the chosen cutoff 0.5 logits. Background color brown and blue indicate the lowest and highest values among the DIF groups.\n\n\n\n\n\n\n\nCodeRIdifFigureLR(df, dif.group) + theme_rise()\n\n\n\n\n\n\n\n\n\n\nCodeRIdifThreshTblLR(df, dif.group)\n\n\n\n\n\nThreshold locations\nStandard errors\n\n\n Item threshold \n    Earlier Start \n    Later Start \n    MaxDiff \n    All \n    SE_Earlier Start \n    SE_Later Start \n    SE_All \n  \n\n\nPANAS_11\n\n c1 \n    -1.245 \n    -1.241 \n    0.004 \n    -1.240 \n    0.098 \n    0.094 \n    0.068 \n  \n\n c2 \n    -0.365 \n    -0.221 \n    0.144 \n    -0.284 \n    0.107 \n    0.100 \n    0.073 \n  \n\n c3 \n    0.281 \n    0.096 \n    0.185 \n    0.180 \n    0.131 \n    0.114 \n    0.086 \n  \n\n c4 \n    1.604 \n    1.655 \n    0.051 \n    1.637 \n    0.224 \n    0.188 \n    0.144 \n  \nPANAS_12\n\n c1 \n    -0.484 \n    -0.362 \n    0.122 \n    -0.418 \n    0.092 \n    0.091 \n    0.065 \n  \n\n c2 \n    0.241 \n    -0.198 \n    0.439 \n    -0.005 \n    0.126 \n    0.108 \n    0.082 \n  \n\n c3 \n    0.479 \n    0.456 \n    0.023 \n    0.467 \n    0.169 \n    0.129 \n    0.103 \n  \n\n c4 \n    1.086 \n    1.489 \n    0.403 \n    1.323 \n    0.233 \n    0.205 \n    0.153 \n  \nPANAS_13\n\n c1 \n    -0.067 \n    0.23 \n    0.297 \n    0.093 \n    0.092 \n    0.089 \n    0.064 \n  \n\n c2 \n    0.403 \n    0.115 \n    0.288 \n    0.248 \n    0.135 \n    0.118 \n    0.088 \n  \n\n c3 \n    0.889 \n    1.042 \n    0.153 \n    0.983 \n    0.197 \n    0.164 \n    0.126 \n  \n\n c4 \n    1.536 \n    2.476 \n    0.94 \n    1.979 \n    0.316 \n    0.384 \n    0.239 \n  \nPANAS_14\n\n c1 \n    -1.017 \n    -0.972 \n    0.045 \n    -0.990 \n    0.095 \n    0.094 \n    0.066 \n  \n\n c2 \n    -0.134 \n    -0.272 \n    0.138 \n    -0.205 \n    0.111 \n    0.103 \n    0.076 \n  \n\n c3 \n    0.456 \n    0.095 \n    0.361 \n    0.239 \n    0.146 \n    0.116 \n    0.091 \n  \n\n c4 \n    1.168 \n    1.366 \n    0.198 \n    1.294 \n    0.216 \n    0.173 \n    0.135 \n  \nPANAS_16\n\n c1 \n    -0.156 \n    -0.25 \n    0.094 \n    -0.202 \n    0.097 \n    0.091 \n    0.066 \n  \n\n c2 \n    0.009 \n    -0.091 \n    0.1 \n    -0.046 \n    0.130 \n    0.112 \n    0.085 \n  \n\n c3 \n    0.324 \n    0.354 \n    0.03 \n    0.344 \n    0.159 \n    0.132 \n    0.102 \n  \n\n c4 \n    1.611 \n    1.435 \n    0.176 \n    1.508 \n    0.253 \n    0.201 \n    0.157 \n  \nPANAS_17\n\n c1 \n    0.264 \n    0.368 \n    0.104 \n    0.324 \n    0.097 \n    0.089 \n    0.066 \n  \n\n c2 \n    0.389 \n    0.421 \n    0.032 \n    0.412 \n    0.146 \n    0.128 \n    0.096 \n  \n\n c3 \n    0.804 \n    0.955 \n    0.151 \n    0.894 \n    0.205 \n    0.181 \n    0.136 \n  \n\n c4 \n    1.182 \n    1.545 \n    0.363 \n    1.373 \n    0.288 \n    0.290 \n    0.204 \n  \nPANAS_19\n\n c1 \n    -1.339 \n    -1.263 \n    0.076 \n    -1.297 \n    0.100 \n    0.098 \n    0.070 \n  \n\n c2 \n    -0.388 \n    -0.27 \n    0.118 \n    -0.323 \n    0.108 \n    0.105 \n    0.075 \n  \n\n c3 \n    0.101 \n    -0.333 \n    0.434 \n    -0.143 \n    0.127 \n    0.111 \n    0.083 \n  \n\n c4 \n    1.512 \n    1.378 \n    0.134 \n    1.430 \n    0.207 \n    0.156 \n    0.125 \n  \nPANAS_20\n\n c1 \n    -0.906 \n    -0.877 \n    0.029 \n    -0.887 \n    0.093 \n    0.090 \n    0.065 \n  \n\n c2 \n    -0.189 \n    -0.257 \n    0.068 \n    -0.223 \n    0.108 \n    0.099 \n    0.073 \n  \n\n c3 \n    1.037 \n    0.585 \n    0.452 \n    0.760 \n    0.162 \n    0.123 \n    0.098 \n  \n\n c4 \n    1.463 \n    1.941 \n    0.478 \n    1.756 \n    0.277 \n    0.238 \n    0.180 \n  \n\n\nNote: \n\n Values highlighted in red are above the chosen cutoff 0.5 logits. Background color brown and blue indicate the lowest and highest values among the DIF groups.\n\n\n\n\n\n\n\nCodeRIdifThreshFigLR(df, dif.group) + theme_rise()\n\n\n\n\n\n\n\n\n\n\nThe item threshold table shows that the top threshold for item 13 differs more than 0.5 logits between groups. In this set of 8 items with 4 thresholds each, it is unlikely to result in problematic differences in estimated person scores.\n\n5.6 Logistic Ordinal Regression DIF\nThe lordif package (Choi et al., 2011) does not use a Rasch measurement model, it only offers a choice between the Graded Response Model (GRM) and the Generalized Partial Credit Model (GPCM). Both of these are 2PL models, meaning that they estimate a discrimination parameter for each item in addition to the item threshold parameters. lordif relies on the mirt package.\nThere are several nice features available in the lordif package. First, we get a χ2 test of uniform or non-uniform DIF. Second, there are three possible methods/criteria for flagging items with potential DIF. One of these uses a likelihood ratio (LR) χ2 test, while the other two are indicators of DIF size/magnitude, either using a pseudo R2 statistic (“McFadden”, “Nagelkerke”, or “CoxSnell”) or a Beta criterion. For further details, see ?lordif in your R console or the paper describing the package (Choi et al., 2011).\nBelow is some sample code to get you started with lordif.\n\nCodelibrary(lordif)\n\ng_dif &lt;- lordif(as.data.frame(df), as.numeric(dif.sex), # make sure that the data is in a dataframe-object and that the DIF variable is numeric\n                criterion = c(\"Chisqr\"), \n                alpha = 0.01, \n                beta.change = 0.1,\n                model = \"GPCM\",\n                R2.change = 0.02)\n\ng_dif_sum &lt;- summary(g_dif)\n\n\n\nCode# threshold values for colorizing the table below\nalpha = 0.01\nbeta.change = 0.1\nR2.change = 0.02\n\ng_dif_sum$stats %&gt;% \n  as.data.frame() %&gt;% \n  select(!all_of(c(\"item\",\"df12\",\"df13\",\"df23\"))) %&gt;% \n  round(3) %&gt;% \n  add_column(itemnr = names(df), .before = \"ncat\") %&gt;% \n  mutate(across(c(chi12,chi13,chi23), ~ cell_spec(.x,\n                               color = case_when(\n                                 .x &lt; alpha ~ \"red\",\n                                 TRUE ~ \"black\"\n                               )))) %&gt;%\n  mutate(across(starts_with(\"pseudo\"), ~ cell_spec(.x,\n                               color = case_when(\n                                 .x &gt; R2.change ~ \"red\",\n                                 TRUE ~ \"black\"\n                               )))) %&gt;%\n  mutate(beta12 =  cell_spec(beta12,\n                               color = case_when(\n                                 beta12 &gt; beta.change ~ \"red\",\n                                 TRUE ~ \"black\"\n                               ))) %&gt;% \n  kbl_rise()\n\n\n\n itemnr \n    ncat \n    chi12 \n    chi13 \n    chi23 \n    beta12 \n    pseudo12.McFadden \n    pseudo13.McFadden \n    pseudo23.McFadden \n    pseudo12.Nagelkerke \n    pseudo13.Nagelkerke \n    pseudo23.Nagelkerke \n    pseudo12.CoxSnell \n    pseudo13.CoxSnell \n    pseudo23.CoxSnell \n  \n\n\n PANAS_11 \n    5 \n    0.323 \n    0 \n    0 \n    0.002 \n    0 \n    0.004 \n    0.003 \n    0 \n    0.005 \n    0.005 \n    0 \n    0.005 \n    0.005 \n  \n\n PANAS_12 \n    5 \n    0.013 \n    0.019 \n    0.192 \n    0.008 \n    0.001 \n    0.002 \n    0 \n    0.001 \n    0.002 \n    0 \n    0.001 \n    0.002 \n    0 \n  \n\n PANAS_13 \n    5 \n    0.106 \n    0.057 \n    0.077 \n    0.007 \n    0.001 \n    0.001 \n    0.001 \n    0.001 \n    0.002 \n    0.001 \n    0.001 \n    0.002 \n    0.001 \n  \n\n PANAS_14 \n    5 \n    0.182 \n    0.401 \n    0.83 \n    0.002 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n\n PANAS_16 \n    5 \n    0.64 \n    0.17 \n    0.068 \n    0.001 \n    0 \n    0.001 \n    0.001 \n    0 \n    0.001 \n    0.001 \n    0 \n    0.001 \n    0.001 \n  \n\n PANAS_17 \n    5 \n    0 \n    0 \n    0.32 \n    0.032 \n    0.008 \n    0.008 \n    0 \n    0.011 \n    0.011 \n    0 \n    0.01 \n    0.01 \n    0 \n  \n\n PANAS_19 \n    5 \n    0.178 \n    0.25 \n    0.33 \n    0.002 \n    0 \n    0 \n    0 \n    0 \n    0.001 \n    0 \n    0 \n    0.001 \n    0 \n  \n\n PANAS_20 \n    5 \n    0.68 \n    0.349 \n    0.164 \n    0.001 \n    0 \n    0 \n    0 \n    0 \n    0.001 \n    0.001 \n    0 \n    0.001 \n    0.001 \n  \n\n\n\n\nWe can review the results regarding uniform/non-uniform DIF by looking at the chi* columns. Uniform DIF is indicated by column chi12 and non-uniform DIF by chi23, while column chi13 represents “an overall test of”total DIF effect” (Choi et al., 2011).\nWhile the table indicates significant chi2-tests for items 11 and 17, the magnitude estimates are low for these items.\nThere are some plots available as well, using the base R plot() function. For some reason the plots won’t render in this Quarto document, so I will try to sort that out at some point.\nCodeplot(g_dif) # use option `graphics.off()` to get the plots rendered one by one\n#plot(g_dif, graphics.off())\n\n\n\n\n5.7 Partial gamma DIF\nThe iarm package provides a function to assess DIF by partial gamma (Bjorner et al., 1998).\nThere are some recommended cutoff-values mentioned in the paper above:\nNo or negligible DIF:\n\nGamma within the interval -0.21 to 0.21, or\n\nGamma not significantly different from 0\n\nSlight to moderate DIF:\n\nGamma within the interval -0.31 to 0.31 (and outside -0.21 to 0.21), or\n\nnot significantly outside the interval -0.21 to 0.21\n\nModerate to large DIF:\n\nGamma outside the interval -0.31 to 0.31, and\n\nsignificantly outside the interval -0.21 to 0.21\n\n\nCodepartgam_DIF(as.data.frame(df), dif.sex, p.adj = \"BH\")\n\n      Item     Var   gamma     se pvalue padj.BH  sig   lower   upper\n1 PANAS_11 dif.sex  0.0659 0.0457 0.1495  1.0000      -0.0237  0.1555\n2 PANAS_12 dif.sex  0.0917 0.0514 0.0743  0.5944      -0.0090  0.1924\n3 PANAS_13 dif.sex  0.0074 0.0543 0.8913  1.0000      -0.0990  0.1139\n4 PANAS_14 dif.sex -0.0954 0.0464 0.0396  0.3171      -0.1863 -0.0045\n5 PANAS_16 dif.sex -0.0318 0.0515 0.5375  1.0000      -0.1327  0.0692\n6 PANAS_17 dif.sex  0.2339 0.0545 0.0000  0.0001  ***  0.1271  0.3407\n7 PANAS_19 dif.sex -0.0918 0.0460 0.0458  0.3662      -0.1819 -0.0017\n8 PANAS_20 dif.sex -0.0067 0.0465 0.8860  1.0000      -0.0978  0.0845\n\n\nWe can see “slight” DIF for item 17, with a statistically significant gamma of .23."
  },
  {
    "objectID": "raschrvignette/RaschRvign.html#rasch-analysis-3",
    "href": "raschrvignette/RaschRvign.html#rasch-analysis-3",
    "title": "RISEkbmRasch vignette",
    "section": "\n6 Rasch analysis 3",
    "text": "6 Rasch analysis 3\nWhile there were no significant issues with DIF for any item/subgroup combination, we need to address the previously identified problem:\n\nItems 16 and 19 have the largest residual correlation.\n\nWe’ll remove item 19 since item 16 has better targeting.\n\nCoderemoved.items &lt;- c(removed.items,\"PANAS_19\")\n\ndf_backup2 &lt;- df\n\ndf &lt;- df_backup2 %&gt;% \n  select(!any_of(removed.items))\n\n\n\n\n\n\n\n\nitemnr\n\n\nitem\n\n\n\n\n\nPANAS_11\n\n\nDistressed\n\n\n\n\nPANAS_12\n\n\nUpset\n\n\n\n\nPANAS_13\n\n\nHostile\n\n\n\n\nPANAS_14\n\n\nIrritable\n\n\n\n\nPANAS_16\n\n\nAfraid\n\n\n\n\nPANAS_17\n\n\nAshamed\n\n\n\n\nPANAS_20\n\n\nJittery\n\n\n\n\n\n\n\nItem fit\nCICC\nResidual correlations\nTargeting\nItem hierarchy\n\n\n\n\nCodesimfit3 &lt;- RIgetfit(df, iterations = 1000, cpu = 8)\nRIitemfit(df, simfit3)\n\n\n\n Item \n    InfitMSQ \n    Infit thresholds \n    OutfitMSQ \n    Outfit thresholds \n    Infit diff \n    Outfit diff \n  \n\n\n PANAS_11 \n    1.127 \n    [0.923, 1.075] \n    1.152 \n    [0.925, 1.076] \n    0.052 \n    0.076 \n  \n\n PANAS_12 \n    0.783 \n    [0.923, 1.069] \n    0.783 \n    [0.899, 1.095] \n    0.14 \n    0.116 \n  \n\n PANAS_13 \n    1.047 \n    [0.924, 1.074] \n    1.127 \n    [0.894, 1.129] \n    no misfit \n    no misfit \n  \n\n PANAS_14 \n    0.952 \n    [0.923, 1.072] \n    0.991 \n    [0.924, 1.078] \n    no misfit \n    no misfit \n  \n\n PANAS_16 \n    0.939 \n    [0.923, 1.08] \n    0.968 \n    [0.901, 1.104] \n    no misfit \n    no misfit \n  \n\n PANAS_17 \n    1.002 \n    [0.914, 1.081] \n    0.981 \n    [0.869, 1.132] \n    no misfit \n    no misfit \n  \n\n PANAS_20 \n    1.162 \n    [0.931, 1.071] \n    1.201 \n    [0.931, 1.078] \n    0.091 \n    0.123 \n  \n\n\nNote: \n\n MSQ values based on conditional calculations (n = 1851).                                Simulation based thresholds based on 1000 simulated datasets.\n\n\n\n\n\n\n\nCodeCICCplot(PCM(df),\n         which.item = c(1:3,7),\n         lower.groups = c(0,7,14,21,28),\n         grid.items = TRUE)\n\n\n\n\n\n\n\n\n\n\nCodesimcor3 &lt;- RIgetResidCor(df, iterations = 1000, cpu = 8)\nRIresidcorr(df, cutoff = simcor3$p99)\n\n\n\n   \n    PANAS_11 \n    PANAS_12 \n    PANAS_13 \n    PANAS_14 \n    PANAS_16 \n    PANAS_17 \n    PANAS_20 \n  \n\n\n PANAS_11 \n     \n     \n     \n     \n     \n     \n     \n  \n\n PANAS_12 \n    -0.18 \n     \n     \n     \n     \n     \n     \n  \n\n PANAS_13 \n    -0.15 \n    -0.11 \n     \n     \n     \n     \n     \n  \n\n PANAS_14 \n    -0.22 \n    0.01 \n    -0.04 \n     \n     \n     \n     \n  \n\n PANAS_16 \n    -0.14 \n    -0.06 \n    -0.26 \n    -0.26 \n     \n     \n     \n  \n\n PANAS_17 \n    -0.2 \n    -0.09 \n    -0.14 \n    -0.22 \n    0 \n     \n     \n  \n\n PANAS_20 \n    -0.12 \n    -0.29 \n    -0.16 \n    -0.13 \n    -0.15 \n    -0.17 \n     \n  \n\n\nNote: \n\n Relative cut-off value (highlighted in red) is -0.052, which is 0.095 above the average correlation (-0.147).\n\n\n\n\n\n\n\nCodeRItargeting(df, bins = 45)\n\n\n\n\n\n\n\n\n\n\nCodeRIitemHierarchy(df)\n\n\n\n\n\n\n\n\n\n\n\n6.1 Analysis 3 comments\nNo problematic residual correlations remaining. Several items show misfit but we will end this sample analysis here and move on to show other functions.\nThere are several item thresholds that are very closely located, as shown in the item hierarchy figure. This is not ideal, since it will inflate reliability estimates. However, we will not modify the response categories for this analysis, we only note that this is not workable and should be dealt with by trying variations of merged response categories to achieve better separation of threshold locations without disordering."
  },
  {
    "objectID": "raschrvignette/RaschRvign.html#rasch-analysis-4",
    "href": "raschrvignette/RaschRvign.html#rasch-analysis-4",
    "title": "RISEkbmRasch vignette",
    "section": "\n7 Rasch analysis 4",
    "text": "7 Rasch analysis 4\n\nCoderemoved.items &lt;- c(removed.items,\"PANAS_12\")\n\ndf2 &lt;- df2 %&gt;% \n  select(!any_of(removed.items))\n\n\n\n\n\n\n\n\nitemnr\n\n\nitem\n\n\n\n\n\nPANAS_11\n\n\nDistressed\n\n\n\n\nPANAS_13\n\n\nHostile\n\n\n\n\nPANAS_14\n\n\nIrritable\n\n\n\n\nPANAS_16\n\n\nAfraid\n\n\n\n\nPANAS_17\n\n\nAshamed\n\n\n\n\nPANAS_20\n\n\nJittery\n\n\n\n\n\n\n\nItem fit\nResidual correlations\nTargeting\nItem hierarchy\n\n\n\n\nCodeRIitemfitPCM2(df2, 350, 32, 8)\n\n\n\n   \n    OutfitMSQ \n    InfitMSQ \n    OutfitZSTD \n    InfitZSTD \n  \n\n\n PANAS_11 \n    0.926 \n    0.932 \n    -0.954 \n    -0.805 \n  \n\n PANAS_13 \n    0.907 \n    0.894 \n    -0.498 \n    -1.348 \n  \n\n PANAS_14 \n    0.85 \n    0.83 \n    -1.744 \n    -2.353 \n  \n\n PANAS_16 \n    0.795 \n    0.8 \n    -2 \n    -2.317 \n  \n\n PANAS_17 \n    0.802 \n    0.834 \n    -1.513 \n    -1.65 \n  \n\n PANAS_20 \n    0.96 \n    0.946 \n    -0.401 \n    -0.759 \n  \n\n\n\n\n\n\n\nCodeRIresidcorr(df2, cutoff = 0.2)\n\n\n\n   \n    PANAS_11 \n    PANAS_13 \n    PANAS_14 \n    PANAS_16 \n    PANAS_17 \n    PANAS_20 \n  \n\n\n PANAS_11 \n     \n     \n     \n     \n     \n     \n  \n\n PANAS_13 \n    -0.17 \n     \n     \n     \n     \n     \n  \n\n PANAS_14 \n    -0.22 \n    -0.03 \n     \n     \n     \n     \n  \n\n PANAS_16 \n    -0.15 \n    -0.26 \n    -0.24 \n     \n     \n     \n  \n\n PANAS_17 \n    -0.22 \n    -0.14 \n    -0.21 \n    0.01 \n     \n     \n  \n\n PANAS_20 \n    -0.17 \n    -0.2 \n    -0.16 \n    -0.19 \n    -0.2 \n     \n  \n\n\nNote: \n\n Relative cut-off value (highlighted in red) is 0.03, which is 0.2 above the average correlation.\n\n\n\n\n\n\n\nCodeRItargeting(df2)\n\n\n\n\n\n\n\n\n\n\nCodeRIitemHierarchy(df2)\n\n\n\n\n\n\n\n\n\n\n\n7.1 Analysis 4 comments\nThere are several item thresholds that are very closely located, as shown in the item hierarchy figure. This is not ideal, since it will inflate reliability estimates.\nHowever, we will not modify the response categories for this sample/simple analysis, we only note that this is not ideal."
  },
  {
    "objectID": "raschrvignette/RaschRvign.html#reliability",
    "href": "raschrvignette/RaschRvign.html#reliability",
    "title": "RISEkbmRasch vignette",
    "section": "\n7 Reliability",
    "text": "7 Reliability\n\nCodeRItif(df)\n\n\n\n\n\n\n\nThe figure above shows the Test Information Function (TIF), which indicates the reliability of all items making up the test/scale (not the reliability of the sample).\nThe default cutoff value used in RItif() is TIF = 3.33, which corresponds to person separation index (PSI) = 0.7. PSI is similar to reliability coefficients such as omega and alpha, ranging from 0 to 1. You can change the TIF cutoff by using the option cutoff, for instance cutoff = 2.5 (TIF values range from 1 and up).\nWhile 11.8% of respondents had a floor effect based on the raw sum scored data, the figure above shows us that 41.8% are located below the point where the items produce a PSI of 0.7 or higher. Again, note that this figure shows the reliability of the test/scale, not the sample. If you want to add the sample reliability use option samplePSI = TRUE. More details are available in the documentation ?RItif."
  },
  {
    "objectID": "raschrvignette/RaschRvign.html#person-fit",
    "href": "raschrvignette/RaschRvign.html#person-fit",
    "title": "RISEkbmRasch vignette",
    "section": "\n8 Person fit",
    "text": "8 Person fit\nWe can also look at how the respondents fit the Rasch model with these items. By default, RIpfit() outputs a histogram and a hex heatmap with the person infit ZSTD statistic, using +/- 1.96 as cutoff values. This is currently the only person fit method implemented in the RISEkbmRasch package, and the curious analyst is suggested to look at the package PerFit for more tools.\n\nCodeRIpfit(df)\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can export the person fit values to a new variable in the dataframe by specifying output = \"dataframe\", or if you just want the row numbers for respondents with deviant infit values, output = \"rowid\".\nYou can also specify a grouping variable to visualize the person fit for different groups.\n\nCodeRIpfit(df, group = dif.sex, output = \"heatmap\")\n\n\n\n\n\n\n\nPerson fit is a useful way to identify respondents with unexpected response patterns and investigate this further.\n\n8.1 PerFit sample code\nWhile none of the functions in the PerFit package has been implemented in RISEkbmRasch, this is some code to get you started if you are interested in using it. There are multiple methods/functions available for polytomous and dichotomous data, see the package documentation.\nFor this example, we’ll use the non-parametric U3 statistic generalized to polytomous items (Emons, 2008).\n\n\nU3poly\nCutoff information\nFlagged respondents\n\n\n\n\nCodelibrary(PerFit)\npfit_u3poly &lt;- U3poly(matrix = df, \n                      Ncat = 5, # make sure to input number of response categories, not thresholds\n                      IRT.PModel = \"PCM\")\n\n\n\n\n\nCodecutoff(pfit_u3poly)\n\n$Cutoff\n[1] 0.4272\n\n$Cutoff.SE\n[1] 0.0174\n\n$Prop.flagged\n[1] 0.0972\n\n$Tail\n[1] \"upper\"\n\n$Cutoff.CI\n  2.5%  97.5% \n0.3922 0.4720 \n\nattr(,\"class\")\n[1] \"PerFit.cutoff\"\n\n\n\n\n\nCodeflagged.resp(pfit_u3poly) %&gt;% \n  pluck(\"Scores\") %&gt;% \n  as.data.frame() %&gt;% \n  arrange(desc(PFscores))\n\n    FlaggedID It1 It4 It7 It2 It5 It3 It6 PFscores\n1         159   0   0   0   0   0   0   1   1.0000\n2         168   0   0   0   0   0   0   1   1.0000\n3         193   0   0   0   0   0   0   1   1.0000\n4         214   0   0   0   0   0   0   1   1.0000\n5         222   0   0   0   0   0   4   0   1.0000\n6         324   0   0   0   0   0   0   1   1.0000\n7         667   0   0   0   0   0   0   1   1.0000\n8        1014   0   0   0   0   0   4   0   1.0000\n9        1146   0   0   0   0   0   0   1   1.0000\n10       1171   0   0   0   0   0   0   1   1.0000\n11       1609   0   0   0   0   0   0   2   1.0000\n12        555   0   0   0   0   0   3   0   0.9484\n13        782   0   0   0   0   0   3   0   0.9484\n14       1015   0   0   0   0   0   3   0   0.9484\n15        187   0   4   2   4   4   4   4   0.9089\n16       1290   0   1   0   0   0   4   0   0.9020\n17        225   0   0   0   0   0   2   0   0.8939\n18        939   0   0   0   0   0   2   0   0.8939\n19       1364   0   0   0   0   0   2   0   0.8939\n20       1738   0   0   0   0   0   2   0   0.8939\n21       1770   0   0   0   0   0   2   0   0.8939\n22       1021   0   1   0   0   0   0   4   0.8880\n23         26   0   0   0   0   0   1   0   0.8476\n24        596   0   0   0   0   0   1   0   0.8476\n25        902   0   0   0   0   0   1   0   0.8476\n26       1098   0   0   0   0   0   1   0   0.8476\n27       1230   0   0   0   0   0   1   0   0.8476\n28       1418   0   0   0   0   0   1   0   0.8476\n29       1475   0   0   0   0   0   1   0   0.8476\n30       1847   0   0   0   0   0   1   0   0.8476\n31       1036   0   2   0   4   4   0   4   0.8127\n32         44   4   0   4   0   0   4   0   0.7964\n33       1075   0   3   0   4   1   4   4   0.7765\n34       1472   4   0   0   0   0   0   4   0.7624\n35        463   0   0   4   0   0   0   0   0.7439\n36        488   0   0   4   0   0   0   0   0.7439\n37       1421   0   0   4   0   0   0   0   0.7439\n38       1531   4   4   0   4   0   4   0   0.7272\n39        971   0   0   0   0   3   0   0   0.7021\n40       1774   0   0   0   4   4   1   3   0.7009\n41        446   0   4   2   4   4   3   4   0.6770\n42       1673   1   0   0   0   4   0   0   0.6588\n43        814   2   0   0   0   1   4   0   0.6560\n44        701   0   0   0   0   2   0   0   0.6536\n45       1578   0   0   0   0   2   0   0   0.6536\n46        487   0   4   2   4   4   1   4   0.6504\n47       1258   0   0   3   0   0   0   0   0.6198\n48       1681   0   0   3   0   0   0   0   0.6198\n49        571   0   0   0   2   0   0   0   0.6101\n50       1402   0   0   0   2   0   0   0   0.6101\n51       1682   0   0   0   2   0   0   0   0.6101\n52        597   0   4   0   0   0   0   0   0.6095\n53        994   1   0   0   0   4   0   1   0.6088\n54        563   0   2   0   4   0   0   0   0.6067\n55        721   4   0   0   0   0   0   0   0.5996\n56       1159   4   0   0   0   0   0   0   0.5996\n57       1602   4   0   0   0   0   0   0   0.5996\n58       1797   4   0   0   0   0   0   0   0.5996\n59       1170   4   4   4   0   0   0   0   0.5993\n60       1287   4   2   0   4   4   0   0   0.5962\n61       1006   0   3   0   4   4   2   0   0.5930\n62       1383   0   4   1   4   0   3   2   0.5925\n63        541   0   4   4   4   2   2   4   0.5887\n64        356   0   0   0   0   1   0   0   0.5825\n65        470   0   0   0   0   1   0   0   0.5825\n66        567   0   0   0   0   1   0   0   0.5825\n67        623   0   0   0   0   1   0   0   0.5825\n68        659   0   0   0   0   1   0   0   0.5825\n69        710   0   0   0   0   1   0   0   0.5825\n70        987   0   0   0   0   1   0   0   0.5825\n71       1095   0   0   0   0   1   0   0   0.5825\n72       1106   0   0   0   0   1   0   0   0.5825\n73       1268   0   0   0   0   1   0   0   0.5825\n74       1271   0   0   0   0   1   0   0   0.5825\n75       1276   0   0   0   0   1   0   0   0.5825\n76       1480   0   0   0   0   1   0   0   0.5825\n77       1763   0   0   0   0   1   0   0   0.5825\n78        576   0   0   2   0   0   3   0   0.5814\n79        690   3   0   0   3   3   0   4   0.5802\n80        727   3   0   2   0   0   0   4   0.5778\n81        916   0   0   1   0   0   0   3   0.5768\n82        712   3   0   0   0   0   3   0   0.5731\n83        799   1   4   0   4   0   0   0   0.5687\n84        754   0   1   0   0   0   0   3   0.5674\n85        717   4   4   4   4   4   0   0   0.5585\n86        472   1   0   0   1   4   0   0   0.5560\n87        173   3   4   0   4   0   0   0   0.5501\n88        851   0   0   1   0   1   0   3   0.5494\n89        227   0   0   0   0   1   0   1   0.5386\n90        409   0   0   0   0   1   0   1   0.5386\n91       1192   0   1   0   0   0   3   0   0.5360\n92        247   4   0   1   0   0   0   0   0.5295\n93       1758   1   4   0   4   3   3   3   0.5229\n94       1703   0   1   0   0   0   0   2   0.5109\n95        531   4   1   3   0   4   3   3   0.5095\n96        622   0   3   0   0   0   0   0   0.5088\n97        762   0   3   0   0   0   0   0   0.5088\n98        981   4   0   4   3   1   0   0   0.5079\n99        278   1   0   0   2   0   0   3   0.5076\n100       584   0   0   0   1   0   0   1   0.5020\n101      1045   0   0   0   1   0   0   1   0.5020\n102      1191   0   0   0   1   0   0   1   0.5020\n103      1556   0   1   0   1   0   3   0   0.4993\n104       820   2   0   0   0   0   2   3   0.4985\n105       481   1   4   3   2   0   3   4   0.4973\n106        38   4   3   0   0   0   0   0   0.4895\n107       728   3   4   4   1   3   0   4   0.4889\n108        56   0   0   0   1   0   0   0   0.4844\n109       183   0   0   0   1   0   0   0   0.4844\n110       209   0   0   0   1   0   0   0   0.4844\n111       331   0   0   0   1   0   0   0   0.4844\n112       410   0   0   0   1   0   0   0   0.4844\n113       797   0   0   0   1   0   0   0   0.4844\n114       886   0   0   0   1   0   0   0   0.4844\n115      1067   0   0   0   1   0   0   0   0.4844\n116      1269   0   0   0   1   0   0   0   0.4844\n117      1558   0   0   0   1   0   0   0   0.4844\n118      1663   0   0   0   1   0   0   0   0.4844\n119      1680   0   0   0   1   0   0   0   0.4844\n120      1726   0   0   0   1   0   0   0   0.4844\n121       197   0   0   0   0   1   1   0   0.4817\n122       562   1   0   3   0   0   3   0   0.4802\n123       451   3   4   0   0   3   0   3   0.4800\n124      1583   0   0   4   2   3   1   1   0.4791\n125      1214   0   2   2   3   4   2   4   0.4754\n126        73   3   3   0   2   0   4   2   0.4732\n127       702   0   3   0   1   0   3   0   0.4732\n128      1642   4   0   1   0   0   2   0   0.4725\n129       527   0   0   1   0   0   2   0   0.4706\n130       857   0   0   1   0   0   2   0   0.4706\n131      1311   0   0   1   0   0   2   0   0.4706\n132       434   2   0   4   0   1   0   0   0.4691\n133       788   4   2   2   4   1   0   4   0.4680\n134       606   1   2   2   0   0   0   4   0.4663\n135      1601   3   0   0   0   0   3   2   0.4601\n136      1550   3   3   0   3   4   1   4   0.4572\n137        96   3   0   0   0   0   0   0   0.4554\n138       352   3   0   0   0   0   0   0   0.4554\n139       755   3   0   0   0   0   0   0   0.4554\n140       830   3   0   0   0   0   0   0   0.4554\n141      1060   3   0   0   0   0   0   0   0.4554\n142      1374   3   0   0   0   0   0   0   0.4554\n143      1714   3   0   0   0   0   0   0   0.4554\n144      1745   3   0   0   0   0   0   0   0.4554\n145       166   0   1   0   0   0   2   0   0.4551\n146       684   0   0   0   2   3   0   1   0.4546\n147      1019   0   0   0   1   3   0   1   0.4546\n148      1800   1   0   1   0   0   3   0   0.4531\n149         8   0   0   2   0   0   0   0   0.4496\n150        54   0   0   2   0   0   0   0   0.4496\n151        82   0   0   2   0   0   0   0   0.4496\n152       343   0   0   2   0   0   0   0   0.4496\n153       401   0   0   2   0   0   0   0   0.4496\n154       538   0   0   2   0   0   0   0   0.4496\n155       603   0   0   2   0   0   0   0   0.4496\n156       914   0   0   2   0   0   0   0   0.4496\n157      1132   0   0   2   0   0   0   0   0.4496\n158      1144   0   0   2   0   0   0   0   0.4496\n159      1193   0   0   2   0   0   0   0   0.4496\n160      1239   0   0   2   0   0   0   0   0.4496\n161      1493   0   0   2   0   0   0   0   0.4496\n162      1532   0   0   2   0   0   0   0   0.4496\n163      1606   0   0   2   0   0   0   0   0.4496\n164      1747   0   0   2   0   0   0   0   0.4496\n165      1752   0   0   2   0   0   0   0   0.4496\n166      1768   0   0   2   0   0   0   0   0.4496\n167      1822   0   0   2   0   0   0   0   0.4496\n168      1176   0   0   0   1   0   1   0   0.4451\n169        62   1   1   0   0   0   3   0   0.4442\n170      1503   4   4   3   4   0   3   1   0.4432\n171        53   0   1   4   1   1   0   0   0.4428\n172       505   3   4   4   0   1   0   0   0.4424\n173       129   0   0   3   2   0   0   0   0.4398\n174       221   0   4   0   3   1   1   0   0.4395\n175       114   0   0   2   0   3   0   0   0.4386\n176       658   0   0   2   0   3   0   0   0.4386\n177       207   3   0   3   4   4   0   2   0.4385\n178      1447   1   4   0   0   1   0   0   0.4358\n179       959   0   3   3   0   0   0   0   0.4294\n180       428   4   4   0   3   3   2   4   0.4281\n181       500   2   4   0   4   3   3   0   0.4243\n182      1666   3   1   4   0   3   0   0   0.4238\n183       115   0   1   0   1   1   3   0   0.4224\n184       394   0   2   0   3   2   3   0   0.4143\n185       803   1   2   4   3   0   0   0   0.4134\n186      1661   4   4   0   3   2   0   1   0.4134\n187       142   2   2   1   1   0   4   0   0.4080\n188       344   2   2   1   1   0   4   0   0.4080\n189      1810   3   0   0   2   3   3   0   0.4071\n190      1231   4   4   2   0   0   2   0   0.4070\n191      1341   0   2   0   3   0   0   2   0.4030\n192       243   0   0   1   0   0   0   1   0.4025\n193      1442   0   0   1   0   0   0   1   0.4025\n194      1655   0   0   1   0   0   0   1   0.4025\n195       216   3   0   3   0   0   0   0   0.4015\n196       298   3   0   3   0   0   0   0   0.4015\n197       697   4   2   2   4   4   4   2   0.4002\n198      1510   1   0   0   3   3   0   0   0.3997\n199       861   0   0   0   1   2   0   0   0.3964\n200       719   4   4   1   3   0   1   0   0.3961\n201       263   0   0   1   0   3   0   0   0.3955\n202       119   3   1   0   2   4   0   0   0.3947\n203      1620   4   0   2   0   0   2   0   0.3931\n204       416   2   0   0   0   3   0   0   0.3907\n205       310   0   0   2   0   0   0   1   0.3903\n206       327   1   1   0   1   0   0   3   0.3896\n207       595   2   2   3   0   1   4   0   0.3890\n208       288   0   3   0   0   2   0   0   0.3887\n209      1031   0   1   0   3   0   1   0   0.3879\n210      1792   4   4   2   4   2   4   1   0.3879\n211       703   0   0   0   1   2   1   2   0.3866\n212      1584   0   1   0   0   3   0   0   0.3861\n213      1010   2   2   1   0   3   0   4   0.3849\n214      1736   1   3   4   4   3   0   2   0.3843\n215       934   3   0   0   3   3   0   0   0.3837\n216      1756   3   4   0   4   1   1   1   0.3833\n217      1565   0   3   4   1   3   1   0   0.3828\n218      1437   1   1   3   2   1   4   2   0.3800\n219      1008   1   4   2   4   3   0   3   0.3778\n220       184   0   2   0   0   0   0   0   0.3776\n221       294   0   2   0   0   0   0   0   0.3776\n222       417   0   2   0   0   0   0   0   0.3776\n223       722   0   2   0   0   0   0   0   0.3776\n224       753   0   2   0   0   0   0   0   0.3776\n225       784   0   2   0   0   0   0   0   0.3776\n226       867   0   2   0   0   0   0   0   0.3776\n227      1030   0   2   0   0   0   0   0   0.3776\n228      1263   0   2   0   0   0   0   0   0.3776\n229      1295   0   2   0   0   0   0   0   0.3776\n230      1545   0   2   0   0   0   0   0   0.3776\n231       588   0   3   0   2   0   0   0   0.3755\n232       130   0   1   0   0   0   0   1   0.3731\n233       325   0   3   0   3   2   0   2   0.3731\n234       391   0   1   0   0   0   0   1   0.3731\n235      1228   0   2   3   0   0   0   0   0.3689\n236       689   4   2   4   4   4   1   2   0.3642\n237      1409   0   0   2   0   0   2   0   0.3632\n238      1804   3   0   0   0   1   2   0   0.3610\n239       179   0   3   4   3   3   1   1   0.3602\n240       421   0   1   3   0   0   1   2   0.3598\n241       437   0   3   3   0   0   1   0   0.3588\n242      1013   1   2   4   0   2   0   0   0.3584\n243       346   0   1   0   3   1   0   0   0.3577\n244      1528   1   2   0   4   2   0   0   0.3566\n245        29   4   3   3   3   4   0   0   0.3557\n246      1754   0   3   0   2   2   3   1   0.3545\n247       188   2   4   4   4   4   1   2   0.3524\n248      1694   3   4   0   2   3   3   0   0.3519\n249      1554   2   0   0   0   3   1   0   0.3518\n\n\n\n\n\nThe dataframe shown under the tab Flagged respondents above contains a variable named FlaggedID which represents the row id’s. This variable is useful if one wants to filter out respondents with deviant response patterns (person misfit). There are indications that persons with misfit may affect results of Andersen’s LR-test for DIF (Artner, 2016).\n\n8.2 Item fit without aberrant responses\nWe can remove the misfitting persons to see how that affects item fit. Let’s also compare with the misfitting respondents identified by RIpfit().\n\nCodemisfits &lt;- flagged.resp(pfit_u3poly) %&gt;% \n  pluck(\"Scores\") %&gt;% \n  as.data.frame() %&gt;% \n  pull(FlaggedID)\n\nmisfits2 &lt;- RIpfit(df, output = \"rowid\")\n\n\n\n\nAll respondents\nU3 misfit removed\nZSTD misfit removed\n\n\n\n\nCodeRIitemfit(df, simcut = simfit3)\n\n\n\n Item \n    InfitMSQ \n    Infit thresholds \n    OutfitMSQ \n    Outfit thresholds \n    Infit diff \n    Outfit diff \n  \n\n\n PANAS_11 \n    1.127 \n    [0.923, 1.075] \n    1.152 \n    [0.925, 1.076] \n    0.052 \n    0.076 \n  \n\n PANAS_12 \n    0.783 \n    [0.923, 1.069] \n    0.783 \n    [0.899, 1.095] \n    0.14 \n    0.116 \n  \n\n PANAS_13 \n    1.047 \n    [0.924, 1.074] \n    1.127 \n    [0.894, 1.129] \n    no misfit \n    no misfit \n  \n\n PANAS_14 \n    0.952 \n    [0.923, 1.072] \n    0.991 \n    [0.924, 1.078] \n    no misfit \n    no misfit \n  \n\n PANAS_16 \n    0.939 \n    [0.923, 1.08] \n    0.968 \n    [0.901, 1.104] \n    no misfit \n    no misfit \n  \n\n PANAS_17 \n    1.002 \n    [0.914, 1.081] \n    0.981 \n    [0.869, 1.132] \n    no misfit \n    no misfit \n  \n\n PANAS_20 \n    1.162 \n    [0.931, 1.071] \n    1.201 \n    [0.931, 1.078] \n    0.091 \n    0.123 \n  \n\n\nNote: \n\n MSQ values based on conditional calculations (n = 1851).                                Simulation based thresholds based on 1000 simulated datasets.\n\n\n\n\n\n\n\nCodeRIitemfit(df[-misfits,], simcut = simfit3)\n\n\n\n Item \n    InfitMSQ \n    Infit thresholds \n    OutfitMSQ \n    Outfit thresholds \n    Infit diff \n    Outfit diff \n  \n\n\n PANAS_11 \n    1.136 \n    [0.923, 1.075] \n    1.144 \n    [0.925, 1.076] \n    0.061 \n    0.068 \n  \n\n PANAS_12 \n    0.81 \n    [0.923, 1.069] \n    0.759 \n    [0.899, 1.095] \n    0.113 \n    0.140 \n  \n\n PANAS_13 \n    0.964 \n    [0.924, 1.074] \n    0.857 \n    [0.894, 1.129] \n    no misfit \n    0.037 \n  \n\n PANAS_14 \n    1.042 \n    [0.923, 1.072] \n    1.083 \n    [0.924, 1.078] \n    no misfit \n    0.005 \n  \n\n PANAS_16 \n    0.943 \n    [0.923, 1.08] \n    0.892 \n    [0.901, 1.104] \n    no misfit \n    0.009 \n  \n\n PANAS_17 \n    1.02 \n    [0.914, 1.081] \n    0.862 \n    [0.869, 1.132] \n    no misfit \n    0.007 \n  \n\n PANAS_20 \n    1.133 \n    [0.931, 1.071] \n    1.147 \n    [0.931, 1.078] \n    0.062 \n    0.069 \n  \n\n\nNote: \n\n MSQ values based on conditional calculations (n = 1633).                                Simulation based thresholds based on 1000 simulated datasets.\n\n\n\n\n\n\n\nCodeRIitemfit(df[-misfits2,], simcut = simfit3)\n\n\n\n Item \n    InfitMSQ \n    Infit thresholds \n    OutfitMSQ \n    Outfit thresholds \n    Infit diff \n    Outfit diff \n  \n\n\n PANAS_11 \n    1.086 \n    [0.923, 1.075] \n    1.093 \n    [0.925, 1.076] \n    0.011 \n    0.017 \n  \n\n PANAS_12 \n    0.8 \n    [0.923, 1.069] \n    0.796 \n    [0.899, 1.095] \n    0.123 \n    0.103 \n  \n\n PANAS_13 \n    1.027 \n    [0.924, 1.074] \n    1.042 \n    [0.894, 1.129] \n    no misfit \n    no misfit \n  \n\n PANAS_14 \n    0.977 \n    [0.923, 1.072] \n    1.006 \n    [0.924, 1.078] \n    no misfit \n    no misfit \n  \n\n PANAS_16 \n    0.943 \n    [0.923, 1.08] \n    0.971 \n    [0.901, 1.104] \n    no misfit \n    no misfit \n  \n\n PANAS_17 \n    1.02 \n    [0.914, 1.081] \n    0.993 \n    [0.869, 1.132] \n    no misfit \n    no misfit \n  \n\n PANAS_20 \n    1.159 \n    [0.931, 1.071] \n    1.186 \n    [0.931, 1.078] \n    0.088 \n    0.108 \n  \n\n\nNote: \n\n MSQ values based on conditional calculations (n = 1695).                                Simulation based thresholds based on 1000 simulated datasets."
  },
  {
    "objectID": "raschrvignette/RaschRvign.html#item-parameters",
    "href": "raschrvignette/RaschRvign.html#item-parameters",
    "title": "RISEkbmRasch vignette",
    "section": "\n9 Item parameters",
    "text": "9 Item parameters\nTo allow others (and oneself) to use the item parameters estimated for estimation of person locations/thetas, we should make the item parameters available. The function will also write a csv-file with the item threshold locations. Estimations of person locations/thetas can be done with the thetaEst() function from the catR package. This is implemented in the function RIestThetasOLD(), see below for details.\nFirst, we’ll output the parameters into a table.\n\nCodeRIitemparams(df)\n\n\n\n   \n    Threshold 1 \n    Threshold 2 \n    Threshold 3 \n    Threshold 4 \n    Item location \n  \n\n\n PANAS_11 \n    -1.63 \n    -0.67 \n    -0.22 \n    1.21 \n    -0.33 \n  \n\n PANAS_12 \n    -0.80 \n    -0.39 \n    0.06 \n    0.89 \n    -0.06 \n  \n\n PANAS_13 \n    -0.29 \n    -0.15 \n    0.56 \n    1.53 \n    0.42 \n  \n\n PANAS_14 \n    -1.38 \n    -0.59 \n    -0.16 \n    0.87 \n    -0.32 \n  \n\n PANAS_16 \n    -0.59 \n    -0.44 \n    -0.06 \n    1.08 \n    0 \n  \n\n PANAS_17 \n    -0.06 \n    0.01 \n    0.48 \n    0.93 \n    0.34 \n  \n\n PANAS_20 \n    -1.27 \n    -0.61 \n    0.35 \n    1.32 \n    -0.05 \n  \n\n\nNote: \n\n Item location is the average of the thresholds for each item.\n\n\n\n\nThe parameters can also be output to a dataframe or a file, using the option output = \"dataframe\" or output = \"file\"."
  },
  {
    "objectID": "raschrvignette/RaschRvign.html#ordinal-sum-score-to-interval-score",
    "href": "raschrvignette/RaschRvign.html#ordinal-sum-score-to-interval-score",
    "title": "RISEkbmRasch vignette",
    "section": "\n10 Ordinal sum score to interval score",
    "text": "10 Ordinal sum score to interval score\nThis table shows the corresponding “raw” ordinal sum score values and logit scores, with standard errors for each logit value. Interval scores are estimated using WL based on a simulated dataset using the item parameters estimated from the input dataset. The choice of WL as default is due to the lower bias compared to ML estimation (Warm, 1989).\n(An option will hopefully be added at some point to create this table based on only item parameters.)\n\nCodeRIscoreSE(df)\n\n\n\n Ordinal sum score \n    Logit score \n    Logit std.error \n  \n\n\n 0 \n    -3.642 \n    0.620 \n  \n\n 1 \n    -2.543 \n    0.716 \n  \n\n 2 \n    -2.032 \n    0.653 \n  \n\n 3 \n    -1.693 \n    0.578 \n  \n\n 4 \n    -1.437 \n    0.515 \n  \n\n 5 \n    -1.228 \n    0.468 \n  \n\n 6 \n    -1.050 \n    0.432 \n  \n\n 7 \n    -0.893 \n    0.406 \n  \n\n 8 \n    -0.750 \n    0.386 \n  \n\n 9 \n    -0.618 \n    0.371 \n  \n\n 10 \n    -0.493 \n    0.361 \n  \n\n 11 \n    -0.373 \n    0.353 \n  \n\n 12 \n    -0.258 \n    0.348 \n  \n\n 13 \n    -0.144 \n    0.346 \n  \n\n 14 \n    -0.031 \n    0.346 \n  \n\n 15 \n    0.083 \n    0.348 \n  \n\n 16 \n    0.198 \n    0.352 \n  \n\n 17 \n    0.317 \n    0.359 \n  \n\n 18 \n    0.441 \n    0.368 \n  \n\n 19 \n    0.572 \n    0.381 \n  \n\n 20 \n    0.712 \n    0.397 \n  \n\n 21 \n    0.866 \n    0.418 \n  \n\n 22 \n    1.037 \n    0.447 \n  \n\n 23 \n    1.233 \n    0.484 \n  \n\n 24 \n    1.464 \n    0.534 \n  \n\n 25 \n    1.747 \n    0.601 \n  \n\n 26 \n    2.118 \n    0.681 \n  \n\n 27 \n    2.666 \n    0.745 \n  \n\n 28 \n    3.804 \n    0.638 \n  \n\n\n\n\n\n10.1 Ordinal/interval figure\nThe figure below can also be generated to illustrate the relationship between ordinal sum score and logit interval score. The errorbars default to show the standard error at each point, multiplied by 1.96.\n\nCodeRIscoreSE(df, output = \"figure\")\n\n\n\n\n\n\n\n\n10.2 Estimating interval level person scores\nBased on the Rasch analysis output of item parameters, we can estimate each individuals location or score (also known as “theta”). RIestThetas() by default uses WLE estimation based on item parameters from a partial credit model (PCM) and outputs a dataframe with person locations (WLE) and measurement error (SEM) on the logit scale.\n\nCodethetas &lt;- RIestThetas(df)\n\nhead(thetas)\n\n         WLE       SEM\n1 -2.5430672 0.7160122\n2 -2.0319918 0.6533338\n3 -0.1439296 0.3460439\n4 -3.6420132 0.6202853\n5 -2.0319918 0.6533338\n6  0.1980813 0.3520345\n\n\nEach individual has a standard error of measurement (SEM) associated with their estimated location/score. This is included in the output of the RIestThetas() function as the SEM variable, as seen above. We can review the distribution of measurement error with a figure.\nWe can take a look at the distribution of person locations (thetas) using a histogram.\n\nCodehist(thetas$WLE, \n     col = \"#009ca6\", \n     main = \"Histogram of person locations (thetas)\", \n     breaks = 20)\n\n\n\n\n\n\n\nRIestThetasOLD() can be used with a pre-specified item (threshold) location matrix. The choice of WL as default is due to the lower bias compared to ML estimation (Warm, 1989). Similarly to RIscoreSE() you can (and may indeed need to) change the range of logit scores, using the option theta_range. The default is c(-7,7), which should hopefully work in most circumstances.\nIf you would like to use an existing item threshold location matrix, this code may be helpful:\n\nCodeitemParameters &lt;- read_csv(\"itemParameters.csv\") %&gt;% \n  as.matrix()\nitemParameters\n\n     Threshold 1 Threshold 2 Threshold 3 Threshold 4\n[1,]     -1.2382     -0.3288      0.0666      1.4649\n[2,]      0.0623      0.1480      0.8241      1.7680\n[3,]     -0.9915     -0.2566      0.1231      1.1222\n[4,]     -0.2179     -0.1217      0.2099      1.3248\n[5,]      0.2868      0.3061      0.7319      1.1655\n[6,]     -0.8929     -0.2860      0.6297      1.5673\n\n\nAs you can see, this is a matrix object (not a dataframe), with each item as a row, and the threshold locations as columns."
  },
  {
    "objectID": "raschrvignette/RaschRvign.html#figure-design",
    "href": "raschrvignette/RaschRvign.html#figure-design",
    "title": "RISEkbmRasch vignette",
    "section": "\n11 Figure design",
    "text": "11 Figure design\nMost of the figures created by the functions can be styled (colors, fonts, etc) by adding theme settings to them. You can use the standard ggplot function theme() and related theme-functions. As usual it is possible to “stack” theme functions, as seen in the example below.\nYou can also change coloring, axis limits/breaks, etc, just by adding ggplot options with a + sign.\nA custom theme function, theme_rise(), is included in the RISEkbmRasch package. It might be easier to use if you are not familiar with theme().\nFor instance, you might like to change the font to “Lato” for the item hierarchy figure, and make the background transparent.\n\nCodeRIitemHierarchy(df) +\n  theme_minimal() + # first apply the minimal theme to make the background transparent\n  theme_rise(fontfamily = \"Lato\") # then apply theme_rise, which simplifies making changes to all plot elements\n\n\n\n\n\n\n\nAs of package version 0.1.30.0, the RItargeting() function allows more flexibility in styling too, by having an option to return a list object with the three separate plots. See the NEWS file for more details. Since the RItargeting() function uses the patchwork library to combine plots, you can also make use of the many functions that patchwork includes. For instance, you can set a title with a specific theme:\n\nCodeRItargeting(df) + plot_annotation(title = \"Targeting\", theme = theme_rise(fontfamily = \"Arial\"))\n\n\n\n\n\n\n\nIn order to change font for text inside plots (such as “t1” for thresholds) you will need to add an additional line of code.\nupdate_geom_defaults(\"text\", list(family = \"Lato\"))\nPlease note that the line of code above updates the default settings for geom_text() for the whole session. Also, some functions, such as RIloadLoc(), make use of geom_text_repel(), for which you would need to change the code above from “text” to “text_repel”.\nA simple way to only change font family and font size would be to use theme_minimal(base_family = \"Calibri\", base_size = 14). Please see the reference page for default ggplot themes for alternatives to theme_minimal()."
  },
  {
    "objectID": "raschrvignette/RaschRvign.html#software-used",
    "href": "raschrvignette/RaschRvign.html#software-used",
    "title": "RISEkbmRasch vignette",
    "section": "\n13 Software used",
    "text": "13 Software used\nThe grateful package is a nice way to give credit to the packages used in making the analysis. The package can create both a bibliography file and a table object, which is handy for automatically creating a reference list based on the packages used (or at least explicitly loaded).\n\nCodelibrary(grateful)\npkgs &lt;- cite_packages(cite.tidyverse = TRUE, \n                      output = \"table\",\n                      bib.file = \"grateful-refs.bib\",\n                      include.RStudio = TRUE,\n                      out.dir = getwd())\n# If kbl() is used to generate this table, the references will not be added to the Reference list.\nformattable(pkgs, \n            table.attr = 'class=\\\"table table-striped\\\" style=\"font-size: 13px; font-family: Lato; width: 80%\"')\n\n\n\n\n\nPackage\n\n\nVersion\n\n\nCitation\n\n\n\n\n\nbase\n\n\n4.2.3\n\n\nR Core Team (2023)\n\n\n\n\ncar\n\n\n3.1.2\n\n\nFox & Weisberg (2019)\n\n\n\n\neRm\n\n\n1.0.4\n\n\nMair & Hatzinger (2007b); Mair & Hatzinger (2007a); Hatzinger & Rusch (2009); Rusch et al. (2013); Koller et al. (2015); Debelak & Koller (2019)\n\n\n\n\nforeach\n\n\n1.5.2\n\n\nMicrosoft & Weston (2022)\n\n\n\n\nformattable\n\n\n0.2.1\n\n\nRen & Russell (2021)\n\n\n\n\nfurrr\n\n\n0.3.1\n\n\nVaughan & Dancho (2022)\n\n\n\n\nggrepel\n\n\n0.9.4\n\n\nSlowikowski (2023)\n\n\n\n\nglue\n\n\n1.6.2\n\n\nHester & Bryan (2022)\n\n\n\n\nkableExtra\n\n\n1.3.4\n\n\nZhu (2021)\n\n\n\n\nknitr\n\n\n1.42\n\n\nXie (2014); Xie (2015); Xie (2023)\n\n\n\n\nmatrixStats\n\n\n0.63.0\n\n\nBengtsson (2022)\n\n\n\n\nmirt\n\n\n1.41\n\n\nChalmers (2012)\n\n\n\n\npatchwork\n\n\n1.1.3\n\n\nPedersen (2023)\n\n\n\n\npsych\n\n\n2.3.6\n\n\nWilliam Revelle (2023)\n\n\n\n\npsychotree\n\n\n0.16.0\n\n\nTrepte & Verbeet (2010); Strobl et al. (2011); Strobl et al. (2015a); Komboz et al. (2018); Wickelmaier & Zeileis (2018)\n\n\n\n\nreshape\n\n\n0.8.9\n\n\nWickham (2007)\n\n\n\n\nRISEkbmRasch\n\n\n0.1.30.2\n\n\nJohansson (2023)\n\n\n\n\nrmarkdown\n\n\n2.22\n\n\nXie et al. (2018); Xie et al. (2020); Allaire et al. (2023)\n\n\n\n\nTAM\n\n\n4.1.4\n\n\n@\n\n\n\n\ntidyverse\n\n\n2.0.0\n\n\nWickham et al. (2019)"
  },
  {
    "objectID": "raschrvignette/RaschRvign.html#additional-credits",
    "href": "raschrvignette/RaschRvign.html#additional-credits",
    "title": "RISEkbmRasch vignette",
    "section": "\n13 Additional credits",
    "text": "13 Additional credits\nThanks to my colleagues at RISE for providing feedback and testing the package on Windows and MacOS platforms. Also, thanks to Mike Linacre and Jeanette Melin for providing useful feedback to improve this vignette."
  },
  {
    "objectID": "powerviz.html",
    "href": "powerviz.html",
    "title": "Power analysis for multilevel models",
    "section": "",
    "text": "I recently needed to do a power analysis for a longitudinal study, and since I always document my explorative work in a Quarto file it seemed reasonable to take a few minutes to share my experiences.\nThe starting point for me was the “Basic example” made by the author of the powerlmm package.\nYou may need to install the package from the GitHub website:\nCodelibrary(powerlmm)\nlibrary(tidyverse)\n\n# define ggplot theme\ntheme_rise &lt;- function(fontfamily = \"Lato\", axissize = 13, titlesize = 15,\n                       margins = 12, axisface = \"plain\", stripsize = 12,\n                       panelDist = 0.6, legendSize = 11, legendTsize = 12) {\n  theme_minimal() +\n  theme(\n    text = element_text(family = fontfamily),\n    axis.title.x = element_text(\n      margin = margin(t = margins),\n      size = axissize\n    ),\n    axis.title.y = element_text(\n      margin = margin(r = margins),\n      size = axissize\n    ),\n    plot.title = element_text(\n      face = \"bold\",\n      size = titlesize\n    ),\n    axis.title = element_text(\n      face = axisface\n    ),\n    plot.caption = element_text(\n      face = \"italic\"\n    ),\n    legend.text = element_text(family = fontfamily, size = legendSize),\n    legend.title = element_text(family = fontfamily, size = legendTsize),\n    legend.background = element_rect(color = \"lightgrey\"),\n    strip.text = element_text(size = stripsize),\n    strip.background = element_rect(color = \"lightgrey\"),\n    panel.spacing = unit(panelDist, \"cm\", data = NULL)\n  )\n}\nI made some changes in the example regarding time points, clusters and icc’s. Below is a test run for one combination of parameter settings.\nCode# dropout per treatment group\nd &lt;- per_treatment(control = dropout_weibull(0.25, 1),\n              treatment = dropout_weibull(0.25, 1))\n# Setup design\np &lt;- study_parameters(n1 = 5, # time points\n                      n2 = 10, # subjects per cluster\n                      n3 = 4, # clusters per treatment arm\n                      icc_pre_subject = 0.5,\n                      icc_pre_cluster = 0.2,\n                      icc_slope = 0.05,\n                      var_ratio = 0.02,\n                      dropout = d,\n                      cohend = -0.8)\n# Power\npowerAnalysis &lt;- get_power(p)\n\npowerAnalysis$power\n\n[1] 0.7626795"
  },
  {
    "objectID": "powerviz.html#creating-a-function",
    "href": "powerviz.html#creating-a-function",
    "title": "Power analysis for multilevel models",
    "section": "\n1 Creating a function",
    "text": "1 Creating a function\nWe want to be able to vary some of the parameters and compare the resulting power analysis output.\nFor this example, we will create a function that allows us to vary three of the input parameters:\n\nthe number of participants per cluster\nattrition/dropout rate\neffect size\n\n\nCodepowerFunc &lt;- function(samplesize = 15, dropoutrate = 0.25, effectsize = -0.8) {\n  d &lt;- per_treatment(\n    control = dropout_weibull(dropoutrate, 1),\n    treatment = dropout_weibull(dropoutrate, 1)\n  )\n\n  p &lt;- study_parameters(\n    n1 = 5, # time points\n    n2 = samplesize, # subjects per cluster\n    n3 = 4, # clusters per treatment arm\n    icc_pre_subject = 0.5,\n    icc_pre_cluster = 0.2,\n    icc_slope = 0.05,\n    var_ratio = 0.02,\n    dropout = d,\n    cohend = effectsize\n  )\n  paout &lt;- get_power(p)\n  return(paout$power)\n}\n\n\nLet’s test the function.\n\nCodepowerFunc()\n\n[1] 0.8937192"
  },
  {
    "objectID": "powerviz.html#specifying-parameter-variations",
    "href": "powerviz.html#specifying-parameter-variations",
    "title": "Power analysis for multilevel models",
    "section": "\n2 Specifying parameter variations",
    "text": "2 Specifying parameter variations\nNext, we will define variables with the parameter variations we want to look at.\n\nCode# set sample sizes\nsampleSizes &lt;- c(10, 12, 14, 16, 18, 20)\n# set dropout rates\ndropoutRates &lt;- c(0.20, 0.25, 0.30)\n# set effect sizes\neffectSizes &lt;- c(-0.6, -0.7, -0.8)\n\n\nAnd now we utilize the magic of expand_grid() to create a dataframe with all combinations of the three variables.\n\nCode# make a dataframe with all combinations\ncombinations &lt;- expand_grid(sampleSizes, dropoutRates, effectSizes)"
  },
  {
    "objectID": "powerviz.html#power-analysis",
    "href": "powerviz.html#power-analysis",
    "title": "Power analysis for multilevel models",
    "section": "\n3 Power analysis",
    "text": "3 Power analysis\nWe’ll make use of pmap() from the purrr:map() family since we need to input more than two variables.\n\nCode# use pmap to iterate over all combinations\npowerList &lt;- pmap(\n  list(\n    combinations$sampleSizes,\n    combinations$dropoutRates,\n    combinations$effectSizes\n  ),\n  powerFunc\n) %&gt;%\n  # set readable names for each output list object, to later separate into variables\n  set_names(paste0(\n    combinations$sampleSizes, \"_\",\n    combinations$dropoutRates, \"_\",\n    combinations$effectSizes\n  ))\n\n\nThe names we set at the end of the chunk above will help us to create separate variables next.\n\nCode# combine into dataframe for visualization\ndf.power &lt;- powerList %&gt;%\n  bind_rows() %&gt;%\n  t() %&gt;%\n  as.data.frame() %&gt;%\n  rownames_to_column(\"split_this\") %&gt;%\n  rename(power = V1) %&gt;%\n  separate(split_this,\n    into = c(\"samplesize\", \"dropoutrate\", \"effectsize\"),\n    sep = \"_\"\n  ) %&gt;%\n  mutate(across(everything(), ~ as.numeric(.x)))\n\nglimpse(df.power)\n\nRows: 54\nColumns: 4\n$ samplesize  &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 12, 12, 12, 12, 12, 12…\n$ dropoutrate &lt;dbl&gt; 0.20, 0.20, 0.20, 0.25, 0.25, 0.25, 0.30, 0.30, 0.30, 0.20…\n$ effectsize  &lt;dbl&gt; -0.6, -0.7, -0.8, -0.6, -0.7, -0.8, -0.6, -0.7, -0.8, -0.6…\n$ power       &lt;dbl&gt; 0.5415203, 0.6703958, 0.7798685, 0.5241826, 0.6515921, 0.7…"
  },
  {
    "objectID": "powerviz.html#visualization",
    "href": "powerviz.html#visualization",
    "title": "Power analysis for multilevel models",
    "section": "\n4 Visualization",
    "text": "4 Visualization\n\nCodedf.power %&gt;%\n  mutate(dropoutrate = factor(dropoutrate,\n                              labels = c(\"20%\",\"25%\",\"30%\")),\n         effectsize = fct_rev(factor(effectsize))) %&gt;%\n  \n  ggplot(aes(\n    x = samplesize,\n    y = power,\n    color = dropoutrate,\n    group = dropoutrate\n  )) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = sampleSizes) +\n  scale_y_continuous(\n    limits = c(0, 1),\n    breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1)\n  ) +\n  labs(\n    x = \"Cluster sample size\",\n    y = \"Statistical power\",\n    title = \"Power analysis\",\n    subtitle = \"For different effect sizes (Cohen's d)\",\n    caption = \"Note. There are four clusters per treatment arm and five time points.\"\n  ) +\n  theme_minimal(\n    base_family = \"Lato\",\n    base_size = 14\n  ) +\n  facet_wrap(~effectsize) +\n  geom_hline(\n    yintercept = 0.8,\n    linetype = 2\n  ) +\n  scale_color_viridis_d('Dropout rate') +\n  theme_rise()\n\n\n\n\n\n\n\nI added a reference line for power = 0.80."
  },
  {
    "objectID": "datawrangling.html",
    "href": "datawrangling.html",
    "title": "Data wrangling for psychometrics in R",
    "section": "",
    "text": "While the RISEkbmRasch package simplifies the process of doing Rasch analysis in R, users still need to be able to import and often make modifications to their data. This demands some knowledge in R data wrangling. For a comprehensive treatment of this topic, please see the “R for data science” book. This guide focuses on common data wrangling issues that occur in psychometric analyses.\nI will rely heavily on library(tidyverse) functions in most examples.\nThis page will be updated intermittently. The planned content includes:"
  },
  {
    "objectID": "datawrangling.html#dividing-a-dataset",
    "href": "datawrangling.html#dividing-a-dataset",
    "title": "Data wrangling for psychometrics in R",
    "section": "2 Dividing a dataset",
    "text": "2 Dividing a dataset"
  },
  {
    "objectID": "datawrangling.html#recoding-response-categories",
    "href": "datawrangling.html#recoding-response-categories",
    "title": "Data wrangling for psychometrics in R",
    "section": "3 Recoding response categories",
    "text": "3 Recoding response categories\nMany options are available. I have settled on primarily using car::recode() from library(car) since I find the syntax to be logical and consistent. Another option to consider is dplyr::recode().\nThe basic syntax of car::recode() (henceforth referred to as only recode()) is this:\nrecode(variable_to_recode, \"newvalue1=oldvalue1;newvalue2=oldvalue2\", as.factor = FALSE/TRUE)\nAs you can see, semi-colon ; is used to separate recodings. When numbers are recoded, you just write them out as 1=0. When characters are involved, you need the single quote symbol to enclose the character string, i.e 'Never'=0 for recoding to numerics (which also necessitates the option as.factor = FALSE if you want the recoded variable to be numeric), or 'Never'='Nevver' when you need to correct misspelled response options.\n\n\n\n\n\n\nTip\n\n\n\nRemember to define your preferred recoding function in your script to avoid headaches due to unexpected error messages. This is done by using the assignment operator &lt;-. Example below.\nrecode &lt;- car::recode\n\n\nThere are some more or less clever ways to use recode(). You can simply copy&paste code for each variable, such as:\ndf$q1 &lt;- recode(df$q1, \"0=1;2=1;3=2\", as.factor = FALSE)\ndf$q2 &lt;- recode(df$q2, \"0=1;2=1;3=2\", as.factor = FALSE)\ndf$q3 &lt;- recode(df$q3, \"0=1;2=1;3=2\", as.factor = FALSE)\ndf$q4 &lt;- recode(df$q4, \"0=1;2=1;3=2\", as.factor = FALSE)\ndf$q5 &lt;- recode(df$q5, \"0=1;2=1;3=2\", as.factor = FALSE)\nSuch an approach might actually be sensible if each variable needed different recodings. But when you want to make the same changes to many variables, there are of course more efficient strategies. The code above could be rewritten as:\ndf %&gt;% \n  mutate(across(q1:q5, ~ car::recode(.x, \"0=1;2=1;3=2\", as.factor = FALSE)))\nOr, in this case, where we only want to recode our scale from the range of 1-3 to 0-2, i.e. subtract one:\ndf %&gt;% \n  mutate(across(q1:q5, ~ .x - 1))\nThe syntax in these two examples is related to how tidyverse uses unnamed functions by the combination of ~ and .x, where the latter becomes a placeholder for the variables defined in the first term of across().\nBelow is another example, where we have multiple cell contents that we want to make into NA value to ensure that R interprets them as missing data. We want to recode three different things:\n\nall the numbers from 990 to 999 (usually a way to differentiate between types of missing data)\nblank cells\n“Don’t know” responses\n\ndf$q45 &lt;- recode(df$q45,\"990:999=NA;''=NA;'Don't know'=NA\")\nThe : means that all numbers from 990 to 999 will be recoded into NA."
  },
  {
    "objectID": "datawrangling.html#item-split",
    "href": "datawrangling.html#item-split",
    "title": "Data wrangling for psychometrics in R",
    "section": "4 Item split",
    "text": "4 Item split\nIt can be desirable to split an item due to issues with DIF. This refers to taking a variable and creating two (or more) replacement variables, one for each demographic group. For each variable, data will be missing for the other group. Often this is relevant for gender DIF, which we will use in this example.\nThis example assumes that there is a (DIF) vector variable dif.gender with the gender data, which has the same length as the number of rows in the dataset df. We’ll create a new dataframe to store the dataset with the item split. Item q10 is the one we want to split.\ndf.q10split &lt;- df %&gt;% \n  add_column(gender = dif.gender) %&gt;% \n  mutate(q10f = if_else(gender == \"Female\", q10, NA), # create variable q10f when gender is \"Female\"\n         q10m = if_else(gender == \"Male\", q10, NA)\n         ) %&gt;% \n  select(!gender) %&gt;% # remove gender and q10 variables from the dataset\n  select(!q10)\n\n# check the data\nRItileplot(df.q10split)\nThe if_else() function used within mutate() has three inputs/options in the example above:\n\ncondition (logical statement)\nassignment if the condition true\nassignment if false"
  },
  {
    "objectID": "datawrangling.html#item-merge",
    "href": "datawrangling.html#item-merge",
    "title": "Data wrangling for psychometrics in R",
    "section": "5 Item merge",
    "text": "5 Item merge\nSometimes it is desirable to merge two items into one. This is often done when there is a high residual correlation between two items. This is called a testlet. The items are merged into a new variable, and the original items are removed from the dataset.\nIt is usually a good idea to create a new dataframe with the merged variable, in case you need to go back to the original dataset.\ndf2 &lt;- df %&gt;% \n  mutate(sdq2_15 = sdq2 + sdq15) %&gt;% # create variable by adding them\n  select(!sdq2) %&gt;% \n  select(!sdq15)\nThen you should check the ICC curves for the merged item:\nRIitemCats(df2, item = \"sdq2_15\")"
  },
  {
    "objectID": "datawrangling.html#links",
    "href": "datawrangling.html#links",
    "title": "Data wrangling for psychometrics in R",
    "section": "7 Links",
    "text": "7 Links\nhttps://github.com/Cghlewis/data-wrangling-functions/wiki"
  },
  {
    "objectID": "datawrangling.html#checking-response-distribution-prior-to-dif-analysis",
    "href": "datawrangling.html#checking-response-distribution-prior-to-dif-analysis",
    "title": "Data wrangling for psychometrics in R",
    "section": "6 Checking response distribution prior to DIF analysis",
    "text": "6 Checking response distribution prior to DIF analysis\nThis example assumes that you have previously created a DIF variable (vector) for gender with two groups. The variable is a factor with the labels “Female” and “Male”.\nThe reason for doing this is making sure that there are no empty cells (particularly in lower response categories) in either group prior to running the DIF analysis, since this could lead to DIF being indicated incorrectly.\ndifGenderTileplots &lt;- df %&gt;% \n  add_column(gender = dif.gender) %&gt;% \n  split(.$gender) %&gt;%\n  map(~ RItileplot(.x %&gt;% select(!gender)) + labs(title = .x$gender))\n  \nlibrary(patchwork)\ndifGenderTileplots$Female + difGenderTileplots$Male\nThe last part will make the tile plots show up side by side, labeled with the gender variable as it is coded in the dataset. You will need to adapt the code to the factor labels in your own dataset."
  },
  {
    "objectID": "compLatent.html",
    "href": "compLatent.html",
    "title": "Using Rasch and WLS to account for measurement uncertainties in regression models",
    "section": "",
    "text": "There are several reasons for putting this blog post together. The larger issue is to investigate ways to analyze relationships between measures that have varying levels of measurement uncertainty across their respective range or continuum. This is relevant to any kind of latent variable measurement that uses multiple indicators/items/questions as a way to assess a latent variable.\nIn classical test theory (CTT; i.e. factor analysis) the assumption is generally that the measurement error is a single value, constant across the scale and across participants. Modern test theory (Rasch Measurement Theory (RMT) or Item Response Theory (IRT)) has tools to describe the varying uncertainties of the measure itself, and also allows for estimation of measurement uncertainty for each individual, based on the item properties.\nIn the “business-as-usual” approach, no matter which types of measurement uncertainty are ignored. The simple case of have two variables and an ordinary least squares (OLS) linear regression model will take the input from each variable as a perfect measurement. Bayesians may have another take on this, and I will look into that at a later point, so for now this is relevant for frequentist statistics.\n“Business-as-usual” also makes use of ordinal sum scores disguised as interval scores. There is a seemingly wide-spread idea that estimated person interval scores is not significantly different from ordinal sum scores, and we’ll look further into that as well by including ordinal sum scores.\nOne way to take measurement uncertainty into account in a linear regression model is to use Weighted Least Squares (WLS) instead of OLS. However, this approach only allows weights for one variable. The weights will be based on the measurement uncertainty for the interval scores.\nAdditionally, we will use Quantile Regression, with and without weights."
  },
  {
    "objectID": "compLatent.html#data",
    "href": "compLatent.html#data",
    "title": "Using Rasch and WLS to account for measurement uncertainties in regression models",
    "section": "\n2 Data",
    "text": "2 Data\nData were collected for a project evaluating multiple work environment questionnaires. Two of the analyzed scales will be used in our example, as a foundation for simulated data. More information is available at the GitHub repository and website.\nThe two questionnaires cover the domains of “recovery” and “agency”, where the latter refers to workers’ perceived control over their work situation. Our analyses will look at how “agency” affects “recovery”. We will retain an interval scale score for the “recovery” scale throughout, while varying the “agency” between ordinal sum score, interval score, and interval score with weights, and check how these three reproduce the true simulated relationship between the two scales.\nVariables will be named SEM for standard error of measurement, Theta for interval theta/scores/locations, and SumScore for ordinal sum scores.\nWe’ll also add analyses using structural equation modeling and weighted sum scores (based on confirmatory factor analysis factor loadings).\n\nCodelibrary(RISEkbmRasch)\nlibrary(easystats)\nlibrary(quantreg)\nlibrary(faux)\nlibrary(broom.mixed)\nlibrary(lavaan)\nlibrary(DescTools)\nlibrary(lme4)\n\n### some commands exist in multiple packages, here we define preferred ones that are frequently used\nselect <- dplyr::select\ncount <- dplyr::count\nrecode <- car::recode\nrename <- dplyr::rename"
  },
  {
    "objectID": "compLatent.html#simulating-data-n-800",
    "href": "compLatent.html#simulating-data-n-800",
    "title": "Using Rasch and WLS to account for measurement uncertainties in regression models",
    "section": "\n3 Simulating data n = 800",
    "text": "3 Simulating data n = 800\nWe’ll pretend that we have n = 400 that are measured at two time points, with a specified correlation between measurements of 0.5. The difference in group means is set to 1 logit, and the standard deviation will be 1 logit for both points of measurement.\n\nCodeset.seed(1523)\nn <- 100\ndata <- rnorm_multi(n = n, \n                  mu = c(-0.5, +0.5),\n                  sd = c(1, 1),\n                  r = c(0.5), \n                  varnames = c(\"pre\", \"post\"),\n                  empirical = FALSE)\n\ncor_test(\"pre\", \"post\", data = data)\n\nParameter1 | Parameter2 |    r |       95% CI | t(98) |         p\n-----------------------------------------------------------------\npre        |       post | 0.55 | [0.39, 0.67] |  6.49 | < .001***\n\nObservations: 100\n\nCode# light wrangling to get long format and an id variable\ndata_long <- data %>% \n  add_column(id = 1:(nrow(.))) %>% \n  pivot_longer(cols = c(\"pre\", \"post\"), \n               names_to = \"time\", \n               values_to = \"theta\") %>% \n  mutate(theta = round(theta, 4),\n         time = dplyr::recode(time, \"pre\" = 0, \"post\" = 1))\n#write_csv(data, \"data800simPrePost.csv\")\n\n\n\n3.1 Scatter plot\n\nCodedata %>% \n  ggplot(aes(x = pre, y = post)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw()\n\n\n\n\n\n3.2 Reference LMM results from the simulated theta values\n\nCodelmm0 <- lmer(scale(theta) ~ time + (1 | id), data = data_long) \n\nlmm0 %>%\n  tidy(conf.int = TRUE) %>% \n  mutate(across(where(is.numeric), round, 4))\n\n# A tibble: 4 × 8\n  effect   group    term         estimate std.error statistic conf.low conf.high\n  <chr>    <chr>    <chr>           <dbl>     <dbl>     <dbl>    <dbl>     <dbl>\n1 fixed    <NA>     (Intercept)    -0.436    0.0902     -4.83   -0.613    -0.259\n2 fixed    <NA>     time            0.872    0.0857     10.2     0.704     1.04 \n3 ran_pars id       sd__(Interc…    0.668   NA          NA      NA        NA    \n4 ran_pars Residual sd__Observa…    0.606   NA          NA      NA        NA    \n\nCodeicc(lmm0)\n\n# Intraclass Correlation Coefficient\n\n    Adjusted ICC: 0.548\n  Unadjusted ICC: 0.444\n\nCodeStdCoef(lmm0)\n\n            Estimate* Std. Error*  df\n(Intercept) 0.0000000  0.00000000 196\ntime        0.4370146  0.04297825 196\nattr(,\"class\")\n[1] \"coefTable\" \"matrix\"   \n\n\nThe standardized coefficient of time is 0.424. This will be our reference value for comparison with the other analyses since ordinal sum scores and estimated theta scores will not be on the same scale.\n\n3.3 Simulating polytomous data\nPrepare the input item parameters.\n\nCode# item parameters\nagencyParams <- read_csv(\"AgencyItemParameters.csv\") %>% \n  as.matrix()\n\n# put item parameters for agency into a list object\ncolnames(agencyParams) <- NULL\n\ntlist <- lapply(1:nrow(agencyParams), function(i) {\n  as.list(agencyParams[i, ])\n})\n\n# simulate polytomous data\nsimData <- SimPartialScore(\n  deltaslist = tlist,\n  thetavec = data_long$theta\n) %>%\n  as.data.frame()\n\n\nA brief look at the simulated data.\n\nCode# distribution\nRIbarstack(simData)\n\n\n\n\n\nCode# reliability/test information\nRItif(simData, cutoff = 2.5, samplePSI = TRUE)\n\n\n\n\nTIF 2.5 = PSI 0.6\n\n3.4 Classical test theory\nConfirmatory factor analysis (CFA) is used to estimate model fit.\n\nCode# specify model\ncfa1 <- 'agencyCFA =~ V1 + V2 + V3 + V4'\n# estimate model\ncfa1.fit <- cfa(cfa1, \n                ordered = TRUE, \n                estimator = \"DWLS\",\n                data = simData)\n# get fit indices etc\nsummary(cfa1.fit, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 13 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        20\n\n  Number of observations                           200\n\nModel Test User Model:\n                                                      \n  Test statistic                                 1.426\n  Degrees of freedom                                 2\n  P-value (Chi-square)                           0.490\n\nModel Test Baseline Model:\n\n  Test statistic                               441.330\n  Degrees of freedom                                 6\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.004\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.127\n  P-value H_0: RMSEA <= 0.050                    0.639\n  P-value H_0: RMSEA >= 0.080                    0.209\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.023\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  agencyCFA =~                                        \n    V1                1.000                           \n    V2                0.918    0.109    8.403    0.000\n    V3                1.179    0.138    8.542    0.000\n    V4                0.942    0.110    8.576    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .V1                0.000                           \n   .V2                0.000                           \n   .V3                0.000                           \n   .V4                0.000                           \n    agencyCFA         0.000                           \n\nThresholds:\n                   Estimate  Std.Err  z-value  P(>|z|)\n    V1|t1            -0.613    0.095   -6.438    0.000\n    V1|t2             0.088    0.089    0.987    0.323\n    V1|t3             0.842    0.101    8.310    0.000\n    V1|t4             2.326    0.265    8.791    0.000\n    V2|t1            -0.842    0.101   -8.310    0.000\n    V2|t2            -0.088    0.089   -0.987    0.323\n    V2|t3             0.824    0.101    8.180    0.000\n    V2|t4             1.881    0.178   10.583    0.000\n    V3|t1            -0.896    0.103   -8.694    0.000\n    V3|t2            -0.292    0.090   -3.240    0.001\n    V3|t3             0.332    0.091    3.661    0.000\n    V3|t4             1.645    0.150   10.980    0.000\n    V4|t1            -1.282    0.121  -10.576    0.000\n    V4|t2             0.151    0.089    1.692    0.091\n    V4|t3             1.036    0.109    9.547    0.000\n    V4|t4             2.054    0.205   10.020    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .V1                0.507                           \n   .V2                0.585                           \n   .V3                0.315                           \n   .V4                0.563                           \n    agencyCFA         0.493    0.074    6.682    0.000\n\nScales y*:\n                   Estimate  Std.Err  z-value  P(>|z|)\n    V1                1.000                           \n    V2                1.000                           \n    V3                1.000                           \n    V4                1.000                           \n\nCode# get standardized factor loadings\ninspect(cfa1.fit,what=\"std\")$lambda\n\n   agnCFA\nV1  0.702\nV2  0.644\nV3  0.828\nV4  0.661\n\nCode# save factor loadings to a vector\ncfa1_loadings <- inspect(cfa1.fit,what=\"std\")$lambda %>% \n  as.data.frame() %>% \n  pull(agencyCFA)\n\n# CTT reliability\npsych::alpha(simData)\n\n\nReliability analysis   \nCall: psych::alpha(x = simData)\n\n  raw_alpha std.alpha G6(smc) average_r S/N   ase mean   sd median_r\n      0.76      0.76    0.72      0.45 3.2 0.027  1.6 0.83     0.45\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.71  0.76  0.81\nDuhachek  0.71  0.76  0.82\n\n Reliability if an item is dropped:\n   raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nV1      0.70      0.71    0.62      0.44 2.4    0.035 0.0071  0.46\nV2      0.72      0.73    0.64      0.47 2.7    0.033 0.0010  0.46\nV3      0.66      0.67    0.57      0.40 2.0    0.041 0.0024  0.40\nV4      0.73      0.73    0.65      0.48 2.7    0.033 0.0047  0.51\n\n Item statistics \n     n raw.r std.r r.cor r.drop mean   sd\nV1 200  0.77  0.77  0.65   0.57  1.4 1.11\nV2 200  0.75  0.74  0.61   0.53  1.6 1.09\nV3 200  0.83  0.81  0.74   0.64  1.9 1.20\nV4 200  0.71  0.74  0.60   0.52  1.5 0.91\n\nNon missing response frequency for each item\n      0    1    2    3    4 miss\nV1 0.27 0.26 0.26 0.19 0.01    0\nV2 0.20 0.26 0.33 0.17 0.03    0\nV3 0.18 0.20 0.24 0.32 0.05    0\nV4 0.10 0.46 0.29 0.13 0.02    0\n\nCodepsych::omega(simData)\n\n\n\n\nOmega \nCall: omegah(m = m, nfactors = nfactors, fm = fm, key = key, flip = flip, \n    digits = digits, title = title, sl = sl, labels = labels, \n    plot = plot, n.obs = n.obs, rotate = rotate, Phi = Phi, option = option, \n    covar = covar)\nAlpha:                 0.76 \nG.6:                   0.72 \nOmega Hierarchical:    0.7 \nOmega H asymptotic:    0.89 \nOmega Total            0.78 \n\nSchmid Leiman Factor loadings greater than  0.2 \n      g   F1* F2* F3*   h2   u2   p2\nV1 0.73               0.49 0.51 1.08\nV2 0.52  0.39         0.43 0.57 0.62\nV3 0.66  0.45         0.64 0.36 0.69\nV4 0.66               0.41 0.59 1.04\n\nWith Sums of squares  of:\n   g  F1*  F2*  F3* \n1.67 0.36 0.00 0.00 \n\ngeneral/max  4.69   max/min =   Inf\nmean percent general =  0.86    with sd =  0.24 and cv of  0.28 \nExplained Common Variance of the general factor =  0.82 \n\nThe degrees of freedom are -3  and the fit is  0 \nThe number of observations was  200  with Chi Square =  0  with prob <  NA\nThe root mean square of the residuals is  0 \nThe df corrected root mean square of the residuals is  NA\n\nCompare this with the adequacy of just a general factor and no group factors\nThe degrees of freedom for just the general factor are 2  and the fit is  0.06 \nThe number of observations was  200  with Chi Square =  11.68  with prob <  0.0029\nThe root mean square of the residuals is  0.08 \nThe df corrected root mean square of the residuals is  0.13 \n\nRMSEA index =  0.155  and the 10 % confidence intervals are  0.078 0.248\nBIC =  1.08 \n\nMeasures of factor score adequacy             \n                                                 g   F1* F2*   F3*\nCorrelation of scores with factors            0.86  0.60   0  0.08\nMultiple R square of scores with factors      0.73  0.36   0  0.01\nMinimum correlation of factor score estimates 0.46 -0.28  -1 -0.99\n\n Total, General and Subset omega for each subset\n                                                 g  F1* F2*  F3*\nOmega total for total scores and subscales    0.78 0.69  NA 0.66\nOmega general for total scores and subscales  0.70 0.46  NA 0.66\nOmega group for total scores and subscales    0.08 0.23  NA 0.00\n\n\n\n3.5 Estimate person thetas/latent scores\nNext step is to estimate person thetas/scores/locations based on the pre-specified item parameters.\n\nCode# estimate person thetas\npersonThetas <- RIestThetas(simData,itemParams = agencyParams)\n# estimate person theta SEM\npersonSEM <- map_vec(personThetas, ~ catR::semTheta(.x, it = agencyParams, method = \"WL\", model = \"PCM\"))\n# add person thetas to the simulated data\nsimData$estTheta <- personThetas\nsimData$estSEM <- personSEM\n# add ordinal sum scores to the simulated data\nsimData <- simData %>% \n  mutate(SumScore = V1+V2+V3+V4)\n# add weighted ordinal sum scores to the simulated data\nsimData$weightedSumScore <- simData$V1*cfa1_loadings[1] + \n  simData$V2*cfa1_loadings[2] + \n  simData$V3*cfa1_loadings[3] + \n  simData$V4*cfa1_loadings[4]\n\n# add simulated theta values to the simData\nsimData$simTheta <- data_long$theta\n# add id variable\nsimData$id <- data_long$id\n# create grouping variable for quintiles\nsimData$quintile <- as.factor(ntile(simData$simTheta, 5))\n\n# add time variable to data\nsimData$time <- data_long$time\n\nwrite_csv(simData, \"simData.csv\")\n\n\n\nCodehist(simData$simTheta, col = \"lightblue\")\nhist(simData$estTheta, col = \"lightpink\")\nhist(simData$SumScore, col = \"lightgreen\")\nhist(simData$weightedSumScore, col = \"darkgreen\")\n\n\n\n\n\nHistograms of generated and estimated theta values, ordinal sum scores, and weighted ordinal sum scores\n\n\n\n\n\n\nHistograms of generated and estimated theta values, ordinal sum scores, and weighted ordinal sum scores\n\n\n\n\n\n\n\n\nHistograms of generated and estimated theta values, ordinal sum scores, and weighted ordinal sum scores\n\n\n\n\n\n\nHistograms of generated and estimated theta values, ordinal sum scores, and weighted ordinal sum scores\n\n\n\n\n\n\n\nCode# density plot for all four of the above histograms, facet_wrapped by time\nsimData %>% \n  mutate(across(c(\"simTheta\", \"estTheta\", \"SumScore\", \"weightedSumScore\"), ~ scale(.x))) %>%\n  pivot_longer(cols = c(\"simTheta\", \"estTheta\", \"SumScore\", \"weightedSumScore\"), \n               names_to = \"variable\", \n               values_to = \"value\") %>% \n  ggplot(aes(x = value, fill = variable)) +\n  geom_density(alpha = 0.5) +\n  facet_wrap(~time) +\n  theme_bw() +\n  scale_fill_viridis_d() +\n  labs(x = \"Value\", y = \"Density\", fill = \"Variable\",\n       subtitle = \"Split by timepoint 0 and 1\")\n\n\n\nDensity plot of scaled values for all four variables"
  },
  {
    "objectID": "compLatent.html#statistical-analyses",
    "href": "compLatent.html#statistical-analyses",
    "title": "Using Rasch and WLS to account for measurement uncertainties in regression models",
    "section": "\n4 Statistical analyses",
    "text": "4 Statistical analyses\n\n4.1 LMM with estimated theta\n\nCodelmm1 <- lmer(scale(estTheta) ~ time + (1 | id), data = simData) \n\nlmm1 %>%\n  tidy(conf.int = TRUE) %>% \n  mutate(across(where(is.numeric), round, 4))\n\n# A tibble: 4 × 8\n  effect   group    term         estimate std.error statistic conf.low conf.high\n  <chr>    <chr>    <chr>           <dbl>     <dbl>     <dbl>    <dbl>     <dbl>\n1 fixed    <NA>     (Intercept)    -0.347    0.094      -3.70   -0.532    -0.163\n2 fixed    <NA>     time            0.695    0.0998      6.96    0.499     0.890\n3 ran_pars id       sd__(Interc…    0.620   NA          NA      NA        NA    \n4 ran_pars Residual sd__Observa…    0.706   NA          NA      NA        NA    \n\nCodeicc(lmm1)\n\n# Intraclass Correlation Coefficient\n\n    Adjusted ICC: 0.436\n  Unadjusted ICC: 0.383\n\nCodeStdCoef(lmm1)\n\n            Estimate* Std. Error*  df\n(Intercept) 0.0000000   0.0000000 196\ntime        0.3481564   0.0500326 196\nattr(,\"class\")\n[1] \"coefTable\" \"matrix\"   \n\n\n0.37 (SE = 0.026) compared with 0.42.\n\n4.2 Weighted LMM with estimated theta\nWe’ll use the estimated theta SEM as weights.\n\nCode# plot range of estSEM across estTheta\nsimData %>% \n  ggplot(aes(x = estTheta, y = estSEM)) +\n  geom_point() +\n  geom_line(group = 1) +\n  theme_bw() +\n  labs(x = \"Estimated theta\", y = \"Estimated theta SEM\")\n\n\n\nPlot of estimated theta SEM against estimated theta\n\n\n\n\n\nCodelmm2 <- lmer(scale(estTheta) ~ time + (1 | id), data = simData,\n             weights = estSEM) \n\nlmm2 %>%\n  tidy(conf.int = TRUE) %>% \n  mutate(across(where(is.numeric), round, 4))\n\n# A tibble: 4 × 8\n  effect   group    term         estimate std.error statistic conf.low conf.high\n  <chr>    <chr>    <chr>           <dbl>     <dbl>     <dbl>    <dbl>     <dbl>\n1 fixed    <NA>     (Intercept)    -0.429    0.101      -4.27   -0.626    -0.232\n2 fixed    <NA>     time            0.798    0.0992      8.04    0.603     0.992\n3 ran_pars id       sd__(Interc…    0.731   NA          NA      NA        NA    \n4 ran_pars Residual sd__Observa…    0.571   NA          NA      NA        NA    \n\nCodeicc(lmm2)\n\n# Intraclass Correlation Coefficient\n\n    Adjusted ICC: 0.622\n  Unadjusted ICC: 0.524\n\nCodeStdCoef(lmm2)\n\n            Estimate* Std. Error*  df\n(Intercept)  0.000000  0.00000000 196\ntime         0.399825  0.04970946 196\nattr(,\"class\")\n[1] \"coefTable\" \"matrix\"   \n\n\n0.414 (SE = 0.026) compared with 0.42.\n\n4.3 LMM with ordinal sum score\n\nCodelmm3 <- lmer(scale(SumScore) ~ time + (1 | id), data = simData)\n\nlmm3 %>%\n  tidy(conf.int = TRUE) %>% \n  mutate(across(where(is.numeric), round, 4))\n\n# A tibble: 4 × 8\n  effect   group    term         estimate std.error statistic conf.low conf.high\n  <chr>    <chr>    <chr>           <dbl>     <dbl>     <dbl>    <dbl>     <dbl>\n1 fixed    <NA>     (Intercept)    -0.336    0.0944     -3.57   -0.522    -0.152\n2 fixed    <NA>     time            0.673    0.101       6.64    0.474     0.872\n3 ran_pars id       sd__(Interc…    0.614   NA          NA      NA        NA    \n4 ran_pars Residual sd__Observa…    0.717   NA          NA      NA        NA    \n\nCodeicc(lmm3)\n\n# Intraclass Correlation Coefficient\n\n    Adjusted ICC: 0.423\n  Unadjusted ICC: 0.375\n\nCodeStdCoef(lmm3)\n\n            Estimate* Std. Error*  df\n(Intercept) 0.0000000  0.00000000 196\ntime        0.3373715  0.05083355 196\nattr(,\"class\")\n[1] \"coefTable\" \"matrix\"   \n\n\n0.373 (SE = 0.026) compared with 0.42.\n\n4.4 LMM with weighted ordinal sum score\n\nCodelmm4 <- lmer(scale(weightedSumScore) ~ time + (1 | id), data = simData)\n\nlmm4 %>%\n  tidy(conf.int = TRUE) %>% \n  mutate(across(where(is.numeric), round, 4))\n\n# A tibble: 4 × 8\n  effect   group    term         estimate std.error statistic conf.low conf.high\n  <chr>    <chr>    <chr>           <dbl>     <dbl>     <dbl>    <dbl>     <dbl>\n1 fixed    <NA>     (Intercept)    -0.333    0.0945     -3.53   -0.518    -0.148\n2 fixed    <NA>     time            0.666    0.102       6.54    0.467     0.866\n3 ran_pars id       sd__(Interc…    0.611   NA          NA      NA        NA    \n4 ran_pars Residual sd__Observa…    0.720   NA          NA      NA        NA    \n\nCodeicc(lmm4)\n\n# Intraclass Correlation Coefficient\n\n    Adjusted ICC: 0.419\n  Unadjusted ICC: 0.372\n\nCodeStdCoef(lmm4)\n\n            Estimate* Std. Error*  df\n(Intercept) 0.0000000  0.00000000 196\ntime        0.3339848  0.05107553 196\nattr(,\"class\")\n[1] \"coefTable\" \"matrix\"   \n\n\n0.373 (SE = 0.026) compared with 0.424."
  },
  {
    "objectID": "compLatent.html#summary",
    "href": "compLatent.html#summary",
    "title": "Using Rasch and WLS to account for measurement uncertainties in regression models",
    "section": "\n5 Summary",
    "text": "5 Summary\n\nCode# rbind together lmm0 to lmm4 in one dataframe\nlmm_summary <- rbind(tidy(lmm0), tidy(lmm1), tidy(lmm2), tidy(lmm3), tidy(lmm4)) %>% \n  add_column(model = rep(c(\"lmm0\", \"lmm1estTheta\", \"lmm2weightedTheta\", \"lmm3sumscore\", \"lmm4weighted Sumscore\"),each = 4))\nlmm_summary %>% \n  filter(term == \"time\") %>% \n  write_csv(paste0(n,\"_lmm_summary.csv\"))\n\n\n\nCode# check ICC vs correlation pre/post for estTheta\nsimData %>% \n  mutate(time = factor(time, labels = c(\"pre\",\"post\"))) %>% \n  pivot_wider(names_from = time, values_from = estTheta, id_cols = \"id\") %>% \n  cor_test(\"pre\",\"post\")\n\nParameter1 | Parameter2 |    r |       95% CI | t(98) |         p\n-----------------------------------------------------------------\npre        |       post | 0.44 | [0.26, 0.58] |  4.80 | < .001***\n\nObservations: 100"
  },
  {
    "objectID": "raschrvignette/RaschRvign.html#sec-grateful",
    "href": "raschrvignette/RaschRvign.html#sec-grateful",
    "title": "RISEkbmRasch vignette",
    "section": "\n12 Software used",
    "text": "12 Software used\nThe grateful package is a nice way to give credit to the packages used in making the analysis. The package can create both a bibliography file and a table object, which is handy for automatically creating a reference list based on the packages used (or at least explicitly loaded).\n\nCodelibrary(grateful)\npkgs &lt;- cite_packages(cite.tidyverse = TRUE, \n                      output = \"table\",\n                      bib.file = \"grateful-refs.bib\",\n                      include.RStudio = TRUE,\n                      out.dir = getwd())\n# If kbl() is used to generate this table, the references will not be added to the Reference list.\nformattable(pkgs, \n            table.attr = 'class=\\\"table table-striped\\\" style=\"font-size: 13px; font-family: Lato; width: 80%\"')\n\n\n\n\nPackage\n\n\nVersion\n\n\nCitation\n\n\n\n\n\nbase\n\n\n4.4.1\n\n\nR Core Team (2024)\n\n\n\n\ncar\n\n\n3.1.2\n\n\nFox & Weisberg (2019)\n\n\n\n\neRm\n\n\n1.0.6\n\n\nMair & Hatzinger (2007b); Mair & Hatzinger (2007a); Hatzinger & Rusch (2009); Rusch et al. (2013); Koller et al. (2015); Debelak & Koller (2019)\n\n\n\n\nforeach\n\n\n1.5.2\n\n\nMicrosoft & Weston (2022)\n\n\n\n\nformattable\n\n\n0.2.1\n\n\nRen & Russell (2021)\n\n\n\n\nggrepel\n\n\n0.9.5\n\n\nSlowikowski (2024)\n\n\n\n\nglue\n\n\n1.7.0\n\n\nHester & Bryan (2024)\n\n\n\n\niarm\n\n\n0.4.3\n\n\nMueller (2022)\n\n\n\n\nkableExtra\n\n\n1.4.0\n\n\nZhu (2024)\n\n\n\n\nknitr\n\n\n1.48\n\n\nXie (2014); Xie (2015); Xie (2024)\n\n\n\n\nlordif\n\n\n0.3.3\n\n\nChoi et al. (2016)\n\n\n\n\nmatrixStats\n\n\n1.3.0\n\n\nBengtsson (2024)\n\n\n\n\nmirt\n\n\n1.42\n\n\nChalmers (2012)\n\n\n\n\npatchwork\n\n\n1.2.0\n\n\nPedersen (2024)\n\n\n\n\nPerFit\n\n\n1.4.6\n\n\nTendeiro et al. (2016)\n\n\n\n\npsych\n\n\n2.4.6.26\n\n\nWilliam Revelle (2024)\n\n\n\n\npsychotree\n\n\n0.16.1\n\n\nTrepte & Verbeet (2010); Strobl et al. (2011); Strobl et al. (2015a); Komboz et al. (2018); Wickelmaier & Zeileis (2018)\n\n\n\n\nRASCHplot\n\n\n0.1.0\n\n\nBuchardt et al. (2022)\n\n\n\n\nreshape\n\n\n0.8.9\n\n\nWickham (2007)\n\n\n\n\nRISEkbmRasch\n\n\n0.2.4\n\n\nJohansson (2024)\n\n\n\n\nrmarkdown\n\n\n2.27\n\n\nXie et al. (2018); Xie et al. (2020); Allaire et al. (2024)\n\n\n\n\ntidyverse\n\n\n2.0.0\n\n\nWickham et al. (2019)"
  },
  {
    "objectID": "datawrangling.html#removing-respondents-with-missing-data",
    "href": "datawrangling.html#removing-respondents-with-missing-data",
    "title": "Data wrangling for psychometrics in R",
    "section": "1 Removing respondents with missing data",
    "text": "1 Removing respondents with missing data\nThere may be situations where you want to specify a minimum number of items that a respondent must have answered in order to be included in the analysis. This is done by using the filter() function from library(dplyr). The syntax is as follows:\nmin.responses &lt;- 5 # set the minimum number of responses\n\ndf2 &lt;- df %&gt;% \n  filter(length(itemlabels$itemnr) - rowSums(is.na(.[itemlabels$itemnr])) &gt;=     min.responses)\nThe object itemlabels$itemnr is a vector (column in a dataframe) with the short item labels as they are used in the dataframe df which contain the data, with items as columns using the corresponding labels.\nThe length() function is used to count the number of items in the vector, and rowSums(is.na()) is used to count the number of missing values in each row. Then a simple subtraction is done, total number of items minus number of missing responses. The &gt;= operator is used to compare the number of responses to the minimum number of responses specified in the object min.responses. The filter() function removes all rows that do not meet the criteria. And the new dataset is saved to df2."
  },
  {
    "objectID": "parameterizedQ.html",
    "href": "parameterizedQ.html",
    "title": "Automating reports with Quarto",
    "section": "",
    "text": "Let’s say you have survey data from a group of 28 municipalities. You have worked out a Quarto file to generate nice tables and figures and want to produce 28 different reports that all use the same Quarto file for each of the municipalities. Additionally, you want one collective report using the complete dataset.\nInstead of creating 28+1 different .qmd files and running them manually, this can be easily automated with parameterization. This will save huge amounts of time, for instance when you find that typo in one figure and need to re-render all 29 reports. Or, even better, when you get next years survey results and can re-use the whole setup and instantly generate your new reports!"
  },
  {
    "objectID": "parameterizedQ.html#background",
    "href": "parameterizedQ.html#background",
    "title": "Automating reports with Quarto",
    "section": "",
    "text": "Let’s say you have survey data from a group of 28 municipalities. You have worked out a Quarto file to generate nice tables and figures and want to produce 28 different reports that all use the same Quarto file for each of the municipalities. Additionally, you want one collective report using the complete dataset.\nInstead of creating 28+1 different .qmd files and running them manually, this can be easily automated with parameterization. This will save huge amounts of time, for instance when you find that typo in one figure and need to re-render all 29 reports. Or, even better, when you get next years survey results and can re-use the whole setup and instantly generate your new reports!"
  },
  {
    "objectID": "parameterizedQ.html#setting-up",
    "href": "parameterizedQ.html#setting-up",
    "title": "Automating reports with Quarto",
    "section": "\n2 Setting up",
    "text": "2 Setting up\nIn our simple case, we will only use one parameter, the name of the municipality. Of course there could be any number of parameters that you may want to customize, which you are likely to easily be able to do based on this example.\nWe need to add two rows to the qmd-file YAML:\n---\nparams:\n  municipality: \"All municipalities\"\n---\nThis creates the object params$municipality and gives it a default value.\nNext, we create our little script, in a file called render.R, starting with a vector of municipalities. This could of course be read from a file, and our example will only contain four.\nmunicipalities &lt;- c(\"All municipalities\",\"Vallentuna\",\"Vaxholm\",\"Södertälje\",\"Botkyrka\")\nlibrary(glue)\nlibrary(quarto)\nlibrary(purrr)\n\nwalk(1:length(municipalities), function(i) {\n  muni &lt;- municipalities[i]\n  \n  outfile &lt;- glue(\"{Sys.Date()}_{muni}.html\") # gives the filename a date and the municipality name\n  \n  quarto_render(input = \"yourQuartoTemplate.qmd\", \n                execute_params = list(\"grupp\" = muni), \n                output_file = outfile,\n                output_format = \"html\")\n})\n\nAs you can see, we make use of purrr::walk, which means you may be able to use furrr::future_walk to enable parallel processing?! I have only tried this briefly, but it didn’t work. Could be worth looking into if you need to generate a lot of reports often.\n\n\n2.1 Final settings\nNow, we just need to make sure that our Quarto file uses the params. For simplicity, I expect that you read your data from a file into a dataframe. We will make use of a simple if and else combined with dplyr::filter() from the tidyverse.\n# read data\ndf &lt;- read_csv(\"yourDataFile.csv\")\n\nif (params$municipality == \"All municipalities\") {\n  df &lt;- df\n} else {\n  df &lt;- df %&gt;% \n  filter(municipality == params$municipality)\n}\nSave your files and run the render.R script! Files will be output to the same directory as your .qmd file.\nIf you’d like to use the municipality in the first headline of the report, you can add a line like this to the Quarto file:\n\nCode## `r params$municipality` {.unnumbered}\n\n\n\n\n\n\n\n\nNote\n\n\n\nA far more complex example can be found here (and some of my code was adapted from there): https://github.com/Pecners/sra_pullout/blob/main/render.R"
  },
  {
    "objectID": "parameterizedQ.html#a-slightly-more-complex-example",
    "href": "parameterizedQ.html#a-slightly-more-complex-example",
    "title": "Automating reports with Quarto",
    "section": "\n3 A slightly more complex example",
    "text": "3 A slightly more complex example\nThe earlier example only used a single vector of municipalities as a parameter. In a current project I’m working on the municipalities also want to specify who they want to compare themselves with, and the timespan in years that they want displayed in the report. We keep this information in a MS Excel file with three variables: focusMuni, compMuni, yearsMuni, which is read into a dataframe called DIDparams in the script below. To avoid issues with blank spaces in the cells, we’ll remove them when importing. This is done with the gsub() function.\n# we need two additional packages for this\nlibrary(readxl)\nlibrary(dplyr)\n\nDIDparams &lt;- read_excel(\"DIDreportParameters.xls\") %&gt;%\n  mutate(across(everything(), ~ gsub(\" \",\"\",.x)))\nThen we loop through each row in the DIDparams dataframe. Each cell in the variables compMuni and YearsMuni will contain multiple values. We use strsplit() and unlist() in a pipe to convert these into vectors. Finally, we want to make sure that the variable containing years is coded as numeric.\nwalk(1:nrow(DIDparams), function(i) {\n  this &lt;- DIDparams[i,]\n\n  outfile &lt;- glue(\"{Sys.Date()}_DIDrapport_{this$fokusKommun}.html\")\n\n  quarto_render(input = \"DIDreport.qmd\",\n                execute_params = list(\"focusMuni\" = this$focusMuni, # only contains one value\n                                      \"compMuni\" = this$compMuni %&gt;% strsplit(\",\") %&gt;% unlist(),\n                                      \"yearsMuni\" = this$yearsMuni %&gt;% strsplit(\",\") %&gt;% unlist() %&gt;% as.numeric()\n                                      ),\n                output_file = outfile,\n                output_format = \"html\")\n})"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Magnus Johansson is a licensed psychologist with a PhD in behavior analysis. I work as a scientist at RISE Research Institutes of Sweden, primarily with psychometrics, measurement, prevention and public health.\nYou can also find me on:\n\nTwitter: @pgmjoh\nORCID: 0000-0003-1669-592X\nMastodon: @pgmj\nOSF: Open Science Framework\n\nand of course on GitHub\n\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "When you work with open source tools such as R it comes with a community of users asking and answering questions, as well as many making helpful tutorials or blog posts freely available.\nI constantly learn from others and like to give something back from my own journey of learning, exploring and hopefully innovating and contributing back to the community. I have the opportunity to work with a lot of different data scenarios. Most often psychometrics is involved, as well as data analysis and visualization.\nMy ambition is to get better at documenting my own learning process and sharing it through this website. Content will be added intermittently under the Blog headline.\n\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "raschrvignette/RaschRvign.html#session-info",
    "href": "raschrvignette/RaschRvign.html#session-info",
    "title": "RISEkbmRasch vignette",
    "section": "\n14 Session info",
    "text": "14 Session info\n\nCodesessionInfo()\n\nR version 4.4.1 (2024-06-14)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sonoma 14.6.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Stockholm\ntzcode source: internal\n\nattached base packages:\n [1] parallel  grid      stats4    stats     graphics  grDevices utils    \n [8] datasets  methods   base     \n\nother attached packages:\n [1] PerFit_1.4.6       ltm_1.2-0          polycor_0.8-1      msm_1.7.1         \n [5] MASS_7.3-61        lordif_0.3-3       rms_6.8-1          Hmisc_5.1-3       \n [9] RASCHplot_0.1.0    doParallel_1.0.17  iterators_1.0.14   tictoc_1.2.1      \n[13] foreach_1.5.2      knitr_1.48         readxl_1.4.3       car_3.1-2         \n[17] carData_3.0-5      grateful_0.2.4     RISEkbmRasch_0.2.4 janitor_2.2.0     \n[21] iarm_0.4.3         hexbin_1.28.3      catR_3.17          glue_1.7.0        \n[25] ggrepel_0.9.5      patchwork_1.2.0    reshape_0.8.9      matrixStats_1.3.0 \n[29] psychotree_0.16-1  psychotools_0.7-4  partykit_1.2-21    mvtnorm_1.2-5     \n[33] libcoin_1.0-10     psych_2.4.6.26     mirt_1.42          lattice_0.22-6    \n[37] eRm_1.0-6          lubridate_1.9.3    forcats_1.0.0      stringr_1.5.1     \n[41] dplyr_1.1.4        purrr_1.0.2        readr_2.1.5        tidyr_1.3.1       \n[45] tibble_3.2.1       ggplot2_3.5.1      tidyverse_2.0.0    kableExtra_1.4.0  \n[49] formattable_0.2.1 \n\nloaded via a namespace (and not attached):\n  [1] bitops_1.0-8         tools_4.4.1          backports_1.5.0     \n  [4] utf8_1.2.4           R6_2.5.1             DT_0.33             \n  [7] vegan_2.6-6.1        sm_2.2-6.0           mgcv_1.9-1          \n [10] ggdist_3.3.2         permute_0.9-7        withr_3.0.1         \n [13] gridExtra_2.3        progressr_0.14.0     quantreg_5.98       \n [16] cli_3.6.3            archive_1.1.8        sandwich_3.1-0      \n [19] labeling_0.4.3       polspline_1.1.25     pbapply_1.7-2       \n [22] systemfonts_1.1.0    foreign_0.8-87       relimp_1.0-5        \n [25] svglite_2.1.3        R.utils_2.12.3       parallelly_1.38.0   \n [28] sessioninfo_1.2.2    rstudioapi_0.16.0    generics_0.1.3      \n [31] vroom_1.6.5          distributional_0.4.0 qvcalc_1.0.3        \n [34] Matrix_1.7-0         fansi_1.0.6          abind_1.4-5         \n [37] R.methodsS3_1.8.2    lifecycle_1.0.4      multcomp_1.4-26     \n [40] yaml_2.3.10          snakecase_0.11.1     inum_1.0-5          \n [43] ggstance_0.3.7       promises_1.3.0       irtoys_0.2.2        \n [46] crayon_1.5.3         pillar_1.9.0         fda_6.1.8           \n [49] vcdExtra_0.8-5       future.apply_1.11.2  admisc_0.35         \n [52] codetools_0.2-20     beepr_2.0            data.table_1.15.4   \n [55] vcd_1.4-12           vctrs_0.6.5          testthat_3.2.1.1    \n [58] cellranger_1.1.0     gtable_0.3.5         cachem_1.1.0        \n [61] ks_1.14.2            xfun_0.46            mime_0.12           \n [64] fds_1.8              pracma_2.4.4         pcaPP_2.0-4         \n [67] survival_3.7-0       audio_0.1-11         RPushbullet_0.3.4   \n [70] TH.data_1.1-2        nlme_3.1-165         bit64_4.0.5         \n [73] rprojroot_2.0.4      Deriv_4.1.3          KernSmooth_2.23-24  \n [76] rpart_4.1.23         colorspace_2.1-1     gnm_1.1-5           \n [79] nnet_7.3-19          mnormt_2.1.1         tidyselect_1.2.1    \n [82] bit_4.0.5            compiler_4.4.1       curl_5.2.1          \n [85] htmlTable_2.4.3      SparseM_1.84-2       expm_0.999-9        \n [88] xml2_1.3.6           checkmate_2.3.2      scales_1.3.0        \n [91] lmtest_0.9-40        digest_0.6.36        rainbow_3.8         \n [94] rmarkdown_2.27       ca_0.71.1            htmltools_0.5.8.1   \n [97] pkgconfig_2.0.3      base64enc_0.1-3      SimDesign_2.16      \n[100] fastmap_1.2.0        rlang_1.1.4          htmlwidgets_1.6.4   \n[103] shiny_1.9.1          farver_2.1.2         zoo_1.8-12          \n[106] jsonlite_1.8.8       mclust_6.1.1         dcurver_0.9.2       \n[109] R.oo_1.26.0          RCurl_1.98-1.16      magrittr_2.0.3      \n[112] Formula_1.2-5        munsell_0.5.1        Rcpp_1.0.13         \n[115] stringi_1.8.4        brio_1.1.5           plyr_1.8.9          \n[118] listenv_0.9.1        splines_4.4.1        hms_1.1.3           \n[121] ggpubr_0.6.0         ggsignif_0.6.4       reshape2_1.4.4      \n[124] GPArotation_2024.3-1 evaluate_0.24.0      renv_1.0.7          \n[127] deSolve_1.40         tzdb_0.4.0           httpuv_1.6.15       \n[130] MatrixModels_0.5-3   future_1.34.0        broom_1.0.6         \n[133] xtable_1.8-4         rstatix_0.7.2        later_1.3.2         \n[136] viridisLite_0.4.2    memoise_2.0.1        cluster_2.1.6       \n[139] corrplot_0.92        timechange_0.3.0     globals_0.16.3      \n[142] hdrcde_3.4           here_1.0.1"
  },
  {
    "objectID": "ttestChange.html",
    "href": "ttestChange.html",
    "title": "Analyzing individual change with t-tests",
    "section": "",
    "text": "When one uses Rasch or Item Response Theory to estimate measurement values on the latent scale it is also easy to estimate an “individualized” measurement error for each value estimated. It has been suggested that a useful way to use this output when analyzing data with two repeated measurement points is to conduct one paired t-test for each individual, comparing the pre/post measurements and using their respective measurement error as the “population standard error” (Hobart et al., 2010).\nThis strategy results in measurably detectable change for individuals across two time points. Whether this change is meaningful requires external validation to determine. Since measurement error is not equal across the continuum, how large the measurably detactable change is will also vary depending on the pre-measurement value.\nAll the usual limitations and caveats with t-tests apply. This post is not an endorsement of using multiple t-tests as a primary strategy of analysis, but it may be an interesting perspective that takes measurement error into account and focuses on individual outcomes.\n\n\n\n\n\n\nNote\n\n\n\nThis is work in progress and will be updated and expanded on. The first aim is to share code to do individual t-tests of theta+SEM and summarise the results. Later on, we’ll look at other methods to analyze longitudinal data, both looking at group level and individual level change.\n\n\nThe reliability of the scale/test will of course heavily influence the possibility of detecting change over time. In the Rasch Measurement Theory and Item Response Theory paradigm, reliability is not a single point value that is constant across the latent continuum (REF to separate post on reliability). Depending on the item threshold locations, the test has varying reliability.\nLater in this post, I will present a figure describing the Test Information Function, and then a figure with the SEM values across the latent continuum.\nAs shown in the separate post on reliability (LINK), SEM * 1.96 will contain the true value in 95% of cases.\n\nCodelibrary(tidyverse)\nlibrary(eRm)\nlibrary(janitor)\nlibrary(RISEkbmRasch)\nlibrary(lme4)\nlibrary(modelsummary)\nlibrary(broom.mixed)\nlibrary(marginaleffects)\nlibrary(faux)\nlibrary(ggdist)\n\n### some commands exist in multiple packages, here we define preferred ones that are frequently used\nselect &lt;- dplyr::select\ncount &lt;- dplyr::count\nrecode &lt;- car::recode\nrename &lt;- dplyr::rename\n\ntheme_rise &lt;- function(fontfamily = \"Lato\", axissize = 13, titlesize = 15,\n                       margins = 12, axisface = \"plain\", panelDist = 0.6, ...) {\n  theme_minimal() +\n  theme(\n    text = element_text(family = fontfamily),\n    axis.title.x = element_text(\n      margin = margin(t = margins),\n      size = axissize\n    ),\n    axis.title.y = element_text(\n      margin = margin(r = margins),\n      size = axissize\n    ),\n    plot.title = element_text(\n      face = \"bold\",\n      size = titlesize\n    ),\n    axis.title = element_text(\n      face = axisface\n    ),\n    plot.caption = element_text(\n      face = \"italic\"\n    ),\n    legend.text = element_text(family = fontfamily),\n    legend.background = element_rect(color = \"lightgrey\"),\n    strip.background = element_rect(color = \"lightgrey\"),\n    panel.spacing = unit(panelDist, \"cm\", data = NULL),\n    panel.border = element_rect(color = \"grey\", fill = NA),\n    ...\n  )\n}\n\ntheme_set(theme_rise())"
  },
  {
    "objectID": "ttestChange.html#introduction",
    "href": "ttestChange.html#introduction",
    "title": "Analyzing individual change with t-tests",
    "section": "",
    "text": "When one uses Rasch or Item Response Theory to estimate measurement values on the latent scale it is also easy to estimate an “individualized” measurement error for each value estimated. It has been suggested that a useful way to use this output when analyzing data with two repeated measurement points is to conduct one paired t-test for each individual, comparing the pre/post measurements and using their respective measurement error as the “population standard error” (Hobart et al., 2010).\nThis strategy results in measurably detectable change for individuals across two time points. Whether this change is meaningful requires external validation to determine. Since measurement error is not equal across the continuum, how large the measurably detactable change is will also vary depending on the pre-measurement value.\nAll the usual limitations and caveats with t-tests apply. This post is not an endorsement of using multiple t-tests as a primary strategy of analysis, but it may be an interesting perspective that takes measurement error into account and focuses on individual outcomes.\n\n\n\n\n\n\nNote\n\n\n\nThis is work in progress and will be updated and expanded on. The first aim is to share code to do individual t-tests of theta+SEM and summarise the results. Later on, we’ll look at other methods to analyze longitudinal data, both looking at group level and individual level change.\n\n\nThe reliability of the scale/test will of course heavily influence the possibility of detecting change over time. In the Rasch Measurement Theory and Item Response Theory paradigm, reliability is not a single point value that is constant across the latent continuum (REF to separate post on reliability). Depending on the item threshold locations, the test has varying reliability.\nLater in this post, I will present a figure describing the Test Information Function, and then a figure with the SEM values across the latent continuum.\nAs shown in the separate post on reliability (LINK), SEM * 1.96 will contain the true value in 95% of cases.\n\nCodelibrary(tidyverse)\nlibrary(eRm)\nlibrary(janitor)\nlibrary(RISEkbmRasch)\nlibrary(lme4)\nlibrary(modelsummary)\nlibrary(broom.mixed)\nlibrary(marginaleffects)\nlibrary(faux)\nlibrary(ggdist)\n\n### some commands exist in multiple packages, here we define preferred ones that are frequently used\nselect &lt;- dplyr::select\ncount &lt;- dplyr::count\nrecode &lt;- car::recode\nrename &lt;- dplyr::rename\n\ntheme_rise &lt;- function(fontfamily = \"Lato\", axissize = 13, titlesize = 15,\n                       margins = 12, axisface = \"plain\", panelDist = 0.6, ...) {\n  theme_minimal() +\n  theme(\n    text = element_text(family = fontfamily),\n    axis.title.x = element_text(\n      margin = margin(t = margins),\n      size = axissize\n    ),\n    axis.title.y = element_text(\n      margin = margin(r = margins),\n      size = axissize\n    ),\n    plot.title = element_text(\n      face = \"bold\",\n      size = titlesize\n    ),\n    axis.title = element_text(\n      face = axisface\n    ),\n    plot.caption = element_text(\n      face = \"italic\"\n    ),\n    legend.text = element_text(family = fontfamily),\n    legend.background = element_rect(color = \"lightgrey\"),\n    strip.background = element_rect(color = \"lightgrey\"),\n    panel.spacing = unit(panelDist, \"cm\", data = NULL),\n    panel.border = element_rect(color = \"grey\", fill = NA),\n    ...\n  )\n}\n\ntheme_set(theme_rise())"
  },
  {
    "objectID": "ttestChange.html#simulating-longitudinal-data",
    "href": "ttestChange.html#simulating-longitudinal-data",
    "title": "Analyzing individual change with t-tests",
    "section": "\n2 Simulating longitudinal data",
    "text": "2 Simulating longitudinal data\n3 time points for later use. First, we’ll focus on t1 and t3 and run the t-tests focusing on individual change.\n\nCodeset.seed(1523)\n\ndata_g1 &lt;- rnorm_multi(n = 250, \n                  mu = c(-0.25, 0, 0.25),\n                  sd = c(1, 1, 1),\n                  r = c(0.5), \n                  varnames = c(\"t_1\", \"t_2\", \"t_3\"),\n                  empirical = FALSE) %&gt;% \n  add_column(group = \"treatment\") %&gt;% \n  rownames_to_column(\"id\")\n\ndata_g2 &lt;- rnorm_multi(n = 250, \n                  mu = c(-0.25, -0.15, -0.05),\n                  sd = c(1, 1, 1),\n                  r = c(0.5), \n                  varnames = c(\"t_1\", \"t_2\", \"t_3\"),\n                  empirical = FALSE) %&gt;% \n  add_column(group = \"control\") %&gt;% \n  mutate(id = c(251:500))\n\nd &lt;- rbind(data_g1,data_g2)\n\nd_long &lt;- d %&gt;% \n  pivot_longer(starts_with(\"t\")) %&gt;% \n  mutate(time = as.numeric(gsub(\"t_\",\"\",name))) %&gt;% \n  select(!name)\n\n\n\n2.1 Simulate response data\n\nCode# item list for simulation\ntlist &lt;- list(\n  t1 = list(1.2, 1.8, 2.4),\n  t2 = list(-1.3, -0.5, 0.5),\n  t3 = list(-0.3, 0.3, 1.2),\n  t4 = list(0.1, 0.6, 1.6),\n  t5 = list(-0.3, 0.7, 1.5),\n  t6 = list(-1.6, -1, -0.3),\n  t7 = list(1, 1.8, 2.5),\n  t8 = list(-1.3, -0.7, 0.4),\n  t9 = list(-0.8, 1.4, 1.9),\n  t10 = list(0.25, 1.25, 2.15)\n)\n\ninputDeltas &lt;- tibble(\n  q1 = c(1.2, 1.8, 2.4),\n  q2 = c(-1.3, -0.5, 0.5),\n  q3 = c(-0.3, 0.3, 1.2),\n  q4 = c(0.1, 0.6, 1.6),\n  q5 = c(-0.3, 0.7, 1.5),\n  q6 = c(-1.6, -1, -0.3),\n  q7 = c(1, 1.8, 2.5),\n  q8 = c(-1.3, -0.7, 0.4),\n  q9 = c(-0.8, 1.4, 1.9),\n  q10 = c(0.25, 1.25, 2.15)\n) %&gt;%\n  t() %&gt;%\n  as.data.frame() %&gt;%\n  mutate(Average = rowMeans(., na.rm = T)) %&gt;% \n  mutate_if(is.double, round, digits = 2) %&gt;% \n  rownames_to_column(var = \"Item\") %&gt;% \n  dplyr::rename(T1 = V1,\n         T2 = V2,\n         T3 = V3)\n\n# simulate response data based on the above defined item thresholds\ntd &lt;- SimPartialScore(\n  deltaslist = tlist,\n  thetavec = d_long$value\n) %&gt;%\n  as.data.frame()\n\n\n\n2.2 Estimating item threshold locations\nWe could use the parameters from the input, but to add some real world usage to the setup, we’ll stack the response data and estimate the item threshold locations using the eRm package with the Partial Credig Model and Conditional Maximum Likelihood.\n\nCodeerm_item_parameters &lt;- RIitemparams(td, output = \"dataframe\") %&gt;% \n  select(!Location) %&gt;% \n  rename(T1 = `Threshold 1`,\n         T2 = `Threshold 2`,\n         T3 = `Threshold 3`) %&gt;% \n  as.matrix()\n\n# center item parameters to sum = 0\nerm_item_parameters &lt;- erm_item_parameters - mean(erm_item_parameters)\n\n\n\n2.3 Estimating person locations and SEM\nUsing Weighted Likelihood (Warm, 1989) to minimize bias.\n\nCode# estimate thetas/person locations, based on eRm estimated item thresholds\nerm_thetas &lt;- RIestThetas(td, itemParams = erm_item_parameters)\n\n# estimate measurement error (SEM)\nerm_sem &lt;- map_vec(erm_thetas, ~ catR::semTheta(.x, it = erm_item_parameters, method = \"WL\", model = \"PCM\"))\n\nd_long$erm_thetas &lt;- erm_thetas\nd_long$erm_sem &lt;- erm_sem"
  },
  {
    "objectID": "ttestChange.html#change",
    "href": "ttestChange.html#change",
    "title": "Analyzing individual change with t-tests",
    "section": "\n3 Change",
    "text": "3 Change\nHow many have changed 0.5+ logits (the mean change simulated, also corresponding to 0.5 SD) in the generated data? This could serve as a reference.\n\nCoded &lt;- d %&gt;% \n  mutate(change = t_3 - t_1)\n\nsummary(d$change)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-2.4126 -0.4427  0.2565  0.2682  0.9909  3.0004 \n\nCodesd(d$change)\n\n[1] 1.00556\n\nCodesd(d$t_3)\n\n[1] 1.02455\n\nCodeggplot(d, aes(x = change, fill = group, color = group)) +\n  #geom_histogram() +\n  stat_dotsinterval(color = \"black\", slab_color = \"white\", slab_linewidth = 0.5) +\n  facet_wrap(~ group) +\n  guides(fill = \"none\", color = \"none\")\n\n\n\n\n\n\nCoded %&gt;% \n  mutate(change_grp = case_when(change &gt; 0.5 ~ \"Improved &gt; 0.5\",\n                                change &lt; -0.5 ~ \"Worsened &gt; 0.5\",\n                                TRUE ~ \"In between\")) %&gt;% \n  group_by(group) %&gt;% \n  count(change_grp) %&gt;% \n  kbl_rise(tbl_width = 40) %&gt;% \n  row_spec(c(1,4),bold=TRUE)\n\n\n\n group \n    change_grp \n    n \n  \n\n\n control \n    Improved &gt; 0.5 \n    82 \n  \n\n control \n    In between \n    95 \n  \n\n control \n    Worsened &gt; 0.5 \n    73 \n  \n\n treatment \n    Improved &gt; 0.5 \n    124 \n  \n\n treatment \n    In between \n    85 \n  \n\n treatment \n    Worsened &gt; 0.5 \n    41 \n  \n\n\n\n\n\n3.1 Test information function\n\nCodeRItif(td, samplePSI = TRUE)"
  },
  {
    "objectID": "ttestChange.html#t-tests-of-individual-change",
    "href": "ttestChange.html#t-tests-of-individual-change",
    "title": "Analyzing individual change with t-tests",
    "section": "\n4 t-tests of individual change",
    "text": "4 t-tests of individual change\nOnly using t1 and t3 estimated person locations/thetas and SEM values.\n\nCoded_wide_tt &lt;- d_long %&gt;% \n  pivot_wider(values_from = c(erm_thetas,erm_sem),\n              id_cols = c(id,group),\n              names_from = time\n              ) %&gt;% \n  mutate(id = as.numeric(id))\n\n# basic formula for t-test\n# (d_wide_tt$erm_thetas_1[1] - d_wide_tt$erm_thetas_3[1]) / sqrt(d_wide_tt$erm_sem_1[1] + d_wide_tt$erm_sem_3[1])\n\n# t-tests for all rows in dataframe\nt_values &lt;- c()\nfor (i in 1:nrow(d_wide_tt)) {\n t_values[i] &lt;- (d_wide_tt$erm_thetas_3[i] - d_wide_tt$erm_thetas_1[i]) / sqrt(d_wide_tt$erm_sem_3[i] + d_wide_tt$erm_sem_1[i])\n}\n\ndata.frame(t_values = t_values,\n           group = rep(c(\"Intervention\",\"Control\"), each = 250)) %&gt;% \n  mutate(result = case_when(t_values &gt; 1.96 ~ \"Improved\",\n                            t_values &lt; -1.96 ~ \"Worsened\",\n                            TRUE ~ \"No detectable change\")) %&gt;% \n  group_by(group) %&gt;% \n  count(result) %&gt;% \n  kbl_rise(tbl_width = 40) %&gt;% \n  row_spec(c(1,4),bold=TRUE)\n\n\n\n group \n    result \n    n \n  \n\n\n Control \n    Improved \n    12 \n  \n\n Control \n    No detectable change \n    229 \n  \n\n Control \n    Worsened \n    9 \n  \n\n Intervention \n    Improved \n    27 \n  \n\n Intervention \n    No detectable change \n    219 \n  \n\n Intervention \n    Worsened \n    4 \n  \n\n\n\n\n\n4.1 “Recovery” of n changed\nAgain, strongly affected by precision/reliability"
  },
  {
    "objectID": "simcutoffs.html",
    "href": "simcutoffs.html",
    "title": "Simulation based cutoff values for Rasch item fit and residual correlations",
    "section": "",
    "text": "It has long been known that rule-of-thumb cutoff values in psychometrics are not optimal (and often misguiding), and that simulations are helpful for determining appropriate cutoff values based on the properties of the sample and items being analyzed. This actually goes for factor analysis, as well as item response theory and Rasch measurement theory. In recent years, we have seen a number of interactive Shiny apps made available to help solve this issue, which is clearly a step in the right direction.\nMy approach here is to write functions to help users easily run these simulations on their computers in R, when they do their psychometric analysis.\nThis blog post will be incorporated into the RISEkbmRasch vignette at some point, but as I just put quite a bit of time into developing these functions I wanted to write something about it. Also, I have not put all that much time into testing, so I hope to hear about any problems you may run into if you try these functions out.\nFinally, I want to thank Karl Bang Christensen for a very nice presentation on item fit and simulations at the Scandinavian Applied Measurement Conference, which made me think about these things a lot until I came up with the idea to implement these functions."
  },
  {
    "objectID": "simcutoffs.html#background",
    "href": "simcutoffs.html#background",
    "title": "Simulation based cutoff values for Rasch item fit and residual correlations",
    "section": "",
    "text": "It has long been known that rule-of-thumb cutoff values in psychometrics are not optimal (and often misguiding), and that simulations are helpful for determining appropriate cutoff values based on the properties of the sample and items being analyzed. This actually goes for factor analysis, as well as item response theory and Rasch measurement theory. In recent years, we have seen a number of interactive Shiny apps made available to help solve this issue, which is clearly a step in the right direction.\nMy approach here is to write functions to help users easily run these simulations on their computers in R, when they do their psychometric analysis.\nThis blog post will be incorporated into the RISEkbmRasch vignette at some point, but as I just put quite a bit of time into developing these functions I wanted to write something about it. Also, I have not put all that much time into testing, so I hope to hear about any problems you may run into if you try these functions out.\nFinally, I want to thank Karl Bang Christensen for a very nice presentation on item fit and simulations at the Scandinavian Applied Measurement Conference, which made me think about these things a lot until I came up with the idea to implement these functions."
  },
  {
    "objectID": "simcutoffs.html#residual-correlations",
    "href": "simcutoffs.html#residual-correlations",
    "title": "Simulation based cutoff values for Rasch item fit and residual correlations",
    "section": "\n3 Residual correlations",
    "text": "3 Residual correlations\nThis is the simpler of the two functions that have been added. It is based on the simulation study by Christensen et al. (2017).\n\nCodelibrary(RISEkbmRasch)\n\n\nFor simplicity, we will use the dataset pcmdat2 included in the eRm package, which has polytomous data. Dichotomous data also works with all functions in this text. The functions will determine the proper model based on the data structure.\n\nCodesimres1 &lt;- RIgetResidCor(pcmdat2, iterations = 1000, cpu = 8)\n\n\nWhile we are mostly interested in the 99% percentile from the simulation (p99 below), we will save the output of the simulation into the list object res_cor.\n\nCodeglimpse(simres1)\n\nList of 8\n $ results          :'data.frame':  1000 obs. of  3 variables:\n  ..$ mean: num [1:1000] -0.246 -0.26 -0.248 -0.262 -0.252 ...\n  ..$ max : num [1:1000] -0.0915 -0.175 -0.0972 -0.1732 -0.1871 ...\n  ..$ diff: num [1:1000] 0.1543 0.0851 0.1506 0.089 0.0649 ...\n $ actual_iterations: num 1000\n $ sample_n         : int 300\n $ sample_summary   : 'summaryDefault' Named num [1:6] -3.873 0.107 0.704 0.684 1.337 ...\n  ..- attr(*, \"names\")= chr [1:6] \"Min.\" \"1st Qu.\" \"Median\" \"Mean\" ...\n $ max_diff         : num 0.229\n $ sd_diff          : num 0.0336\n $ p95              : Named num 0.152\n  ..- attr(*, \"names\")= chr \"95%\"\n $ p99              : Named num 0.174\n  ..- attr(*, \"names\")= chr \"99%\"\n\n\nThe object contains a dataframe with mean and max values for residual correlations within each dataset simulated, and the difference between the mean and the max. This difference is the key metric we are interested in.\nThe max value will increase with the number of iterations, and it seems to be a bit spurious, so I would suggest to use the 99% percentile value as the cutoff. Based on the simulations I have made so far, it seems that 1000 iterations may be sufficient for a reasonably accurate 99% percentile value (p99) value. For more detailed information on the topic I refer to Christensen et al. (2017).\n\nCodeRIresidcorr(pcmdat2, cutoff = simres1$p99)\n\n\n\n   \n    I1 \n    I2 \n    I3 \n    I4 \n  \n\n\n I1 \n     \n     \n     \n     \n  \n\n I2 \n    -0.13 \n     \n     \n     \n  \n\n I3 \n    -0.29 \n    -0.33 \n     \n     \n  \n\n I4 \n    -0.38 \n    -0.44 \n    0.2 \n     \n  \n\n\nNote: \n\n Relative cut-off value (highlighted in red) is -0.052, which is 0.174 above the average correlation (-0.226).\n\n\n\n\nWe can see that items 3 and 4 have a residual correlation between them that is quite a bit above the threshold value.\nSince the results of the simulation is included in the output object, we can investigate it further.\n\nCodehist(simres1$results$diff, breaks = 50, col = \"lightblue\")\nabline(v = simres1$p99, col = \"red\")\nabline(v = simres1$p95, col = \"orange\")\n\n\n\n\n\n\n\n\nCodesummary(simres1$results$diff)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.01344 0.06429 0.08356 0.08805 0.10804 0.22923"
  },
  {
    "objectID": "simcutoffs.html#item-fit",
    "href": "simcutoffs.html#item-fit",
    "title": "Simulation based cutoff values for Rasch item fit and residual correlations",
    "section": "\n3 Item fit",
    "text": "3 Item fit\nWhile conditional item fit is a huge step towards getting correct item fit values, no matter what the sample size is (Buchardt et al., 2023; Müller, 2020), we also need to know the range of values that are plausible for items fitting the Rasch model in the current context. The specific properties of the sample and the items is used to simulate multiple datasets that fit the Rasch model, to understand the variation in item fit that can be expected. The simulation results can then be compared with the observed data.\n\n\n\n\n\n\nNote\n\n\n\nWe will use 1000 simulations, but no extensive tests have been made (yet) to determine a reasonable number of simulations. The more items/thresholds and the bigger your sample size, the more time this simulation will take. If you have more cpu cores, this will reduce the time (please remember to not use all cores, leave 1-2 unused). To give some reference, the code below (n = 300, 4 items, 4 response categories) using 500 iterations took 7.7 seconds on 8 cpu cores and 11.7 seconds on 4 cores. 1000 iterations on 8 cores took 12.8 seconds (based on single runs).\n\n\n\nCodeitemfit_sim &lt;- RIgetfit(pcmdat2, iterations = 1000, cpu = 8)\n\n\nThe output is a list object consisting of one dataframe per iteration. We can look at iteration 1:\n\nCodeitemfit_sim[[1]]\n\n  Item InfitMSQ OutfitMSQ\n1   V1    0.938     0.908\n2   V2    1.004     1.064\n3   V3    1.012     1.048\n4   V4    1.066     1.065\n\n\nThis object can in turn be used with three different functions. Most importantly, you can use it with RIitemfit() to set cutoff values for both MSQ and ZSTD based on your sample size and item parameters. This uses the 1st and 99th percentile values for each individual item.\n\nCodeRIitemfit(pcmdat2, simcut = itemfit_sim)\n\n\n\n Item \n    InfitMSQ \n    Infit thresholds \n    OutfitMSQ \n    Outfit thresholds \n  \n\n\n I1 \n    1.08 \n    [0.874, 1.141] \n    1.069 \n    [0.844, 1.192] \n  \n\n I2 \n    1.155 \n    [0.854, 1.164] \n    1.084 \n    [0.792, 1.269] \n  \n\n I3 \n    0.828 \n    [0.866, 1.146] \n    0.802 \n    [0.806, 1.217] \n  \n\n I4 \n    1.007 \n    [0.837, 1.165] \n    1.024 \n    [0.813, 1.198] \n  \n\n\nNote: \n\n MSQ values based on conditional calculations (n = 300).                                Simulation based thresholds based on 1000 simulated datasets.\n\n\n\n\nThe function RIgetfitPlot() uses the package ggdist to plot the distribution of fit values from the simulation results.\n\nCodeRIgetfitPlot(itemfit_sim)\n\n\n\n\n\n\n\nAs a side note, a graphical representation of conditional item fit across class intervals can be helpful to further analyze our observed data.\n\nCodelibrary(RASCHplot) # devtools::install_github(\"ERRTG/RASCHplot\")\nCICCplot(PCM(pcmdat2), which.item = 1:4, grid.items = TRUE)"
  },
  {
    "objectID": "simcutoffs.html#session-info",
    "href": "simcutoffs.html#session-info",
    "title": "Simulation based cutoff values for Rasch item fit and residual correlations",
    "section": "\n6 Session info",
    "text": "6 Session info\n\nCodesessionInfo() \n\nR version 4.4.1 (2024-06-14)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sonoma 14.6.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Stockholm\ntzcode source: internal\n\nattached base packages:\n [1] parallel  grid      stats4    stats     graphics  grDevices utils    \n [8] datasets  methods   base     \n\nother attached packages:\n [1] RASCHplot_0.1.0    ggdist_3.3.2       doParallel_1.0.17  iterators_1.0.14  \n [5] foreach_1.5.2      RISEkbmRasch_0.2.4 janitor_2.2.0      iarm_0.4.3        \n [9] hexbin_1.28.3      catR_3.17          glue_1.7.0         ggrepel_0.9.5     \n[13] patchwork_1.2.0    reshape_0.8.9      matrixStats_1.3.0  psychotree_0.16-1 \n[17] psychotools_0.7-4  partykit_1.2-21    mvtnorm_1.2-5      libcoin_1.0-10    \n[21] psych_2.4.6.26     mirt_1.42          lattice_0.22-6     eRm_1.0-6         \n[25] lubridate_1.9.3    forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4       \n[29] purrr_1.0.2        readr_2.1.5        tidyr_1.3.1        tibble_3.2.1      \n[33] ggplot2_3.5.1      tidyverse_2.0.0    kableExtra_1.4.0   formattable_0.2.1 \n\nloaded via a namespace (and not attached):\n  [1] later_1.3.2          splines_4.4.1        R.oo_1.26.0         \n  [4] cellranger_1.1.0     rpart_4.1.23         lifecycle_1.0.4     \n  [7] rstatix_0.7.2        rprojroot_2.0.4      globals_0.16.3      \n [10] MASS_7.3-61          backports_1.5.0      magrittr_2.0.3      \n [13] vcd_1.4-12           Hmisc_5.1-3          rmarkdown_2.27      \n [16] yaml_2.3.10          httpuv_1.6.15        sessioninfo_1.2.2   \n [19] pbapply_1.7-2        RColorBrewer_1.1-3   abind_1.4-5         \n [22] audio_0.1-11         quadprog_1.5-8       R.utils_2.12.3      \n [25] nnet_7.3-19          listenv_0.9.1        testthat_3.2.1.1    \n [28] RPushbullet_0.3.4    vegan_2.6-6.1        parallelly_1.38.0   \n [31] svglite_2.1.3        permute_0.9-7        codetools_0.2-20    \n [34] DT_0.33              xml2_1.3.6           tidyselect_1.2.1    \n [37] farver_2.1.2         base64enc_0.1-3      jsonlite_1.8.8      \n [40] progressr_0.14.0     Formula_1.2-5        survival_3.7-0      \n [43] systemfonts_1.1.0    tools_4.4.1          gnm_1.1-5           \n [46] Rcpp_1.0.13          mnormt_2.1.1         gridExtra_2.3       \n [49] xfun_0.46            here_1.0.1           mgcv_1.9-1          \n [52] distributional_0.4.0 ca_0.71.1            withr_3.0.1         \n [55] beepr_2.0            fastmap_1.2.0        fansi_1.0.6         \n [58] digest_0.6.36        mime_0.12            timechange_0.3.0    \n [61] R6_2.5.1             colorspace_2.1-1     R.methodsS3_1.8.2   \n [64] inum_1.0-5           utf8_1.2.4           generics_0.1.3      \n [67] data.table_1.15.4    SimDesign_2.16       htmlwidgets_1.6.4   \n [70] pkgconfig_2.0.3      gtable_0.3.5         lmtest_0.9-40       \n [73] brio_1.1.5           htmltools_0.5.8.1    carData_3.0-5       \n [76] scales_1.3.0         corrplot_0.92        snakecase_0.11.1    \n [79] knitr_1.48           rstudioapi_0.16.0    reshape2_1.4.4      \n [82] tzdb_0.4.0           checkmate_2.3.2      nlme_3.1-165        \n [85] curl_5.2.1           zoo_1.8-12           cachem_1.1.0        \n [88] relimp_1.0-5         vcdExtra_0.8-5       foreign_0.8-87      \n [91] pillar_1.9.0         vctrs_0.6.5          promises_1.3.0      \n [94] ggpubr_0.6.0         car_3.1-2            xtable_1.8-4        \n [97] Deriv_4.1.3          cluster_2.1.6        dcurver_0.9.2       \n[100] GPArotation_2024.3-1 htmlTable_2.4.3      evaluate_0.24.0     \n[103] cli_3.6.3            compiler_4.4.1       rlang_1.1.4         \n[106] future.apply_1.11.2  ggsignif_0.6.4       labeling_0.4.3      \n[109] plyr_1.8.9           stringi_1.8.4        viridisLite_0.4.2   \n[112] munsell_0.5.1        Matrix_1.7-0         qvcalc_1.0.3        \n[115] hms_1.1.3            future_1.34.0        shiny_1.9.1         \n[118] broom_1.0.6          memoise_2.0.1        ggstance_0.3.7      \n[121] readxl_1.4.3"
  },
  {
    "objectID": "simcutoffs.html#conditional-item-fit",
    "href": "simcutoffs.html#conditional-item-fit",
    "title": "Simulation based cutoff values for Rasch item fit and residual correlations",
    "section": "\n4 Conditional item fit",
    "text": "4 Conditional item fit\nWhile conditional item fit is a huge step towards getting correct item fit values (Buchardt et al., 2023; Christensen & Kreiner, 2012; Müller, 2020), we also need to know the range of values that are plausible for items fitting the Rasch model in the current context. The specific properties of the sample and the items is used to simulate multiple datasets that fit the Rasch model, to understand the variation in item fit that can be expected. The simulation results can then be compared with the observed data.\n\n\n\n\n\n\nNote\n\n\n\nWe will use 1000 simulations, but no extensive tests have been made (yet) to determine a reasonable number of simulations. The more items/thresholds and the bigger your sample size, the more time this simulation will take. If you have more cpu cores, this will reduce the time (please remember to not use all cores, leave 1-2 unused).\nTo give some reference, the code below (n = 300, 4 items, 4 response categories per item) using 500 iterations took 3.7 seconds on 4 cpu cores. 1000 iterations on 8 cores took 4.2 seconds (based on single runs). I recommend library(tictoc) to make timing easy.\n\n\n\nCodesimfit1 &lt;- RIgetfit(pcmdat2, iterations = 1000, cpu = 8)\n\n\nThe output is a list object consisting of one dataframe per iteration. We can look at iteration 1:\n\nCodesimfit1[[1]]\n\n  Item InfitMSQ OutfitMSQ\n1   I1    0.962     0.969\n2   I2    0.964     0.946\n3   I3    1.041     1.027\n4   I4    1.020     1.023\n\n\nThis object can in turn be used with three different functions. Most importantly, you can use it with RIitemfit() to automatically set the simulation based cutoff values for infit & outfit MSQ based on your sample size and item parameters. RIitemfit() uses the .05 and 99.5 percentile values for each individual item. The cutoff limit might be added as a user option later. You can optionally sort the table output according to misfit by using sort = \"infit\".\n\nCodeRIitemfit(pcmdat2, simfit1)\n\n\n\n Item \n    InfitMSQ \n    Infit thresholds \n    OutfitMSQ \n    Outfit thresholds \n    Infit diff \n    Outfit diff \n  \n\n\n I1 \n    1.08 \n    [0.853, 1.138] \n    1.069 \n    [0.835, 1.201] \n    no misfit \n    no misfit \n  \n\n I2 \n    1.155 \n    [0.838, 1.169] \n    1.084 \n    [0.794, 1.256] \n    no misfit \n    no misfit \n  \n\n I3 \n    0.828 \n    [0.849, 1.174] \n    0.802 \n    [0.792, 1.238] \n    0.021 \n    no misfit \n  \n\n I4 \n    1.007 \n    [0.838, 1.171] \n    1.024 \n    [0.808, 1.22] \n    no misfit \n    no misfit \n  \n\n\nNote: \n\n MSQ values based on conditional calculations (n = 300).                                Simulation based thresholds based on 1000 simulated datasets.\n\n\n\n\nThe function RIgetfitPlot() uses the package ggdist to plot the distribution of fit values from the simulation results. You can get the observed conditional item fit included in the plot by using the option data = yourdataframe.\n\nCodeRIgetfitPlot(simfit1, pcmdat2)"
  },
  {
    "objectID": "simcutoffs.html#visualizing-conditional-fit",
    "href": "simcutoffs.html#visualizing-conditional-fit",
    "title": "Simulation based cutoff values for Rasch item fit and residual correlations",
    "section": "\n5 Visualizing conditional fit",
    "text": "5 Visualizing conditional fit\nAs a side note, a graphical representation of conditional item fit across class intervals (Buchardt et al., 2023) can be helpful to further analyze our observed data.\n\nCodelibrary(RASCHplot) # devtools::install_github(\"ERRTG/RASCHplot\")\nCICCplot(PCM(pcmdat2), which.item = 3)\n\n$I3"
  },
  {
    "objectID": "simcutoffs.html#simulation-methodology",
    "href": "simcutoffs.html#simulation-methodology",
    "title": "Simulation based cutoff values for Rasch item fit and residual correlations",
    "section": "\n2 Simulation methodology",
    "text": "2 Simulation methodology\nThe process is similar for both functions:\n\nEstimate item parameters (using conditional maximum likelihood) and person parameters (thetas, using weighted likelihood).\nResample thetas with replacement (parametric bootstrapping) and simulate response data (that fit a Rasch model) based on the resampled thetas and previously estimated item parameters\nCalculate conditional item fit/residual correlations for the simulated response data\nRepeat 2 & 3 across n iterations.\n\nThe simulation then results in an empirical distribution of plausible values."
  },
  {
    "objectID": "est_comp.html",
    "href": "est_comp.html",
    "title": "Comparing Rasch packages/estimators",
    "section": "",
    "text": "I’m doing comparisons of the bias in the estimators for the Partial Credit Model (PCM) implemented in Rasch R packages and thought I would share a bit of code and simulated data. There will be more extensive simulations and comparisons coming along, varying targeting and sample distribution.\nFor this example we have a simple setup:\n\n250 datasets\neach dataset has 9 items and 4 thresholds (5 response categories)\neach dataset has 720 respondents (20 per threshold estimated, which should be plenty)\n\nThe .rds data file contains a list object with the 250 datasets, and each dataset is accompanied by a matrix of item threshold parameters and a vector of theta values used to generate the response data.\n\nthe vector of theta values is normally distributed with a mean and SD closely matching that of the item parameters\n\nWe have four packages in the comparison:\n\n\neRm - Conditional Maximum Likelihood (CML)\n\nTAM - Marginal ML (MML)\n\npairwise - Pairwise CML (PCML)\n\nmirt - fixed quadrature expectation-maximization algorithm\n\nOther estimation methods are available in TAM and mirt, but we’ll just test these for now.\nThe datafile is available in the Github repo."
  },
  {
    "objectID": "est_comp.html#background",
    "href": "est_comp.html#background",
    "title": "Comparing Rasch packages/estimators",
    "section": "",
    "text": "I’m doing comparisons of the bias in the estimators for the Partial Credit Model (PCM) implemented in Rasch R packages and thought I would share a bit of code and simulated data. There will be more extensive simulations and comparisons coming along, varying targeting and sample distribution.\nFor this example we have a simple setup:\n\n250 datasets\neach dataset has 9 items and 4 thresholds (5 response categories)\neach dataset has 720 respondents (20 per threshold estimated, which should be plenty)\n\nThe .rds data file contains a list object with the 250 datasets, and each dataset is accompanied by a matrix of item threshold parameters and a vector of theta values used to generate the response data.\n\nthe vector of theta values is normally distributed with a mean and SD closely matching that of the item parameters\n\nWe have four packages in the comparison:\n\n\neRm - Conditional Maximum Likelihood (CML)\n\nTAM - Marginal ML (MML)\n\npairwise - Pairwise CML (PCML)\n\nmirt - fixed quadrature expectation-maximization algorithm\n\nOther estimation methods are available in TAM and mirt, but we’ll just test these for now.\nThe datafile is available in the Github repo."
  },
  {
    "objectID": "est_comp.html#data-import",
    "href": "est_comp.html#data-import",
    "title": "Comparing Rasch packages/estimators",
    "section": "\n2 Data import",
    "text": "2 Data import\n\nCodelibrary(tidyverse)\nlibrary(eRm)\nlibrary(janitor)\nlibrary(TAM)\nlibrary(mirt)\nlibrary(pairwise)\nlibrary(ggdist)\nlibrary(doParallel)\nlibrary(tinytable)\n\n### some commands exist in multiple packages, here we define preferred ones that are frequently used\nselect &lt;- dplyr::select\ncount &lt;- dplyr::count\nrecode &lt;- car::recode\nrename &lt;- dplyr::rename\n\n# read 250 simulated datasets, stored in a list() object\nsim_data_4t &lt;- readRDS(\"sim_data_4t.rds\")"
  },
  {
    "objectID": "est_comp.html#estimation",
    "href": "est_comp.html#estimation",
    "title": "Comparing Rasch packages/estimators",
    "section": "\n3 Estimation",
    "text": "3 Estimation\nWe’ll make use of library(doParallel) for multicore processing.\n\nCoderegisterDoParallel(cores = 8)\niterations = 250\n\nsim_results_4t &lt;- list()\n\nsim_results_4t &lt;- foreach(i = 1:iterations) %dopar% {\n\n  input_params &lt;- sim_data_4t[[i]]$input_params\n  input_thetas &lt;- sim_data_4t[[i]]$input_thetas\n  testData &lt;- sim_data_4t[[i]]$data\n\n  # check mean/centrality (item parameters should have been centered before data generation)\n  input_params_correction &lt;- mean(input_params)\n\n  # eRm\n  erm_out &lt;- PCM(testData)\n  erm_params &lt;- thresholds(erm_out)[[3]][[1]][,-1] %&gt;%\n    as.data.frame() %&gt;%\n    set_names(c(\"T1\",\"T2\",\"T3\",\"T4\")) %&gt;%\n    as.matrix()\n\n  erm_params_c &lt;- erm_params - mean(erm_params) + input_params_correction\n\n  # TAM\n  tam_out &lt;- tam(as.matrix(testData), irtmodel = \"PCM\", verbose = FALSE)\n\n  tam_params &lt;- tam_out$item_irt %&gt;%\n    as.data.frame() %&gt;%\n    select(starts_with(\"tau\")) %&gt;%\n    set_names(c(\"T1\",\"T2\",\"T3\",\"T4\")) %&gt;%\n    as.matrix()\n\n  tam_params_c &lt;- tam_params - mean(tam_params) + input_params_correction\n\n  # mirt\n  mirt_out &lt;- mirt(data = testData, model = 1, itemtype = \"Rasch\", verbose = FALSE)\n  mirt_params &lt;- coef(mirt_out, simplify = TRUE, IRTpars = TRUE)$items %&gt;%\n    as.data.frame() %&gt;%\n    select(!a) %&gt;%\n    set_names(c(\"T1\",\"T2\",\"T3\",\"T4\")) %&gt;%\n    as.matrix()\n  mirt_params_c &lt;- mirt_params - mean(mirt_params) + input_params_correction\n\n  # PAIR\n  pair_out &lt;- pair(testData)\n  pair_params &lt;- deltapar(pair_out) %&gt;%\n    as.data.frame()\n\n  pair_params &lt;- pair_params[,-1] %&gt;%\n    set_names(c(\"T1\",\"T2\",\"T3\",\"T4\")) %&gt;%\n    as.matrix()\n\n  pair_params_c &lt;- pair_params - mean(pair_params) + input_params_correction\n\n  # combine item parameters and calculate lowest to highest threshold distances\n  input_params %&gt;%\n    as.data.frame() %&gt;%\n    rename(T1 = V1,\n           T2 = V2,\n           T3 = V3,\n           T4 = V4) %&gt;%\n    add_column(Item = c(1:9),\n               Type = \"Input\") %&gt;%\n    bind_rows(\n      erm_params_c %&gt;%\n        as.data.frame() %&gt;%\n        add_column(Item = c(1:9),\n                   Type = \"eRm\")\n    ) %&gt;%\n    bind_rows(\n      tam_params_c %&gt;%\n        as.data.frame() %&gt;%\n        add_column(Item = c(1:9),\n                   Type = \"TAM\")\n    ) %&gt;%\n    bind_rows(\n      mirt_params_c %&gt;%\n        as.data.frame() %&gt;%\n        add_column(Item = c(1:9),\n                   Type = \"mirt\")\n    ) %&gt;%\n    bind_rows(\n      pair_params_c %&gt;%\n        as.data.frame() %&gt;%\n        add_column(Item = c(1:9),\n                   Type = \"PAIR\")\n    ) %&gt;%\n    remove_rownames()\n}"
  },
  {
    "objectID": "est_comp.html#results",
    "href": "est_comp.html#results",
    "title": "Comparing Rasch packages/estimators",
    "section": "\n4 Results",
    "text": "4 Results\n\nCode# collect item threshold parameters to a single dataframe\nresults_params_4t &lt;- map_df(1:iterations, ~ sim_results_4t[[.x]] %&gt;%\n                               mutate(iteration = .x))\n\n\n\n4.1 Summary table MAE\nMean Absolute Error\n\nCode# calculate absolute differences between input and estimated item thresholds per estimator, average by item\nresults_params_diff_4t &lt;- results_params_4t %&gt;%\n  pivot_wider(\n    values_from = c(\"T1\", \"T2\", \"T3\", \"T4\"),\n    names_from = \"Type\",\n    id_cols = c(\"iteration\", \"Item\")\n  ) %&gt;%\n  group_by(iteration, Item) %&gt;%\n  summarise(\n    diff_eRm = sum(abs(T1_Input - T1_eRm) + abs(T2_Input - T2_eRm) + abs(T3_Input - T3_eRm) + abs(T4_Input - T4_eRm))/4,\n    diff_TAM = sum(abs(T1_Input - T1_TAM) + abs(T2_Input - T2_TAM) + abs(T3_Input - T3_TAM) + abs(T4_Input - T4_TAM))/4,\n    diff_mirt = sum(abs(T1_Input - T1_mirt) + abs(T2_Input - T2_mirt) + abs(T3_Input - T3_mirt) + abs(T4_Input - T4_mirt))/4,\n    diff_PAIR = sum(abs(T1_Input - T1_PAIR) + abs(T2_Input - T2_PAIR) + abs(T3_Input - T3_PAIR) + abs(T4_Input - T4_PAIR))/4\n  ) %&gt;%\n  ungroup() %&gt;%\n  pivot_longer(\n    cols = c(diff_eRm, diff_TAM,diff_mirt,diff_PAIR),\n    names_to = c(NA, \"Estimator\"),\n    names_sep = \"_\",\n    values_to = \"diff\"\n  )\n\n# produce table with summary stats per estimator/package\nresults_params_diff_4t %&gt;%\n  group_by(Estimator) %&gt;%\n  summarise(\n    Median = median(diff),\n    MAD = mad(diff),\n    IQR = IQR(diff),\n    Mean = mean(diff),\n    SD = sd(diff)\n  ) %&gt;%\n  mutate(across(where(is.numeric), ~ round(.x,3))) %&gt;%\n  rename(Package = Estimator) %&gt;%\n  arrange(Median) %&gt;%\n  tt()\n\n \n\n  \n    \n\ntinytable_0po126oqgr0buj0q9gye\n\n\n      \n\nPackage\n                Median\n                MAD\n                IQR\n                Mean\n                SD\n              \n\n\nmirt\n                  0.101\n                  0.043\n                  0.059\n                  0.106\n                  0.043\n                \n\neRm \n                  0.102\n                  0.043\n                  0.059\n                  0.106\n                  0.043\n                \n\nTAM \n                  0.140\n                  0.064\n                  0.087\n                  0.152\n                  0.069\n                \n\nPAIR\n                  0.146\n                  0.065\n                  0.091\n                  0.157\n                  0.070\n                \n\n\n\n\n    \n\n\n\n4.2 Summary table RMSE\nRoot Mean Squared Error\n\nCode# RMSE\nresults_params_4t %&gt;%\n  pivot_wider(\n    values_from = c(\"T1\", \"T2\", \"T3\", \"T4\"),\n    names_from = \"Type\",\n    id_cols = c(\"iteration\", \"Item\")\n  ) %&gt;%\n  group_by(iteration, Item) %&gt;% # sqrt(mean((data$actual - data$predicted)^2))\n  summarise(\n    rmse_eRm = sqrt(mean(((T1_Input - T1_eRm)^2) + ((T2_Input - T2_eRm)^2) + ((T3_Input - T3_eRm)^2) + ((T4_Input - T4_eRm))^2)),\n        rmse_TAM = sqrt(mean(((T1_Input - T1_TAM)^2) + ((T2_Input - T2_TAM)^2) + ((T3_Input - T3_TAM)^2) + ((T4_Input - T4_TAM))^2)),\n        rmse_mirt = sqrt(mean(((T1_Input - T1_mirt)^2) + ((T2_Input - T2_mirt)^2) + ((T3_Input - T3_mirt)^2) + ((T4_Input - T4_mirt))^2)),\n        rmse_PAIR = sqrt(mean(((T1_Input - T1_PAIR)^2) + ((T2_Input - T2_PAIR)^2) + ((T3_Input - T3_PAIR)^2) + ((T4_Input - T4_PAIR))^2))\n  ) %&gt;%\n  ungroup() %&gt;%\n  pivot_longer(\n    cols = c(rmse_eRm, rmse_TAM,rmse_mirt,rmse_PAIR),\n    names_to = c(NA, \"Estimator\"),\n    names_sep = \"_\",\n    values_to = \"rmse\"\n  ) %&gt;% \n  group_by(Estimator) %&gt;%\n  summarise(\n    Median = median(rmse),\n    MAD = mad(rmse),\n    IQR = IQR(rmse),\n    Mean = mean(rmse),\n    SD = sd(rmse)\n  ) %&gt;%\n  mutate(across(where(is.numeric), ~ round(.x,3))) %&gt;%\n  rename(Package = Estimator) %&gt;%\n  arrange(Median) %&gt;% \n  tt()\n\n \n\n  \n    \n\ntinytable_q26dyrtpg74yhyxvj2vb\n\n\n      \n\nPackage\n                Median\n                MAD\n                IQR\n                Mean\n                SD\n              \n\n\nmirt\n                  0.240\n                  0.103\n                  0.138\n                  0.252\n                  0.101\n                \n\neRm \n                  0.242\n                  0.102\n                  0.137\n                  0.253\n                  0.101\n                \n\nTAM \n                  0.330\n                  0.147\n                  0.200\n                  0.350\n                  0.148\n                \n\nPAIR\n                  0.344\n                  0.149\n                  0.204\n                  0.364\n                  0.151\n                \n\n\n\n\n    \n\n\n\n4.3 Thresholds summary MAE\n\nCode# table summarizing all thresholds and estimators\nresults_params_4t %&gt;%\n  pivot_wider(values_from = c(\"T1\", \"T2\", \"T3\", \"T4\"),\n              names_from = \"Type\",\n              id_cols = c(\"iteration\",\"Item\")\n  ) %&gt;%\n  group_by(iteration,Item) %&gt;%\n  summarise(\n    diff_eRm.T1 = abs(T1_eRm - T1_Input),\n    diff_eRm.T2 = abs(T2_eRm - T2_Input),\n    diff_eRm.T3 = abs(T3_eRm - T3_Input),\n    diff_eRm.T4 = abs(T4_eRm - T4_Input),\n    diff_TAM.T1 = abs(T1_TAM - T1_Input),\n    diff_TAM.T2 = abs(T2_TAM - T2_Input),\n    diff_TAM.T3 = abs(T3_TAM - T3_Input),\n    diff_TAM.T4 = abs(T4_TAM - T4_Input),\n    diff_mirt.T1 = abs(T1_mirt - T1_Input),\n    diff_mirt.T2 = abs(T2_mirt - T2_Input),\n    diff_mirt.T3 = abs(T3_mirt - T3_Input),\n    diff_mirt.T4 = abs(T4_mirt - T4_Input),\n    diff_PAIR.T1 = abs(T1_PAIR - T1_Input),\n    diff_PAIR.T2 = abs(T2_PAIR - T2_Input),\n    diff_PAIR.T3 = abs(T3_PAIR - T3_Input),\n    diff_PAIR.T4 = abs(T4_PAIR - T4_Input)\n  ) %&gt;%\n  ungroup() %&gt;%\n  pivot_longer(cols = starts_with(\"diff\"),\n               names_to = c(\"Estimator\",\"Threshold\"),\n               names_sep = \"\\\\.\",\n               values_to = \"diff\") %&gt;%\n  mutate(Package = gsub(\"diff_\",\"\",Estimator)) %&gt;%\n  group_by(Package, Threshold) %&gt;%\n  summarise(\n    Median = median(diff),\n    MAD = mad(diff),\n    IQR = IQR(diff),\n    Mean = mean(diff),\n    SD = sd(diff)\n  ) %&gt;%\n  mutate(across(where(is.numeric), ~ round(.x,3))) %&gt;%\n  arrange(Threshold,Median) %&gt;%\n  tt() %&gt;% \n  style_tt(i = c(1, 5, 9, 13), j = 2, rowspan = 4, alignv = \"t\")\n\n \n\n  \n    \n\ntinytable_bebptriuqhnmt4cb6k99\n\n\n      \n\nPackage\n                Threshold\n                Median\n                MAD\n                IQR\n                Mean\n                SD\n              \n\n\neRm \n                  T1\n                  0.106\n                  0.093\n                  0.130\n                  0.127\n                  0.097\n                \n\nmirt\n                  T1\n                  0.106\n                  0.094\n                  0.131\n                  0.126\n                  0.097\n                \n\nTAM \n                  T1\n                  0.133\n                  0.116\n                  0.160\n                  0.157\n                  0.118\n                \n\nPAIR\n                  T1\n                  0.142\n                  0.118\n                  0.166\n                  0.164\n                  0.121\n                \n\neRm \n                  T2\n                  0.072\n                  0.063\n                  0.088\n                  0.085\n                  0.064\n                \n\nmirt\n                  T2\n                  0.072\n                  0.062\n                  0.087\n                  0.085\n                  0.063\n                \n\nTAM \n                  T2\n                  0.123\n                  0.108\n                  0.153\n                  0.144\n                  0.106\n                \n\nPAIR\n                  T2\n                  0.129\n                  0.113\n                  0.158\n                  0.148\n                  0.109\n                \n\neRm \n                  T3\n                  0.072\n                  0.066\n                  0.094\n                  0.086\n                  0.066\n                \n\nmirt\n                  T3\n                  0.073\n                  0.067\n                  0.091\n                  0.085\n                  0.065\n                \n\nTAM \n                  T3\n                  0.119\n                  0.109\n                  0.153\n                  0.144\n                  0.110\n                \n\nPAIR\n                  T3\n                  0.120\n                  0.108\n                  0.155\n                  0.147\n                  0.113\n                \n\nmirt\n                  T4\n                  0.105\n                  0.091\n                  0.131\n                  0.127\n                  0.097\n                \n\neRm \n                  T4\n                  0.106\n                  0.093\n                  0.130\n                  0.128\n                  0.097\n                \n\nTAM \n                  T4\n                  0.138\n                  0.117\n                  0.164\n                  0.163\n                  0.121\n                \n\nPAIR\n                  T4\n                  0.144\n                  0.121\n                  0.171\n                  0.170\n                  0.129\n                \n\n\n\n\n    \n\n\n\n4.4 Figure\n\nCoderesults_params_4t %&gt;%\n  pivot_wider(values_from = c(\"T1\", \"T2\", \"T3\", \"T4\"),\n              names_from = \"Type\",\n              id_cols = c(\"iteration\",\"Item\")\n  ) %&gt;%\n  group_by(iteration,Item) %&gt;%\n  summarise(\n    diff_eRm.T1 = T1_eRm - T1_Input,\n    diff_eRm.T2 = T2_eRm - T2_Input,\n    diff_eRm.T3 = T3_eRm - T3_Input,\n    diff_eRm.T4 = T4_eRm - T4_Input,\n    diff_TAM.T1 = T1_TAM - T1_Input,\n    diff_TAM.T2 = T2_TAM - T2_Input,\n    diff_TAM.T3 = T3_TAM - T3_Input,\n    diff_TAM.T4 = T4_TAM - T4_Input,\n    diff_mirt.T1 = T1_mirt - T1_Input,\n    diff_mirt.T2 = T2_mirt - T2_Input,\n    diff_mirt.T3 = T3_mirt - T3_Input,\n    diff_mirt.T4 = T4_mirt - T4_Input,\n    diff_PAIR.T1 = T1_PAIR - T1_Input,\n    diff_PAIR.T2 = T2_PAIR - T2_Input,\n    diff_PAIR.T3 = T3_PAIR - T3_Input,\n    diff_PAIR.T4 = T4_PAIR - T4_Input\n  ) %&gt;%\n  ungroup() %&gt;%\n  pivot_longer(cols = starts_with(\"diff\"),\n               names_to = c(\"Estimator\",\"Threshold\"),\n               names_sep = \"\\\\.\",\n               values_to = \"diff\") %&gt;%\n  mutate(Package = gsub(\"diff_\",\"\",Estimator)) %&gt;%\n  mutate(Threshold = car::recode(Threshold,\"'T1'='Threshold 1';'T2'='Threshold 2';'T3'='Threshold 3';'T4'='Threshold 4';\")) %&gt;%\n  ggplot(aes(x = diff, y = Package, slab_fill = after_stat(level))) +\n  stat_dotsinterval(quantiles = 250, point_interval = \"median_qi\",\n                    layout = \"weave\", slab_color = NA, .width = c(.66,.95)) +\n  labs(caption = \"Point interval: median_qi (.66 and .95). Based on 250 simulated datasets with 9 items and 720 respondents each.\",\n       x = \"Bias (logit scale)\",\n       y = \"Package\",\n       title = \"Distribution of item threshold estimation bias\",\n       subtitle = \"Rasch Partial Credit Model\") +\n  scale_color_manual(guide = \"none\", values = scales::brewer_pal()(3)[-1], aesthetics = \"slab_fill\") +\n  facet_wrap(~Threshold, nrow = 1) +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  theme_minimal()"
  },
  {
    "objectID": "est_comp.html#smaller-sample",
    "href": "est_comp.html#smaller-sample",
    "title": "Comparing Rasch packages/estimators",
    "section": "\n5 Smaller sample",
    "text": "5 Smaller sample\nSince the pairwise method has been claimed to be good with small samples, at least compared to MML (Finch and French 2019). Notably, the paper mentions using the ltm package for MML estimation (which is referred to as “standard MLE” in the paper), for PCM estimation, but PCM is not available in ltm.\nI was interested to have a quick look at this. We’ll use the same 250 datasets again, but randomly select 108 respondents (3 per threshold estimated) from each dataset.\n\nCoderegisterDoParallel(cores = 8)\niterations = 250\nsamplesize = 108 # n = 3 per threshold (instead of 20/threshold)\n\nsim_results_4t2 &lt;- list()\n\nsim_results_4t2 &lt;- foreach(i = 1:iterations) %dopar% {\n\n  input_params &lt;- sim_data_4t[[i]]$input_params\n  testData &lt;- sim_data_4t[[i]]$data[sample(1:720, samplesize), ]\n\n  # check mean/centrality (item parameters should have been centered before data generation)\n  input_params_correction &lt;- mean(input_params)\n\n  # eRm\n  erm_out &lt;- PCM(testData)\n  erm_params &lt;- thresholds(erm_out)[[3]][[1]][,-1] %&gt;%\n    as.data.frame() %&gt;%\n    set_names(c(\"T1\",\"T2\",\"T3\",\"T4\")) %&gt;%\n    as.matrix()\n\n  erm_params_c &lt;- erm_params - mean(erm_params) + input_params_correction\n\n  # TAM\n  tam_out &lt;- tam(as.matrix(testData), irtmodel = \"PCM\", verbose = FALSE)\n\n  tam_params &lt;- tam_out$item_irt %&gt;%\n    as.data.frame() %&gt;%\n    select(starts_with(\"tau\")) %&gt;%\n    set_names(c(\"T1\",\"T2\",\"T3\",\"T4\")) %&gt;%\n    as.matrix()\n\n  tam_params_c &lt;- tam_params - mean(tam_params) + input_params_correction\n\n  # mirt\n  mirt_out &lt;- mirt(data = testData, model = 1, itemtype = \"Rasch\", verbose = FALSE)\n  mirt_params &lt;- coef(mirt_out, simplify = TRUE, IRTpars = TRUE)$items %&gt;%\n    as.data.frame() %&gt;%\n    select(!a) %&gt;%\n    set_names(c(\"T1\",\"T2\",\"T3\",\"T4\")) %&gt;%\n    as.matrix()\n  mirt_params_c &lt;- mirt_params - mean(mirt_params) + input_params_correction\n\n  # PAIR\n  pair_out &lt;- pair(testData, m = 5)\n  pair_params &lt;- deltapar(pair_out) %&gt;%\n    as.data.frame()\n\n  pair_params &lt;- pair_params[,-1] %&gt;%\n    set_names(c(\"T1\",\"T2\",\"T3\",\"T4\")) %&gt;%\n    as.matrix()\n\n  pair_params_c &lt;- pair_params - mean(pair_params) + input_params_correction\n\n  # combine item parameters and calculate lowest to highest threshold distances\n  input_params %&gt;%\n    as.data.frame() %&gt;%\n    rename(T1 = V1,\n           T2 = V2,\n           T3 = V3,\n           T4 = V4) %&gt;%\n    add_column(Item = c(1:9),\n               Type = \"Input\") %&gt;%\n    bind_rows(\n      erm_params_c %&gt;%\n        as.data.frame() %&gt;%\n        add_column(Item = c(1:9),\n                   Type = \"eRm\")\n    ) %&gt;%\n    bind_rows(\n      tam_params_c %&gt;%\n        as.data.frame() %&gt;%\n        add_column(Item = c(1:9),\n                   Type = \"TAM\")\n    ) %&gt;%\n    bind_rows(\n      mirt_params_c %&gt;%\n        as.data.frame() %&gt;%\n        add_column(Item = c(1:9),\n                   Type = \"mirt\")\n    ) %&gt;%\n    bind_rows(\n      pair_params_c %&gt;%\n        as.data.frame() %&gt;%\n        add_column(Item = c(1:9),\n                   Type = \"PAIR\")\n    ) %&gt;%\n    remove_rownames()\n}\n\n\n\n5.1 Results\n\nCode# collect item threshold parameters to a single dataframe\nresults_params_4t2 &lt;- map_df(1:iterations, ~ sim_results_4t2[[.x]] %&gt;%\n                               mutate(iteration = .x))\n\n\n\n5.1.1 Summary table MAE\n\nCode# calculate absolute differences between input and estimated item thresholds per estimator, average by item\nresults_params_diff_4t2 &lt;- results_params_4t2 %&gt;%\n  pivot_wider(\n    values_from = c(\"T1\", \"T2\", \"T3\", \"T4\"),\n    names_from = \"Type\",\n    id_cols = c(\"iteration\", \"Item\")\n  ) %&gt;%\n  group_by(iteration, Item) %&gt;%\n  summarise(\n    diff_eRm = sum(abs(T1_Input - T1_eRm) + abs(T2_Input - T2_eRm) + abs(T3_Input - T3_eRm) + abs(T4_Input - T4_eRm))/4,\n    diff_TAM = sum(abs(T1_Input - T1_TAM) + abs(T2_Input - T2_TAM) + abs(T3_Input - T3_TAM) + abs(T4_Input - T4_TAM))/4,\n    diff_mirt = sum(abs(T1_Input - T1_mirt) + abs(T2_Input - T2_mirt) + abs(T3_Input - T3_mirt) + abs(T4_Input - T4_mirt))/4,\n    diff_PAIR = sum(abs(T1_Input - T1_PAIR) + abs(T2_Input - T2_PAIR) + abs(T3_Input - T3_PAIR) + abs(T4_Input - T4_PAIR))/4\n  ) %&gt;%\n  ungroup() %&gt;%\n  pivot_longer(\n    cols = c(diff_eRm, diff_TAM,diff_mirt,diff_PAIR),\n    names_to = c(NA, \"Estimator\"),\n    names_sep = \"_\",\n    values_to = \"diff\"\n  )\n\n# produce table with summary stats per estimator/package\nresults_params_diff_4t2 %&gt;%\n  group_by(Estimator) %&gt;%\n  summarise(\n    Median = median(diff, na.rm = TRUE),\n    MAD = mad(diff, na.rm = TRUE),\n    IQR = IQR(diff, na.rm = TRUE),\n    Mean = mean(diff, na.rm = TRUE),\n    SD = sd(diff, na.rm = TRUE),\n  ) %&gt;%\n  mutate(across(where(is.numeric), ~ round(.x,3))) %&gt;%\n  rename(Package = Estimator) %&gt;%\n  arrange(Median) %&gt;%\n  tt()\n\n \n\n  \n    \n\ntinytable_eat8y8n90g0mp1tyxubx\n\n\n      \n\nPackage\n                Median\n                MAD\n                IQR\n                Mean\n                SD\n              \n\n\neRm \n                  0.273\n                  0.121\n                  0.167\n                  0.293\n                  0.127\n                \n\nmirt\n                  0.273\n                  0.121\n                  0.166\n                  0.292\n                  0.126\n                \n\nTAM \n                  0.283\n                  0.122\n                  0.168\n                  0.301\n                  0.131\n                \n\nPAIR\n                  0.297\n                  0.130\n                  0.182\n                  0.326\n                  0.184\n                \n\n\n\n\n    \n\n\n\n5.1.2 Summary table RMSE\n\nCode# RMSE\nresults_params_4t2 %&gt;%\n  pivot_wider(\n    values_from = c(\"T1\", \"T2\", \"T3\", \"T4\"),\n    names_from = \"Type\",\n    id_cols = c(\"iteration\", \"Item\")\n  ) %&gt;%\n  group_by(iteration, Item) %&gt;% # sqrt(mean((data$actual - data$predicted)^2))\n  summarise(\n    rmse_eRm = sqrt(mean(((T1_Input - T1_eRm)^2) + ((T2_Input - T2_eRm)^2) + ((T3_Input - T3_eRm)^2) + ((T4_Input - T4_eRm))^2)),\n        rmse_TAM = sqrt(mean(((T1_Input - T1_TAM)^2) + ((T2_Input - T2_TAM)^2) + ((T3_Input - T3_TAM)^2) + ((T4_Input - T4_TAM))^2)),\n        rmse_mirt = sqrt(mean(((T1_Input - T1_mirt)^2) + ((T2_Input - T2_mirt)^2) + ((T3_Input - T3_mirt)^2) + ((T4_Input - T4_mirt))^2)),\n        rmse_PAIR = sqrt(mean(((T1_Input - T1_PAIR)^2) + ((T2_Input - T2_PAIR)^2) + ((T3_Input - T3_PAIR)^2) + ((T4_Input - T4_PAIR))^2))\n  ) %&gt;%\n  ungroup() %&gt;%\n  pivot_longer(\n    cols = c(rmse_eRm, rmse_TAM,rmse_mirt,rmse_PAIR),\n    names_to = c(NA, \"Estimator\"),\n    names_sep = \"_\",\n    values_to = \"rmse\"\n  ) %&gt;% \n  group_by(Estimator) %&gt;%\n  summarise(\n    Median = median(rmse, na.rm = T),\n    MAD = mad(rmse, na.rm = T),\n    IQR = IQR(rmse, na.rm = T),\n    Mean = mean(rmse, na.rm = T),\n    SD = sd(rmse, na.rm = T)\n  ) %&gt;%\n  mutate(across(where(is.numeric), ~ round(.x,3))) %&gt;%\n  rename(Package = Estimator) %&gt;%\n  arrange(Median) %&gt;% \n  tt()\n\n \n\n  \n    \n\ntinytable_1005n7a3vvcypthp701e\n\n\n      \n\nPackage\n                Median\n                MAD\n                IQR\n                Mean\n                SD\n              \n\n\nmirt\n                  0.657\n                  0.287\n                  0.394\n                  0.704\n                  0.319\n                \n\neRm \n                  0.658\n                  0.289\n                  0.400\n                  0.708\n                  0.321\n                \n\nTAM \n                  0.668\n                  0.283\n                  0.380\n                  0.709\n                  0.296\n                \n\nPAIR\n                  0.700\n                  0.302\n                  0.419\n                  0.768\n                  0.418\n                \n\n\n\n\n    \n\n\n\n5.1.3 Thresholds summary MAE\n\nCode# table summarizing all thresholds and estimators\nresults_params_4t2 %&gt;%\n  pivot_wider(values_from = c(\"T1\", \"T2\", \"T3\", \"T4\"),\n              names_from = \"Type\",\n              id_cols = c(\"iteration\",\"Item\")\n  ) %&gt;%\n  group_by(iteration,Item) %&gt;%\n  summarise(\n    diff_eRm.T1 = abs(T1_eRm - T1_Input),\n    diff_eRm.T2 = abs(T2_eRm - T2_Input),\n    diff_eRm.T3 = abs(T3_eRm - T3_Input),\n    diff_eRm.T4 = abs(T4_eRm - T4_Input),\n    diff_TAM.T1 = abs(T1_TAM - T1_Input),\n    diff_TAM.T2 = abs(T2_TAM - T2_Input),\n    diff_TAM.T3 = abs(T3_TAM - T3_Input),\n    diff_TAM.T4 = abs(T4_TAM - T4_Input),\n    diff_mirt.T1 = abs(T1_mirt - T1_Input),\n    diff_mirt.T2 = abs(T2_mirt - T2_Input),\n    diff_mirt.T3 = abs(T3_mirt - T3_Input),\n    diff_mirt.T4 = abs(T4_mirt - T4_Input),\n    diff_PAIR.T1 = abs(T1_PAIR - T1_Input),\n    diff_PAIR.T2 = abs(T2_PAIR - T2_Input),\n    diff_PAIR.T3 = abs(T3_PAIR - T3_Input),\n    diff_PAIR.T4 = abs(T4_PAIR - T4_Input)\n  ) %&gt;%\n  ungroup() %&gt;%\n  pivot_longer(cols = starts_with(\"diff\"),\n               names_to = c(\"Estimator\",\"Threshold\"),\n               names_sep = \"\\\\.\",\n               values_to = \"diff\") %&gt;%\n  mutate(Package = gsub(\"diff_\",\"\",Estimator)) %&gt;%\n  group_by(Package, Threshold) %&gt;%\n  summarise(\n    Median = median(diff, na.rm = TRUE),\n    MAD = mad(diff, na.rm = TRUE),\n    IQR = IQR(diff, na.rm = TRUE),\n    Mean = mean(diff, na.rm = TRUE),\n    SD = sd(diff, na.rm = TRUE)\n  ) %&gt;%\n  mutate(across(where(is.numeric), ~ round(.x,3))) %&gt;%\n  arrange(Threshold,Median) %&gt;%\n  tt() %&gt;% \n  style_tt(i = c(1, 5, 9, 13), j = 2, rowspan = 4, alignv = \"t\")\n\n \n\n  \n    \n\ntinytable_777lxuxj5dm3imapdb4u\n\n\n      \n\nPackage\n                Threshold\n                Median\n                MAD\n                IQR\n                Mean\n                SD\n              \n\n\nTAM \n                  T1\n                  0.277\n                  0.240\n                  0.332\n                  0.330\n                  0.259\n                \n\nPAIR\n                  T1\n                  0.286\n                  0.252\n                  0.353\n                  0.357\n                  0.308\n                \n\neRm \n                  T1\n                  0.290\n                  0.258\n                  0.374\n                  0.360\n                  0.303\n                \n\nmirt\n                  T1\n                  0.292\n                  0.261\n                  0.367\n                  0.358\n                  0.299\n                \n\nmirt\n                  T2\n                  0.184\n                  0.162\n                  0.233\n                  0.223\n                  0.177\n                \n\neRm \n                  T2\n                  0.187\n                  0.166\n                  0.231\n                  0.224\n                  0.178\n                \n\nTAM \n                  T2\n                  0.226\n                  0.206\n                  0.290\n                  0.270\n                  0.209\n                \n\nPAIR\n                  T2\n                  0.247\n                  0.214\n                  0.296\n                  0.289\n                  0.229\n                \n\nmirt\n                  T3\n                  0.194\n                  0.171\n                  0.241\n                  0.232\n                  0.179\n                \n\neRm \n                  T3\n                  0.196\n                  0.170\n                  0.245\n                  0.234\n                  0.180\n                \n\nTAM \n                  T3\n                  0.236\n                  0.207\n                  0.290\n                  0.278\n                  0.211\n                \n\nPAIR\n                  T3\n                  0.252\n                  0.220\n                  0.302\n                  0.296\n                  0.239\n                \n\nTAM \n                  T4\n                  0.258\n                  0.234\n                  0.335\n                  0.325\n                  0.264\n                \n\neRm \n                  T4\n                  0.281\n                  0.251\n                  0.349\n                  0.353\n                  0.299\n                \n\nmirt\n                  T4\n                  0.284\n                  0.250\n                  0.352\n                  0.353\n                  0.297\n                \n\nPAIR\n                  T4\n                  0.290\n                  0.262\n                  0.368\n                  0.363\n                  0.360\n                \n\n\n\n\n    \n\n\n\n5.1.4 Figure\n\nCoderesults_params_4t2 %&gt;%\n  pivot_wider(values_from = c(\"T1\", \"T2\", \"T3\", \"T4\"),\n              names_from = \"Type\",\n              id_cols = c(\"iteration\",\"Item\")\n  ) %&gt;%\n  group_by(iteration,Item) %&gt;%\n  summarise(\n    diff_eRm.T1 = T1_eRm - T1_Input,\n    diff_eRm.T2 = T2_eRm - T2_Input,\n    diff_eRm.T3 = T3_eRm - T3_Input,\n    diff_eRm.T4 = T4_eRm - T4_Input,\n    diff_TAM.T1 = T1_TAM - T1_Input,\n    diff_TAM.T2 = T2_TAM - T2_Input,\n    diff_TAM.T3 = T3_TAM - T3_Input,\n    diff_TAM.T4 = T4_TAM - T4_Input,\n    diff_mirt.T1 = T1_mirt - T1_Input,\n    diff_mirt.T2 = T2_mirt - T2_Input,\n    diff_mirt.T3 = T3_mirt - T3_Input,\n    diff_mirt.T4 = T4_mirt - T4_Input,\n    diff_PAIR.T1 = T1_PAIR - T1_Input,\n    diff_PAIR.T2 = T2_PAIR - T2_Input,\n    diff_PAIR.T3 = T3_PAIR - T3_Input,\n    diff_PAIR.T4 = T4_PAIR - T4_Input\n  ) %&gt;%\n  ungroup() %&gt;%\n  pivot_longer(cols = starts_with(\"diff\"),\n               names_to = c(\"Estimator\",\"Threshold\"),\n               names_sep = \"\\\\.\",\n               values_to = \"diff\") %&gt;%\n  mutate(Package = gsub(\"diff_\",\"\",Estimator)) %&gt;%\n  mutate(Threshold = car::recode(Threshold,\"'T1'='Threshold 1';'T2'='Threshold 2';'T3'='Threshold 3';'T4'='Threshold 4';\")) %&gt;%\n  ggplot(aes(x = diff, y = Package, slab_fill = after_stat(level))) +\n  stat_dotsinterval(quantiles = 250, point_interval = \"median_qi\",\n                    layout = \"weave\", slab_color = NA, .width = c(.66,.95)) +\n  labs(caption = str_wrap(\"Point interval: median_qi (.66 and .95). Based on 250 simulated datasets with 9 items and 108 respondents each.\"),\n       x = \"Bias (logit scale)\",\n       y = \"Package\",\n       title = \"Distribution of item threshold estimation bias\",\n       subtitle = \"Rasch Partial Credit Model\") +\n  scale_color_manual(guide = \"none\", values = scales::brewer_pal()(3)[-1], aesthetics = \"slab_fill\") +\n  facet_wrap(~Threshold, nrow = 1) +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  theme_minimal()"
  },
  {
    "objectID": "est_comp.html#references",
    "href": "est_comp.html#references",
    "title": "Comparing Rasch packages/estimators",
    "section": "\n6 References",
    "text": "6 References"
  },
  {
    "objectID": "est_comp.html#even-smaller-sample",
    "href": "est_comp.html#even-smaller-sample",
    "title": "Comparing Rasch packages/estimators",
    "section": "\n6 Even smaller sample",
    "text": "6 Even smaller sample\nn = 54, 2 per threshold estimated.\n\nCoderegisterDoParallel(cores = 8)\niterations = 250\nsamplesize = 54 # n = 2 per threshold (instead of 20/threshold)\n\nsim_results_4t3 &lt;- list()\n\nsim_results_4t3 &lt;- foreach(i = 1:iterations) %dopar% {\n\n  input_params &lt;- sim_data_4t[[i]]$input_params\n  testData &lt;- sim_data_4t[[i]]$data[sample(1:720, samplesize), ]\n\n  # check mean/centrality (item parameters should have been centered before data generation)\n  input_params_correction &lt;- mean(input_params)\n\n  # eRm\n  erm_out &lt;- PCM(testData)\n  erm_params &lt;- thresholds(erm_out)[[3]][[1]][,-1] %&gt;%\n    as.data.frame() %&gt;%\n    set_names(c(\"T1\",\"T2\",\"T3\",\"T4\")) %&gt;%\n    as.matrix()\n\n  erm_params_c &lt;- erm_params - mean(erm_params) + input_params_correction\n\n  # TAM\n  tam_out &lt;- tam(as.matrix(testData), irtmodel = \"PCM\", verbose = FALSE)\n\n  tam_params &lt;- tam_out$item_irt %&gt;%\n    as.data.frame() %&gt;%\n    select(starts_with(\"tau\")) %&gt;%\n    set_names(c(\"T1\",\"T2\",\"T3\",\"T4\")) %&gt;%\n    as.matrix()\n\n  tam_params_c &lt;- tam_params - mean(tam_params) + input_params_correction\n\n  # mirt\n  mirt_out &lt;- mirt(data = testData, model = 1, itemtype = \"Rasch\", verbose = FALSE)\n  mirt_params &lt;- coef(mirt_out, simplify = TRUE, IRTpars = TRUE)$items %&gt;%\n    as.data.frame() %&gt;%\n    select(!a) %&gt;%\n    set_names(c(\"T1\",\"T2\",\"T3\",\"T4\")) %&gt;%\n    as.matrix()\n  mirt_params_c &lt;- mirt_params - mean(mirt_params) + input_params_correction\n\n  # PAIR\n  pair_out &lt;- pair(testData, m = 5)\n  pair_params &lt;- deltapar(pair_out) %&gt;%\n    as.data.frame()\n\n  pair_params &lt;- pair_params[,-1] %&gt;%\n    set_names(c(\"T1\",\"T2\",\"T3\",\"T4\")) %&gt;%\n    as.matrix()\n\n  pair_params_c &lt;- pair_params - mean(pair_params) + input_params_correction\n\n  # combine item parameters and calculate lowest to highest threshold distances\n  input_params %&gt;%\n    as.data.frame() %&gt;%\n    rename(T1 = V1,\n           T2 = V2,\n           T3 = V3,\n           T4 = V4) %&gt;%\n    add_column(Item = c(1:9),\n               Type = \"Input\") %&gt;%\n    bind_rows(\n      erm_params_c %&gt;%\n        as.data.frame() %&gt;%\n        add_column(Item = c(1:9),\n                   Type = \"eRm\")\n    ) %&gt;%\n    bind_rows(\n      tam_params_c %&gt;%\n        as.data.frame() %&gt;%\n        add_column(Item = c(1:9),\n                   Type = \"TAM\")\n    ) %&gt;%\n    bind_rows(\n      mirt_params_c %&gt;%\n        as.data.frame() %&gt;%\n        add_column(Item = c(1:9),\n                   Type = \"mirt\")\n    ) %&gt;%\n    bind_rows(\n      pair_params_c %&gt;%\n        as.data.frame() %&gt;%\n        add_column(Item = c(1:9),\n                   Type = \"PAIR\")\n    ) %&gt;%\n    remove_rownames()\n}\n\n\n\n6.1 Results\n\nCode# collect item threshold parameters to a single dataframe\nresults_params_4t3 &lt;- map_df(1:iterations, ~ sim_results_4t3[[.x]] %&gt;%\n                               mutate(iteration = .x))\n\n\n\n6.1.1 Summary table MAE\n\nCode# calculate absolute differences between input and estimated item thresholds per estimator, average by item\nresults_params_diff_4t3 &lt;- results_params_4t3 %&gt;%\n  pivot_wider(\n    values_from = c(\"T1\", \"T2\", \"T3\", \"T4\"),\n    names_from = \"Type\",\n    id_cols = c(\"iteration\", \"Item\")\n  ) %&gt;%\n  group_by(iteration, Item) %&gt;%\n  summarise(\n    diff_eRm = sum(abs(T1_Input - T1_eRm) + abs(T2_Input - T2_eRm) + abs(T3_Input - T3_eRm) + abs(T4_Input - T4_eRm))/4,\n    diff_TAM = sum(abs(T1_Input - T1_TAM) + abs(T2_Input - T2_TAM) + abs(T3_Input - T3_TAM) + abs(T4_Input - T4_TAM))/4,\n    diff_mirt = sum(abs(T1_Input - T1_mirt) + abs(T2_Input - T2_mirt) + abs(T3_Input - T3_mirt) + abs(T4_Input - T4_mirt))/4,\n    diff_PAIR = sum(abs(T1_Input - T1_PAIR) + abs(T2_Input - T2_PAIR) + abs(T3_Input - T3_PAIR) + abs(T4_Input - T4_PAIR))/4\n  ) %&gt;%\n  ungroup() %&gt;%\n  pivot_longer(\n    cols = c(diff_eRm, diff_TAM,diff_mirt,diff_PAIR),\n    names_to = c(NA, \"Estimator\"),\n    names_sep = \"_\",\n    values_to = \"diff\"\n  )\n\n# produce table with summary stats per estimator/package\nresults_params_diff_4t3 %&gt;%\n  group_by(Estimator) %&gt;%\n  summarise(\n    Median = median(diff, na.rm = TRUE),\n    MAD = mad(diff, na.rm = TRUE),\n    IQR = IQR(diff, na.rm = TRUE),\n    Mean = mean(diff, na.rm = TRUE),\n    SD = sd(diff, na.rm = TRUE),\n  ) %&gt;%\n  mutate(across(where(is.numeric), ~ round(.x,3))) %&gt;%\n  rename(Package = Estimator) %&gt;%\n  arrange(Median) %&gt;%\n  tt()\n\n \n\n  \n    \n\ntinytable_0avvuv15de1s8xf3hktk\n\n\n      \n\nPackage\n                Median\n                MAD\n                IQR\n                Mean\n                SD\n              \n\n\nTAM \n                  0.384\n                  0.167\n                  0.237\n                  0.575\n                  1.471\n                \n\nmirt\n                  0.390\n                  0.170\n                  0.233\n                  0.410\n                  0.177\n                \n\neRm \n                  0.392\n                  0.177\n                  0.237\n                  0.413\n                  0.180\n                \n\nPAIR\n                  0.422\n                  0.207\n                  0.293\n                  0.535\n                  0.470\n                \n\n\n\n\n    \n\n\n\n6.1.2 Summary table RMSE\n\nCode# RMSE\nresults_params_4t3 %&gt;%\n  pivot_wider(\n    values_from = c(\"T1\", \"T2\", \"T3\", \"T4\"),\n    names_from = \"Type\",\n    id_cols = c(\"iteration\", \"Item\")\n  ) %&gt;%\n  group_by(iteration, Item) %&gt;% # sqrt(mean((data$actual - data$predicted)^2))\n  summarise(\n    rmse_eRm = sqrt(mean(((T1_Input - T1_eRm)^2) + ((T2_Input - T2_eRm)^2) + ((T3_Input - T3_eRm)^2) + ((T4_Input - T4_eRm))^2)),\n        rmse_TAM = sqrt(mean(((T1_Input - T1_TAM)^2) + ((T2_Input - T2_TAM)^2) + ((T3_Input - T3_TAM)^2) + ((T4_Input - T4_TAM))^2)),\n        rmse_mirt = sqrt(mean(((T1_Input - T1_mirt)^2) + ((T2_Input - T2_mirt)^2) + ((T3_Input - T3_mirt)^2) + ((T4_Input - T4_mirt))^2)),\n        rmse_PAIR = sqrt(mean(((T1_Input - T1_PAIR)^2) + ((T2_Input - T2_PAIR)^2) + ((T3_Input - T3_PAIR)^2) + ((T4_Input - T4_PAIR))^2))\n  ) %&gt;%\n  ungroup() %&gt;%\n  pivot_longer(\n    cols = c(rmse_eRm, rmse_TAM,rmse_mirt,rmse_PAIR),\n    names_to = c(NA, \"Estimator\"),\n    names_sep = \"_\",\n    values_to = \"rmse\"\n  ) %&gt;% \n  group_by(Estimator) %&gt;%\n  summarise(\n    Median = median(rmse, na.rm = T),\n    MAD = mad(rmse, na.rm = T),\n    IQR = IQR(rmse, na.rm = T),\n    Mean = mean(rmse, na.rm = T),\n    SD = sd(rmse, na.rm = T)\n  ) %&gt;%\n  mutate(across(where(is.numeric), ~ round(.x,3))) %&gt;%\n  rename(Package = Estimator) %&gt;%\n  arrange(Median) %&gt;% \n  tt()\n\n \n\n  \n    \n\ntinytable_zmjrgt9crv6rrmgkpnid\n\n\n      \n\nPackage\n                Median\n                MAD\n                IQR\n                Mean\n                SD\n              \n\n\nTAM \n                  0.902\n                  0.370\n                  0.507\n                  1.342\n                  3.381\n                \n\nmirt\n                  0.925\n                  0.400\n                  0.543\n                  0.987\n                  0.430\n                \n\neRm \n                  0.937\n                  0.405\n                  0.550\n                  0.994\n                  0.439\n                \n\nPAIR\n                  1.009\n                  0.468\n                  0.655\n                  1.250\n                  1.078\n                \n\n\n\n\n    \n\n\n\n6.1.3 Thresholds summary MAE\n\nCode# table summarizing all thresholds and estimators\nresults_params_4t3 %&gt;%\n  pivot_wider(values_from = c(\"T1\", \"T2\", \"T3\", \"T4\"),\n              names_from = \"Type\",\n              id_cols = c(\"iteration\",\"Item\")\n  ) %&gt;%\n  group_by(iteration,Item) %&gt;%\n  summarise(\n    diff_eRm.T1 = abs(T1_eRm - T1_Input),\n    diff_eRm.T2 = abs(T2_eRm - T2_Input),\n    diff_eRm.T3 = abs(T3_eRm - T3_Input),\n    diff_eRm.T4 = abs(T4_eRm - T4_Input),\n    diff_TAM.T1 = abs(T1_TAM - T1_Input),\n    diff_TAM.T2 = abs(T2_TAM - T2_Input),\n    diff_TAM.T3 = abs(T3_TAM - T3_Input),\n    diff_TAM.T4 = abs(T4_TAM - T4_Input),\n    diff_mirt.T1 = abs(T1_mirt - T1_Input),\n    diff_mirt.T2 = abs(T2_mirt - T2_Input),\n    diff_mirt.T3 = abs(T3_mirt - T3_Input),\n    diff_mirt.T4 = abs(T4_mirt - T4_Input),\n    diff_PAIR.T1 = abs(T1_PAIR - T1_Input),\n    diff_PAIR.T2 = abs(T2_PAIR - T2_Input),\n    diff_PAIR.T3 = abs(T3_PAIR - T3_Input),\n    diff_PAIR.T4 = abs(T4_PAIR - T4_Input)\n  ) %&gt;%\n  ungroup() %&gt;%\n  pivot_longer(cols = starts_with(\"diff\"),\n               names_to = c(\"Estimator\",\"Threshold\"),\n               names_sep = \"\\\\.\",\n               values_to = \"diff\") %&gt;%\n  mutate(Package = gsub(\"diff_\",\"\",Estimator)) %&gt;%\n  group_by(Package, Threshold) %&gt;%\n  summarise(\n    Median = median(diff, na.rm = TRUE),\n    MAD = mad(diff, na.rm = TRUE),\n    IQR = IQR(diff, na.rm = TRUE),\n    Mean = mean(diff, na.rm = TRUE),\n    SD = sd(diff, na.rm = TRUE)\n  ) %&gt;%\n  mutate(across(where(is.numeric), ~ round(.x,3))) %&gt;%\n  arrange(Threshold,Median) %&gt;%\n  tt() %&gt;% \n  style_tt(i = c(1, 5, 9, 13), j = 2, rowspan = 4, alignv = \"t\")\n\n \n\n  \n    \n\ntinytable_4111b9318frvetbjqouw\n\n\n      \n\nPackage\n                Threshold\n                Median\n                MAD\n                IQR\n                Mean\n                SD\n              \n\n\nTAM \n                  T1\n                  0.386\n                  0.343\n                  0.486\n                  0.794\n                  2.957\n                \n\nmirt\n                  T1\n                  0.407\n                  0.366\n                  0.512\n                  0.508\n                  0.417\n                \n\neRm \n                  T1\n                  0.412\n                  0.368\n                  0.524\n                  0.514\n                  0.425\n                \n\nPAIR\n                  T1\n                  0.433\n                  0.399\n                  0.575\n                  0.619\n                  0.749\n                \n\nmirt\n                  T2\n                  0.272\n                  0.239\n                  0.332\n                  0.319\n                  0.249\n                \n\neRm \n                  T2\n                  0.274\n                  0.246\n                  0.339\n                  0.322\n                  0.251\n                \n\nTAM \n                  T2\n                  0.312\n                  0.279\n                  0.398\n                  0.479\n                  1.013\n                \n\nPAIR\n                  T2\n                  0.353\n                  0.315\n                  0.448\n                  0.451\n                  0.404\n                \n\nmirt\n                  T3\n                  0.266\n                  0.237\n                  0.336\n                  0.320\n                  0.249\n                \n\neRm \n                  T3\n                  0.270\n                  0.235\n                  0.329\n                  0.322\n                  0.250\n                \n\nTAM \n                  T3\n                  0.302\n                  0.271\n                  0.394\n                  0.473\n                  1.011\n                \n\nPAIR\n                  T3\n                  0.342\n                  0.309\n                  0.431\n                  0.446\n                  0.409\n                \n\nTAM \n                  T4\n                  0.367\n                  0.339\n                  0.474\n                  0.555\n                  1.025\n                \n\neRm \n                  T4\n                  0.412\n                  0.361\n                  0.503\n                  0.496\n                  0.396\n                \n\nmirt\n                  T4\n                  0.416\n                  0.367\n                  0.507\n                  0.494\n                  0.392\n                \n\nPAIR\n                  T4\n                  0.425\n                  0.403\n                  0.590\n                  0.626\n                  0.809\n                \n\n\n\n\n    \n\n\n\n6.1.4 Figure\n\nCoderesults_params_4t3 %&gt;%\n  pivot_wider(values_from = c(\"T1\", \"T2\", \"T3\", \"T4\"),\n              names_from = \"Type\",\n              id_cols = c(\"iteration\",\"Item\")\n  ) %&gt;%\n  group_by(iteration,Item) %&gt;%\n  summarise(\n    diff_eRm.T1 = T1_eRm - T1_Input,\n    diff_eRm.T2 = T2_eRm - T2_Input,\n    diff_eRm.T3 = T3_eRm - T3_Input,\n    diff_eRm.T4 = T4_eRm - T4_Input,\n    diff_TAM.T1 = T1_TAM - T1_Input,\n    diff_TAM.T2 = T2_TAM - T2_Input,\n    diff_TAM.T3 = T3_TAM - T3_Input,\n    diff_TAM.T4 = T4_TAM - T4_Input,\n    diff_mirt.T1 = T1_mirt - T1_Input,\n    diff_mirt.T2 = T2_mirt - T2_Input,\n    diff_mirt.T3 = T3_mirt - T3_Input,\n    diff_mirt.T4 = T4_mirt - T4_Input,\n    diff_PAIR.T1 = T1_PAIR - T1_Input,\n    diff_PAIR.T2 = T2_PAIR - T2_Input,\n    diff_PAIR.T3 = T3_PAIR - T3_Input,\n    diff_PAIR.T4 = T4_PAIR - T4_Input\n  ) %&gt;%\n  ungroup() %&gt;%\n  pivot_longer(cols = starts_with(\"diff\"),\n               names_to = c(\"Estimator\",\"Threshold\"),\n               names_sep = \"\\\\.\",\n               values_to = \"diff\") %&gt;%\n  mutate(Package = gsub(\"diff_\",\"\",Estimator)) %&gt;%\n  mutate(Threshold = car::recode(Threshold,\"'T1'='Threshold 1';'T2'='Threshold 2';'T3'='Threshold 3';'T4'='Threshold 4';\")) %&gt;%\n  ggplot(aes(x = diff, y = Package, slab_fill = after_stat(level))) +\n  stat_dotsinterval(quantiles = 250, point_interval = \"median_qi\",\n                    layout = \"weave\", slab_color = NA, .width = c(.66,.95)) +\n  labs(caption = str_wrap(\"Point interval: median_qi (.66 and .95). Based on 250 simulated datasets with 9 items and 54 respondents each. X-axis omits extreme values.\"),\n       x = \"Bias (logit scale)\",\n       y = \"Package\",\n       title = \"Distribution of item threshold estimation bias\",\n       subtitle = \"Rasch Partial Credit Model\") +\n  scale_color_manual(guide = \"none\", values = scales::brewer_pal()(3)[-1], aesthetics = \"slab_fill\") +\n  facet_wrap(~Threshold, nrow = 1) +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  theme_minimal() +\n  coord_cartesian(xlim = c(-2.5,2.5))\n\n\n\n\n\n\n\n\nCodesessionInfo()\n\nR version 4.4.1 (2024-06-14)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sonoma 14.6.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Stockholm\ntzcode source: internal\n\nattached base packages:\n[1] parallel  stats4    stats     graphics  grDevices utils     datasets \n[8] methods   base     \n\nother attached packages:\n [1] tinytable_0.3.0   doParallel_1.0.17 iterators_1.0.14  foreach_1.5.2    \n [5] ggdist_3.3.2      pairwise_0.6.1-0  mirt_1.42         lattice_0.22-6   \n [9] TAM_4.2-21        CDM_8.2-6         mvtnorm_1.2-5     janitor_2.2.0    \n[13] eRm_1.0-6         lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n[17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n[21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n\nloaded via a namespace (and not attached):\n [1] mnormt_2.1.1         pbapply_1.7-2        gridExtra_2.3       \n [4] permute_0.9-7        testthat_3.2.1.1     rlang_1.1.4         \n [7] magrittr_2.0.3       snakecase_0.11.1     compiler_4.4.1      \n[10] mgcv_1.9-1           vctrs_0.6.5          quadprog_1.5-8      \n[13] pkgconfig_2.0.3      fastmap_1.2.0        labeling_0.4.3      \n[16] utf8_1.2.4           rmarkdown_2.27       sessioninfo_1.2.2   \n[19] tzdb_0.4.0           xfun_0.46            jsonlite_1.8.8      \n[22] Deriv_4.1.3          psych_2.4.6.26       cluster_2.1.6       \n[25] R6_2.5.1             stringi_1.8.4        RColorBrewer_1.1-3  \n[28] parallelly_1.38.0    car_3.1-2            brio_1.1.5          \n[31] Rcpp_1.0.13          knitr_1.48           future.apply_1.11.2 \n[34] snow_0.4-4           audio_0.1-11         R.utils_2.12.3      \n[37] polycor_0.8-1        Matrix_1.7-0         splines_4.4.1       \n[40] timechange_0.3.0     tidyselect_1.2.1     rstudioapi_0.16.0   \n[43] abind_1.4-5          yaml_2.3.10          vegan_2.6-6.1       \n[46] codetools_0.2-20     dcurver_0.9.2        curl_5.2.1          \n[49] admisc_0.35          listenv_0.9.1        withr_3.0.1         \n[52] evaluate_0.24.0      future_1.34.0        pillar_1.9.0        \n[55] carData_3.0-5        distributional_0.4.0 generics_0.1.3      \n[58] hms_1.1.3            munsell_0.5.1        scales_1.3.0        \n[61] globals_0.16.3       glue_1.7.0           RPushbullet_0.3.4   \n[64] tools_4.4.1          beepr_2.0            SimDesign_2.17.1    \n[67] grid_4.4.1           colorspace_2.1-1     nlme_3.1-165        \n[70] cli_3.6.3            fansi_1.0.6          gtable_0.3.5        \n[73] R.methodsS3_1.8.2    digest_0.6.36        progressr_0.14.0    \n[76] GPArotation_2024.3-1 htmlwidgets_1.6.4    farver_2.1.2        \n[79] htmltools_0.5.8.1    R.oo_1.26.0          lifecycle_1.0.4     \n[82] MASS_7.3-61"
  }
]