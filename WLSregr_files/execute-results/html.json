{
  "hash": "07a9874f2983efe7586e8c8b64f209e4",
  "result": {
    "markdown": "---\ntitle: \"Using Rasch and WLS to account for measurement uncertainties in regression models\"\nauthor: \n  name: Magnus Johansson\n  affiliation: RISE Research Institutes of Sweden\n  affiliation-url: https://www.ri.se/en/what-we-do/projects/center-for-category-based-measurements\n  orcid: 0000-0003-1669-592X\ndate: last-modified\ncitation:\n  type: 'webpage'\ncsl: apa.csl\nexecute: \n  cache: false\n  warning: false\n  message: false\neditor: \n  markdown: \n    wrap: 72\neditor_options: \n  chunk_output_type: console\n---\n\n\n## Introduction\n\nThere are several reasons for putting this blog post together. The larger issue is to investigate ways to analyze relationships between measures that have varying levels of measurement uncertainty across their respective range or continuum. This is  relevant to any kind of latent variable measurement that uses multiple indicators/items/questions as a way to assess a latent variable. \n\nIn classical test theory (CTT; i.e. factor analysis) the assumption is generally that the measurement error is a single value, constant across the scale and across participants. Modern test theory (Rasch Measurement Theory (RMT) or Item Response Theory (IRT)) has tools to describe the varying uncertainties of the measure itself, and also allows for estimation of measurement uncertainty for each individual, based on the item properties.\n\nIn the \"business-as-usual\" approach, no matter which  types of measurement uncertainty are ignored. The simple case of have two variables and an ordinary least squares (OLS) linear regression model will take the input from each variable as a perfect measurement. Bayesians may have another take on this, and I will look into that at a later point, so for now this is relevant for frequentist statistics. \n\n\"Business-as-usual\" also makes use of ordinal sum scores disguised as interval scores. There is a seemingly wide-spread idea that estimated person interval scores is not significantly different from ordinal sum scores, and we'll look further into that as well by including ordinal sum scores.\n\nOne way to take measurement uncertainty into account in a linear regression model is to use Weighted Least Squares (WLS) instead of OLS. However, this approach only allows weights for one variable. The weights will be based on the measurement uncertainty for the interval scores.\n\nAdditionally, we will use Quantile Regression, with and without weights.\n\n## Data\n\nThe data used were collected for a project evaluating multiple work environment questionnaires. Two of the analyzed scales will be used in our example. More information is available at the GitHub [repository](https://github.com/pgmj/PreventOSA) and [website](https://pgmj.github.io/PreventOSA/).\n\nThe two questionnaires cover the domains of \"recovery\" and \"agency\", where the latter refers to workers' perceived control over their work situation. Our analyses will look at how \"agency\" affects \"recovery\". We will retain an interval scale score for the \"recovery\" scale throughout, while varying the \"agency\" between ordinal sum score, interval score, and interval score with weights.\n\nVariables will be named `SEM` for standard error of measurement, `Score` for interval scores, and `SumScore` for ordinal sum scores.\n\n::: {.callout-note}\nThis analysis is intended to be fully reproducible, which means some data wrangling is done initially. Please jump ahead to @sec-viz for data visualizations or @sec-lmm for the regression model output.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(RISEkbmRasch)\nlibrary(foreign)\nlibrary(readxl)\nlibrary(easystats)\nlibrary(lmtest)\nlibrary(quantreg)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n### some commands exist in multiple packages, here we define preferred ones that are frequently used\nselect <- dplyr::select\ncount <- dplyr::count\nrecode <- car::recode\nrename <- dplyr::rename\n\n# read full dataset, remove ppl w missing data\ndf <- read.spss(\"data/PreventOSAspss.sav\",\n                to.data.frame = TRUE) %>% \n  na.omit()\n# and item information\nitemlabels <- read_excel(\"data/PreventOSAitemlabels.xlsx\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# vector of items\nagencyItems <- itemlabels %>%\n  filter(Dimension == \"Möjlighet att påverka\") %>%\n  select(!Dimension)\n\n# data import, with recode of response categories to numerics\nagencyData <- df %>%\n  select(starts_with(\"q0007\")) %>%\n  mutate(across(everything(), ~ car::recode(.x, \"'Aldrig'=0;\n                                            'Sällan' =1;\n                                            'Ibland'=2;\n                                            'Ganska ofta'=3;\n                                            'Mycket ofta'=4;\n                                            'Alltid'=5\",\n    as.factor = FALSE\n  )))\nnames(agencyData) <- agencyItems$itemnr\n\n# adjustments based on psychometric analysis\nagencyData$mp4 <- NULL\nagencyData$mp1<-recode(agencyData$mp1,\"1=0;2=1;3=2;4=3;5=4\",as.factor=FALSE)\nagencyData$mp3<-recode(agencyData$mp3,\"1=0;2=1;3=2;4=3;5=4\",as.factor=FALSE)\nagencyData$mp2<-recode(agencyData$mp2,\"1=0;2=1;3=2;4=3;5=4\",as.factor=FALSE)\nagencyData$mp5<-recode(agencyData$mp5,\"2=1;3=2;4=3;5=4\",as.factor=FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# vector of items\nrecoveryItems <- itemlabels %>%\n  filter(Dimension == \"Återhämtning\") %>%\n  select(!Dimension)\n\n# data import, with recode of response categories to numerics\nrecoveryData <- df %>%\n  select(starts_with(\"q0009\")) %>%\n  mutate(across(everything(), ~ car::recode(.x, \"'Aldrig'=0;\n                                            'Sällan' =1;\n                                            'Ibland'=2;\n                                            'Ganska ofta'=3;\n                                            'Mycket ofta'=4;\n                                            'Alltid'=5\",\n    as.factor = FALSE\n  )))\nnames(recoveryData) <- recoveryItems$itemnr\n\n# adjustments based on psychometric analysis\nrecoveryData$å2 <- NULL\n```\n:::\n\n\n## Measurement properties for the two scales\n\n::: {.panel-tabset} \n### Targeting recovery\n\n::: {.cell}\n\n```{.r .cell-code}\nRItargeting(recoveryData)\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-5-1.png){width=1050}\n:::\n\n```{.r .cell-code}\nrecoveryRange <- c(-4,6)\n```\n:::\n\n\n### Targeting agency\n\n::: {.cell}\n\n```{.r .cell-code}\nRItargeting(agencyData)\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-6-1.png){width=1050}\n:::\n\n```{.r .cell-code}\nagencyRange <- c(-4,6)\n```\n:::\n\n\n### Reliability recovery\n\n::: {.cell}\n\n```{.r .cell-code}\nRItif(recoveryData)\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-7-1.png){width=1050}\n:::\n:::\n\n### Reliability agency\n\n::: {.cell}\n\n```{.r .cell-code}\nRItif(agencyData, cutoff = 2.5) +\n  geom_hline(yintercept = 2.5, \n    color = \"#e83c63\", linetype = 5, linewidth = 0.5)\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-8-1.png){width=1050}\n:::\n:::\n\n:::\n\n## Estimating person score/locations\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf$agencyScore <- RIestThetas(agencyData, theta_range = agencyRange)\ndf$agencyScore <- round(df$agencyScore,3)\n\ndf$recoveryScore <- RIestThetas(recoveryData, theta_range = recoveryRange)\ndf$recoveryScore <- round(df$recoveryScore,3)\n```\n:::\n\n\n### Plot relationship ordinal/interval\n\n\n::: {.cell}\n\n```{.r .cell-code}\nRIscoreSE(recoveryData, sdx = 15, score_range = recoveryRange, output = \"figure\")\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-10-1.png){width=1050}\n:::\n\n```{.r .cell-code}\n#RIscoreSE(recoveryData, sdx = 15, score_range = recoveryRange)\nRIscoreSE(agencyData, sdx = 10, score_range = agencyRange, output = \"figure\")\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-10-2.png){width=1050}\n:::\n\n```{.r .cell-code}\n#RIscoreSE(agencyData, sdx = 10, score_range = agencyRange, output = \"table\")\n```\n:::\n\n\n### Estimating measurement uncertainties (SEM)\n\n::: {.cell}\n\n```{.r .cell-code}\nrecoveryTable <- RIscoreSE(recoveryData, sdx = 15, width = 50, score_range = recoveryRange, output = \"dataframe\") \nrecoveryTable <- recoveryTable %>% \n  rename(recoverySEM = `Logit std.error`,\n         recoveryScore = `Logit score`,\n         recoverySumScore = `Ordinal sum score`) %>% \n  mutate(recoveryScore = round(recoveryScore,3))\n\nagencyTable <- RIscoreSE(agencyData, width = 50, sdx = 10, score_range = agencyRange, output = \"dataframe\")\nagencyTable <- agencyTable %>% \n  rename(agencySEM = `Logit std.error`,\n         agencyScore = `Logit score`,\n         agencySumScore = `Ordinal sum score`) %>% \n  mutate(agencyScore = round(agencyScore,3))\n```\n:::\n\n\nJoin SEM values to df based on scores\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data.frame(\n  agencyScore = df$agencyScore,\n  recoveryScore = df$recoveryScore\n)\n\ndata <- left_join(data,recoveryTable, by = \"recoveryScore\")\ndata <- left_join(data,agencyTable, by = \"agencyScore\")\n\nglimpse(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 447\nColumns: 6\n$ agencyScore      <dbl> 2.128, 0.484, 2.128, 3.423, 1.622, 2.732, 0.484, 1.62…\n$ recoveryScore    <dbl> -0.592, 0.858, 2.598, 1.919, 1.627, 3.002, 1.919, 1.6…\n$ recoverySumScore <dbl> NA, 10, 16, 14, 13, 17, 14, 13, 13, 10, 14, 20, 10, 4…\n$ recoverySEM      <dbl> NA, 0.511, 0.623, 0.558, 0.536, 0.675, 0.558, 0.536, …\n$ agencySumScore   <dbl> 12, 8, 12, 14, 11, 13, 8, 11, 11, 12, 10, 16, 8, 10, …\n$ agencySEM        <dbl> 0.737, 0.582, 0.737, 0.885, 0.680, 0.803, 0.582, 0.68…\n```\n:::\n:::\n\n\nWe have some respondents with unexpected responses and thetas outside what we have generic SEM info about. It is possible to estimate individual SEM but this has not yet been implemented in the RISEkbmRasch package and for this exercise it'll be sufficient to use those with responses that fully adhere to the expected Rasch model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- na.omit(data)\n```\n:::\n\n\n## Visualizing data {#sec-viz}\n\n### Histograms\n\n::: panel-tabset\n#### Interval score\n\n::: {.cell}\n\n```{.r .cell-code}\ndata %>% \n  pivot_longer(cols = c(\"agencyScore\",\"recoveryScore\")) %>%\n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 20) +\n  facet_wrap(~name) +\n  theme_rise()\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-14-1.png){width=1050}\n:::\n:::\n\n#### Ordinal sum score\n\n::: {.cell}\n\n```{.r .cell-code}\ndata %>% \n  pivot_longer(cols = c(\"agencySumScore\",\"recoverySumScore\")) %>%\n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 20) +\n  facet_wrap(~name) +\n  theme_rise()\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-15-1.png){width=1050}\n:::\n:::\n\n:::\n\n### Measurement uncertainty\n\n::: panel-tabset\n#### Agency\n\n::: {.cell}\n\n```{.r .cell-code}\ndata %>% \n\n  ggplot(aes(y = agencySEM, \n             x = agencyScore)) +\n  geom_point() +\n  geom_line(aes(group = 1)) +\n  geom_hline(yintercept = 0.54, linetype = 2) +\n  theme_rise() +\n  coord_cartesian(ylim = c(0,2)) +\n  labs(caption = str_wrap(\"Note. Lower SEM = improved reliability. A SEM at 0.54 (dashed line) corresponds to a reliability coefficient of 0.7 on a 0 to 1 scale. SEM = 0.45 corresponds to reliability 0.8\"))\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-16-1.png){width=1050}\n:::\n:::\n\n\n#### Recovery\n\n::: {.cell}\n\n```{.r .cell-code}\ndata %>% \n\n  ggplot(aes(y = recoverySEM, \n             x = recoveryScore)) +\n  geom_point() +\n  geom_line(aes(group = 1)) +\n  geom_hline(yintercept = 0.54, linetype = 2) +\n  theme_rise() +\n  coord_cartesian(ylim = c(0,2)) +\n  labs(caption = str_wrap(\"Note. Lower SEM = improved reliability. A SEM at 0.54 (dashed line) corresponds to a reliability coefficient of 0.7 on a 0 to 1 scale. SEM = 0.45 corresponds to reliability 0.8\"))\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-17-1.png){width=1050}\n:::\n:::\n\n:::\n\n### Scatter plots\n\n::: panel-tabset\n#### Interval score \n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data,\n       aes(x = agencyScore,\n           y = recoveryScore)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_rise()\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-18-1.png){width=1050}\n:::\n:::\n\n#### Ordinal sum score \n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data,\n       aes(x = agencySumScore,\n           y = recoveryScore)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_rise()\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-19-1.png){width=1050}\n:::\n:::\n\n:::\n\n## Relationship ordinal/interval score\n\n::: panel-tabset\n### Correlation\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(cor_test(data = data, x = \"agencySumScore\", y = \"agencyScore\"))\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-20-1.png){width=1050}\n:::\n:::\n\n\n### Correlation standardized\n\n::: {.cell}\n\n```{.r .cell-code}\ndata %>% \n  mutate(agencySumScore = standardize(agencySumScore),\n         agencyScore = standardize(agencyScore)) %>% \n  cor_test(data = ., x = \"agencySumScore\", y = \"agencyScore\") %>% \n  plot()\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-21-1.png){width=1050}\n:::\n:::\n\n\n### Ord/int OLS quintiles w sim data\n\n::: {.cell}\n\n```{.r .cell-code}\nRIscoreSE(agencyData, sdx = 10, score_range = agencyRange, output = \"dataframe\") %>% \n  ggplot(aes(x = `Logit score`,\n             y = `Ordinal sum score`)) +\n  geom_point() +\n  geom_quantile(quantiles = c(0.2,0.4,0.6,0.8),\n                method = \"rq\")\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-22-1.png){width=1050}\n:::\n\n```{.r .cell-code}\nRIscoreSE(agencyData, sdx = 10, score_range = agencyRange, output = \"dataframe\") %>% \n  janitor::clean_names() %>% \n  rq(ordinal_sum_score ~ logit_score, \n     tau = c(0.2,0.4,0.6,0.8),\n     data = .) %>% \n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall: rq(formula = ordinal_sum_score ~ logit_score, tau = c(0.2, 0.4, \n    0.6, 0.8), data = .)\n\ntau: [1] 0.2\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 5.50305      5.02492  5.86042 \nlogit_score 2.03114      1.89836  2.34038 \n\nCall: rq(formula = ordinal_sum_score ~ logit_score, tau = c(0.2, 0.4, \n    0.6, 0.8), data = .)\n\ntau: [1] 0.4\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 6.11011      5.62335  6.99763 \nlogit_score 2.30496      1.73799  2.62284 \n\nCall: rq(formula = ordinal_sum_score ~ logit_score, tau = c(0.2, 0.4, \n    0.6, 0.8), data = .)\n\ntau: [1] 0.6\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 6.92349      6.16612  7.39662 \nlogit_score 2.22420      1.91853  2.80089 \n\nCall: rq(formula = ordinal_sum_score ~ logit_score, tau = c(0.2, 0.4, \n    0.6, 0.8), data = .)\n\ntau: [1] 0.8\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 7.52022      6.60879  9.56380 \nlogit_score 2.07340      1.62513  2.62931 \n```\n:::\n:::\n\n:::\n\n## Standardizing predictor\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata2 <- data %>% \n  mutate(agencySumScore = standardize(agencySumScore),\n         agencyScore = standardize(agencyScore))\n```\n:::\n\n\n\n## Weights for WLS regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata %>% \n  mutate(weights = 1/agencySEM) %>% \n  ggplot(aes(x = agencySEM, \n             y = weights)) +\n  geom_point(size = 2) +\n  theme_rise() +\n  coord_cartesian(ylim = c(0,2))\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-24-1.png){width=1050}\n:::\n\n```{.r .cell-code}\ndata %>% \n  mutate(weights = 1/agencySEM) %>% \n  select(weights,agencySEM) %>% \n  unique() %>% \n  arrange(agencySEM) %>% \n  head(20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     weights agencySEM\n1  1.7699115     0.565\n2  1.7605634     0.568\n3  1.7421603     0.574\n4  1.7182131     0.582\n5  1.6694491     0.599\n6  1.6556291     0.604\n7  1.5723270     0.636\n8  1.5408320     0.649\n9  1.4705882     0.680\n10 1.3568521     0.737\n11 1.3422819     0.745\n12 1.2453300     0.803\n13 1.1299435     0.885\n14 1.0504202     0.952\n15 0.9560229     1.046\n16 0.6045949     1.654\n```\n:::\n:::\n\n  \n## Linear regression models {#sec-lmm}\n\n::: panel-tabset\n### OLS interval score\n\n::: {.cell}\n\n```{.r .cell-code}\nolsInt <- lm(recoveryScore ~ agencyScore, data = data)\nsummary(olsInt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = recoveryScore ~ agencyScore, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.3997 -0.8229  0.0283  0.7144  4.1132 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.30254    0.08407   3.599 0.000357 ***\nagencyScore  0.57475    0.03545  16.212  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.152 on 433 degrees of freedom\nMultiple R-squared:  0.3777,\tAdjusted R-squared:  0.3763 \nF-statistic: 262.8 on 1 and 433 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nbptest(olsInt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tstudentized Breusch-Pagan test\n\ndata:  olsInt\nBP = 2.1311, df = 1, p-value = 0.1443\n```\n:::\n\n```{.r .cell-code}\ndwtest(olsInt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tDurbin-Watson test\n\ndata:  olsInt\nDW = 1.945, p-value = 0.2824\nalternative hypothesis: true autocorrelation is greater than 0\n```\n:::\n\n```{.r .cell-code}\ncheck_model(olsInt)\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-25-1.png){width=1050}\n:::\n:::\n\n\n### WLS interval score \n\n::: {.cell}\n\n```{.r .cell-code}\nwlsInt <- lm(recoveryScore ~ agencyScore, \n         data = data,\n         weights = 1/data$agencySEM)\nsummary(wlsInt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = recoveryScore ~ agencyScore, data = data, weights = 1/data$agencySEM)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-5.8273 -0.8885  0.0199  0.8090  4.9726 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.29223    0.08019   3.644 0.000301 ***\nagencyScore  0.58893    0.03985  14.778  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.346 on 433 degrees of freedom\nMultiple R-squared:  0.3353,\tAdjusted R-squared:  0.3337 \nF-statistic: 218.4 on 1 and 433 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\ncheck_model(wlsInt)\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-26-1.png){width=1050}\n:::\n:::\n\n\n### OLS ordinal score\n\n::: {.cell}\n\n```{.r .cell-code}\nolsOrd <- lm(recoveryScore ~ agencySumScore, data = data)\nsummary(olsOrd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = recoveryScore ~ agencySumScore, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.2632 -0.7899 -0.0307  0.6911  3.9214 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    -1.77279    0.19929  -8.895   <2e-16 ***\nagencySumScore  0.29085    0.01795  16.205   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.152 on 433 degrees of freedom\nMultiple R-squared:  0.3775,\tAdjusted R-squared:  0.3761 \nF-statistic: 262.6 on 1 and 433 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\ncheck_model(olsOrd)\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-27-1.png){width=1050}\n:::\n:::\n\n### OLS int score std\n\n::: {.cell}\n\n```{.r .cell-code}\nolsIntStd <- lm(recoveryScore ~ standardize(agencyScore), data = data)\nsummary(olsIntStd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = recoveryScore ~ standardize(agencyScore), data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.3997 -0.8229  0.0283  0.7144  4.1132 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)               1.33032    0.05522   24.09   <2e-16 ***\nstandardize(agencyScore)  0.89619    0.05528   16.21   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.152 on 433 degrees of freedom\nMultiple R-squared:  0.3777,\tAdjusted R-squared:  0.3763 \nF-statistic: 262.8 on 1 and 433 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n### OLS ord score std\n\n::: {.cell}\n\n```{.r .cell-code}\nolsOrdStd <- lm(recoveryScore ~ standardize(agencySumScore), data = data)\nsummary(olsOrdStd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = recoveryScore ~ standardize(agencySumScore), data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.2632 -0.7899 -0.0307  0.6911  3.9214 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  1.33032    0.05522   24.09   <2e-16 ***\nstandardize(agencySumScore)  0.89596    0.05529   16.20   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.152 on 433 degrees of freedom\nMultiple R-squared:  0.3775,\tAdjusted R-squared:  0.3761 \nF-statistic: 262.6 on 1 and 433 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n### WLS int score std\n\n::: {.cell}\n\n```{.r .cell-code}\nwlsIntStd <- lm(recoveryScore ~ standardize(agencyScore), \n         data = data,\n         weights = 1/data$agencySEM)\nsummary(wlsIntStd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = recoveryScore ~ standardize(agencyScore), data = data, \n    weights = 1/data$agencySEM)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-5.8273 -0.8885  0.0199  0.8090  4.9726 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)               1.34536    0.05559   24.20   <2e-16 ***\nstandardize(agencyScore)  0.91829    0.06214   14.78   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.346 on 433 degrees of freedom\nMultiple R-squared:  0.3353,\tAdjusted R-squared:  0.3337 \nF-statistic: 218.4 on 1 and 433 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n### Comparison std\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\nmodels <- c(\"OLSinterval\",\"WLSinterval\",\"OLSordinal\")\n\nrbind(tidy(olsIntStd, conf.int = TRUE),\n      tidy(wlsIntStd, conf.int = TRUE),\n      tidy(olsOrdStd, conf.int = TRUE)) %>% \n  add_column(model = rep(models, each = 2), .before = \"term\") %>% \n  mutate(across(where(is.numeric), ~ round(.x, 3))) %>% \n  arrange(term) %>% \n  kbl_rise()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"width:65%; font-size: 14px;  font-family: Arial; margin-left: auto; margin-right: auto;\" class=\"table table-striped table-hover lightable-classic\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> model </th>\n   <th style=\"text-align:left;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> term </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> estimate </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> std.error </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> statistic </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> p.value </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> conf.low </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> conf.high </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> OLSinterval </td>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 1.330 </td>\n   <td style=\"text-align:right;\"> 0.055 </td>\n   <td style=\"text-align:right;\"> 24.093 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1.222 </td>\n   <td style=\"text-align:right;\"> 1.439 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> WLSinterval </td>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 1.345 </td>\n   <td style=\"text-align:right;\"> 0.056 </td>\n   <td style=\"text-align:right;\"> 24.202 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1.236 </td>\n   <td style=\"text-align:right;\"> 1.455 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> OLSordinal </td>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 1.330 </td>\n   <td style=\"text-align:right;\"> 0.055 </td>\n   <td style=\"text-align:right;\"> 24.089 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1.222 </td>\n   <td style=\"text-align:right;\"> 1.439 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> OLSinterval </td>\n   <td style=\"text-align:left;\"> standardize(agencyScore) </td>\n   <td style=\"text-align:right;\"> 0.896 </td>\n   <td style=\"text-align:right;\"> 0.055 </td>\n   <td style=\"text-align:right;\"> 16.212 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.788 </td>\n   <td style=\"text-align:right;\"> 1.005 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> WLSinterval </td>\n   <td style=\"text-align:left;\"> standardize(agencyScore) </td>\n   <td style=\"text-align:right;\"> 0.918 </td>\n   <td style=\"text-align:right;\"> 0.062 </td>\n   <td style=\"text-align:right;\"> 14.778 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.796 </td>\n   <td style=\"text-align:right;\"> 1.040 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> OLSordinal </td>\n   <td style=\"text-align:left;\"> standardize(agencySumScore) </td>\n   <td style=\"text-align:right;\"> 0.896 </td>\n   <td style=\"text-align:right;\"> 0.055 </td>\n   <td style=\"text-align:right;\"> 16.205 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.787 </td>\n   <td style=\"text-align:right;\"> 1.005 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\nrbind(glance(olsIntStd),\n      glance(wlsIntStd),\n      glance(olsOrdStd)) %>% \n  add_column(model = rep(models, each = 1), .before = \"r.squared\") %>% \n  mutate(across(where(is.numeric), ~ round(.x, 3))) %>% \n  kbl_rise()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"width:65%; font-size: 14px;  font-family: Arial; margin-left: auto; margin-right: auto;\" class=\"table table-striped table-hover lightable-classic\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> model </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> r.squared </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> adj.r.squared </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> sigma </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> statistic </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> p.value </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> df </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> logLik </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> AIC </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> BIC </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> deviance </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> df.residual </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> nobs </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> OLSinterval </td>\n   <td style=\"text-align:right;\"> 0.378 </td>\n   <td style=\"text-align:right;\"> 0.376 </td>\n   <td style=\"text-align:right;\"> 1.152 </td>\n   <td style=\"text-align:right;\"> 262.822 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> -677.649 </td>\n   <td style=\"text-align:right;\"> 1361.298 </td>\n   <td style=\"text-align:right;\"> 1373.524 </td>\n   <td style=\"text-align:right;\"> 574.268 </td>\n   <td style=\"text-align:right;\"> 433 </td>\n   <td style=\"text-align:right;\"> 435 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> WLSinterval </td>\n   <td style=\"text-align:right;\"> 0.335 </td>\n   <td style=\"text-align:right;\"> 0.334 </td>\n   <td style=\"text-align:right;\"> 1.346 </td>\n   <td style=\"text-align:right;\"> 218.385 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> -676.201 </td>\n   <td style=\"text-align:right;\"> 1358.403 </td>\n   <td style=\"text-align:right;\"> 1370.629 </td>\n   <td style=\"text-align:right;\"> 785.009 </td>\n   <td style=\"text-align:right;\"> 433 </td>\n   <td style=\"text-align:right;\"> 435 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> OLSordinal </td>\n   <td style=\"text-align:right;\"> 0.378 </td>\n   <td style=\"text-align:right;\"> 0.376 </td>\n   <td style=\"text-align:right;\"> 1.152 </td>\n   <td style=\"text-align:right;\"> 262.611 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> -677.715 </td>\n   <td style=\"text-align:right;\"> 1361.430 </td>\n   <td style=\"text-align:right;\"> 1373.656 </td>\n   <td style=\"text-align:right;\"> 574.443 </td>\n   <td style=\"text-align:right;\"> 433 </td>\n   <td style=\"text-align:right;\"> 435 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n### Comparison unstd\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\nmodels <- c(\"OLSinterval\",\"WLSinterval\",\"OLSordinal\")\n\nrbind(tidy(olsInt, conf.int = TRUE),\n      tidy(wlsInt, conf.int = TRUE),\n      tidy(olsOrd, conf.int = TRUE)) %>% \n  add_column(model = rep(models, each = 2), .before = \"term\") %>% \n  mutate(across(where(is.numeric), ~ round(.x, 3))) %>% \n  arrange(term) %>% \n  kbl_rise()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"width:65%; font-size: 14px;  font-family: Arial; margin-left: auto; margin-right: auto;\" class=\"table table-striped table-hover lightable-classic\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> model </th>\n   <th style=\"text-align:left;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> term </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> estimate </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> std.error </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> statistic </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> p.value </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> conf.low </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> conf.high </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> OLSinterval </td>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 0.303 </td>\n   <td style=\"text-align:right;\"> 0.084 </td>\n   <td style=\"text-align:right;\"> 3.599 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.137 </td>\n   <td style=\"text-align:right;\"> 0.468 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> WLSinterval </td>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 0.292 </td>\n   <td style=\"text-align:right;\"> 0.080 </td>\n   <td style=\"text-align:right;\"> 3.644 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.135 </td>\n   <td style=\"text-align:right;\"> 0.450 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> OLSordinal </td>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> -1.773 </td>\n   <td style=\"text-align:right;\"> 0.199 </td>\n   <td style=\"text-align:right;\"> -8.895 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> -2.164 </td>\n   <td style=\"text-align:right;\"> -1.381 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> OLSinterval </td>\n   <td style=\"text-align:left;\"> agencyScore </td>\n   <td style=\"text-align:right;\"> 0.575 </td>\n   <td style=\"text-align:right;\"> 0.035 </td>\n   <td style=\"text-align:right;\"> 16.212 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.505 </td>\n   <td style=\"text-align:right;\"> 0.644 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> WLSinterval </td>\n   <td style=\"text-align:left;\"> agencyScore </td>\n   <td style=\"text-align:right;\"> 0.589 </td>\n   <td style=\"text-align:right;\"> 0.040 </td>\n   <td style=\"text-align:right;\"> 14.778 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.511 </td>\n   <td style=\"text-align:right;\"> 0.667 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> OLSordinal </td>\n   <td style=\"text-align:left;\"> agencySumScore </td>\n   <td style=\"text-align:right;\"> 0.291 </td>\n   <td style=\"text-align:right;\"> 0.018 </td>\n   <td style=\"text-align:right;\"> 16.205 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.256 </td>\n   <td style=\"text-align:right;\"> 0.326 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\nrbind(glance(olsInt),\n      glance(wlsInt),\n      glance(olsOrd)) %>% \n  add_column(model = rep(models, each = 1), .before = \"r.squared\") %>% \n  mutate(across(where(is.numeric), ~ round(.x, 3))) %>% \n  kbl_rise()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"width:65%; font-size: 14px;  font-family: Arial; margin-left: auto; margin-right: auto;\" class=\"table table-striped table-hover lightable-classic\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> model </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> r.squared </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> adj.r.squared </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> sigma </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> statistic </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> p.value </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> df </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> logLik </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> AIC </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> BIC </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> deviance </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> df.residual </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;\"> nobs </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> OLSinterval </td>\n   <td style=\"text-align:right;\"> 0.378 </td>\n   <td style=\"text-align:right;\"> 0.376 </td>\n   <td style=\"text-align:right;\"> 1.152 </td>\n   <td style=\"text-align:right;\"> 262.822 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> -677.649 </td>\n   <td style=\"text-align:right;\"> 1361.298 </td>\n   <td style=\"text-align:right;\"> 1373.524 </td>\n   <td style=\"text-align:right;\"> 574.268 </td>\n   <td style=\"text-align:right;\"> 433 </td>\n   <td style=\"text-align:right;\"> 435 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> WLSinterval </td>\n   <td style=\"text-align:right;\"> 0.335 </td>\n   <td style=\"text-align:right;\"> 0.334 </td>\n   <td style=\"text-align:right;\"> 1.346 </td>\n   <td style=\"text-align:right;\"> 218.385 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> -676.201 </td>\n   <td style=\"text-align:right;\"> 1358.403 </td>\n   <td style=\"text-align:right;\"> 1370.629 </td>\n   <td style=\"text-align:right;\"> 785.009 </td>\n   <td style=\"text-align:right;\"> 433 </td>\n   <td style=\"text-align:right;\"> 435 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> OLSordinal </td>\n   <td style=\"text-align:right;\"> 0.378 </td>\n   <td style=\"text-align:right;\"> 0.376 </td>\n   <td style=\"text-align:right;\"> 1.152 </td>\n   <td style=\"text-align:right;\"> 262.611 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> -677.715 </td>\n   <td style=\"text-align:right;\"> 1361.430 </td>\n   <td style=\"text-align:right;\"> 1373.656 </td>\n   <td style=\"text-align:right;\"> 574.443 </td>\n   <td style=\"text-align:right;\"> 433 </td>\n   <td style=\"text-align:right;\"> 435 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n:::\n\n### Quantile regression scatter plots\n\nI haven't figured out how to make ggplot use weighted model, so these are only unweighted.\n\n::: panel-tabset\n#### Interval OLS quartiles\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data,\n       aes(x = agencyScore, y = recoveryScore)) +\n  geom_point() +\n  geom_quantile(quantiles = c(0.25,0.5,0.75),\n                method = \"rq\")\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-33-1.png){width=1050}\n:::\n:::\n\n#### Ordinal OLS quartiles\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data,\n       aes(x = agencySumScore, y = recoveryScore)) +\n  geom_point() +\n  geom_quantile(quantiles = c(0.25,0.5,0.75),\n                method = \"rq\")\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-34-1.png){width=1050}\n:::\n:::\n\n#### Interval OLS quintiles\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data,\n       aes(x = agencyScore, y = recoveryScore)) +\n  geom_point() +\n  geom_quantile(quantiles = c(0.2,0.4,0.6,0.8),\n                method = \"rq\")\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-35-1.png){width=1050}\n:::\n:::\n\n#### Ordinal OLS quintiles\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data,\n       aes(x = agencySumScore, y = recoveryScore)) +\n  geom_point() +\n  geom_quantile(quantiles = c(0.2,0.4,0.6,0.8),\n                method = \"rq\")\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-36-1.png){width=1050}\n:::\n:::\n\n#### Ordinal/interval OLS quintiles\n\n::: {.cell}\n\n```{.r .cell-code}\npointSize <- data %>% \n  count(agencyScore)\n\ndata %>% \n  left_join(.,pointSize, by = \"agencyScore\") %>% \n  ggplot(aes(x = agencyScore, y = agencySumScore)) +\n  geom_point(aes(size = n)) +\n  geom_quantile(quantiles = c(0.2,0.4,0.6,0.8),\n                method = \"rq\")\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-37-1.png){width=1050}\n:::\n\n```{.r .cell-code}\n                #color = c(\"blue\",\"red\",\"orange\",\"pink\")) # add coloring to lines\n                #linetype = c(\"dotted\", \"dashed\", \"solid\", \"dashed\"))\n```\n:::\n\n:::\n\n## Quantile regression\n\nWe can use any set of quantiles using the `tau` option. Here, we choose 0.25, 0.5, and 0.75. Tau = 0.5 is the same as \"median regression\".\n\n### Visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndviz <- data %>%\n  add_column(id = seq(1, nrow(data), by = 1)) %>% \n  pivot_longer(c(\"agencyScore\",\"recoveryScore\")) %>% \n  group_by(name) %>%\n  mutate(qgroup = case_when(value < quantile(value, probs = .25) ~ \"lower\",\n                            value >= quantile(value, probs = .25) & value < quantile(value, probs = .75) ~ \"middle\",\n                            value >= quantile(value, probs = .75) ~ \"upper\")) %>% \n  ungroup() %>% \n  pivot_wider(id_cols = \"id\", \n              names_from = \"name\", \n              values_from = c(\"value\",\"qgroup\"))\n\ndviz %>%\n  ggplot(aes(\n    x = value_agencyScore,\n    y = value_recoveryScore,\n    color = qgroup_recoveryScore\n  )) +\n  geom_point() +\n  theme_rise() +\n  scale_color_brewer(type = \"qual\", palette = \"Dark2\") +\n  theme(legend.position = \"none\") +\n  labs(x = \"Agency Score\",\n       y = \"Recovery Score\")\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-38-1.png){width=1050}\n:::\n:::\n\n\n### Quantile regression scatter plots\n\nI haven't figured out how to make ggplot use weighted model (WLS), so these are only unweighted.\n\n::: panel-tabset\n#### Interval OLS quartiles\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data,\n       aes(x = agencyScore, y = recoveryScore)) +\n  geom_point() +\n  geom_quantile(quantiles = c(0.25,0.5,0.75),\n                method = \"rq\")\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-39-1.png){width=1050}\n:::\n:::\n\n#### Ordinal OLS quartiles\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data,\n       aes(x = agencySumScore, y = recoveryScore)) +\n  geom_point() +\n  geom_quantile(quantiles = c(0.25,0.5,0.75),\n                method = \"rq\")\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-40-1.png){width=1050}\n:::\n:::\n\n#### Interval OLS quintiles\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data,\n       aes(x = agencyScore, y = recoveryScore)) +\n  geom_point() +\n  geom_quantile(quantiles = c(0.2,0.4,0.6,0.8),\n                method = \"rq\")\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-41-1.png){width=1050}\n:::\n:::\n\n#### Ordinal OLS quintiles\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data,\n       aes(x = agencySumScore, y = recoveryScore)) +\n  geom_point() +\n  geom_quantile(quantiles = c(0.2,0.4,0.6,0.8),\n                method = \"rq\")\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-42-1.png){width=1050}\n:::\n:::\n\n#### Ordinal/interval OLS quintiles\n\n::: {.cell}\n\n```{.r .cell-code}\npointSize <- data %>% \n  count(agencyScore)\n\ndata %>% \n  left_join(.,pointSize, by = \"agencyScore\") %>% \n  ggplot(aes(x = agencyScore, y = agencySumScore)) +\n  geom_point(aes(size = n)) +\n  geom_quantile(quantiles = c(0.2,0.4,0.6,0.8),\n                method = \"rq\")\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-43-1.png){width=1050}\n:::\n\n```{.r .cell-code}\n                #color = c(\"blue\",\"red\",\"orange\",\"pink\")) # add coloring to lines\n                #linetype = c(\"dotted\", \"dashed\", \"solid\", \"dashed\"))\n```\n:::\n\n:::\n\n### Quartiles\n\n::: panel-tabset\n#### Interval \n\n::: {.cell}\n\n```{.r .cell-code}\nolsIntQ <- rq(recoveryScore ~ agencyScore, \n              tau = c(0.25,0.5,0.75),\n              data = data2)\nsummary(olsIntQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall: rq(formula = recoveryScore ~ agencyScore, tau = c(0.25, 0.5, \n    0.75), data = data2)\n\ntau: [1] 0.25\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 0.54852      0.40162  0.69930 \nagencyScore 0.77303      0.61108  0.85989 \n\nCall: rq(formula = recoveryScore ~ agencyScore, tau = c(0.25, 0.5, \n    0.75), data = data2)\n\ntau: [1] 0.5\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 1.39128      1.13848  1.48046 \nagencyScore 0.76494      0.55469  0.95523 \n\nCall: rq(formula = recoveryScore ~ agencyScore, tau = c(0.25, 0.5, \n    0.75), data = data2)\n\ntau: [1] 0.75\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 2.02444      1.99369  2.34137 \nagencyScore 0.98917      0.47491  1.26604 \n```\n:::\n:::\n\n\n#### Interval weighted\n\n::: {.cell}\n\n```{.r .cell-code}\nwlsIntQ <- rq(recoveryScore ~ agencyScore, \n              tau = c(0.25,0.5,0.75),\n              data = data2,\n              weights = 1/data$agencySEM)\nsummary(wlsIntQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall: rq(formula = recoveryScore ~ agencyScore, tau = c(0.25, 0.5, \n    0.75), data = data2, weights = 1/data$agencySEM)\n\ntau: [1] 0.25\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 0.60364      0.27785  0.78794 \nagencyScore 0.81241      0.65763  0.96267 \n\nCall: rq(formula = recoveryScore ~ agencyScore, tau = c(0.25, 0.5, \n    0.75), data = data2, weights = 1/data$agencySEM)\n\ntau: [1] 0.5\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 1.40682      1.02961  1.46561 \nagencyScore 0.79468      0.59389  1.04917 \n\nCall: rq(formula = recoveryScore ~ agencyScore, tau = c(0.25, 0.5, \n    0.75), data = data2, weights = 1/data$agencySEM)\n\ntau: [1] 0.75\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 2.03860      1.97684  2.30859 \nagencyScore 0.92420      0.63342  1.19706 \n```\n:::\n:::\n\n\n#### Ordinal\n\n::: {.cell}\n\n```{.r .cell-code}\nolsOrdQ <- rq(recoveryScore ~ agencySumScore, \n              tau = c(0.25,0.5,0.75),\n              data = data2)\nsummary(olsOrdQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall: rq(formula = recoveryScore ~ agencySumScore, tau = c(0.25, 0.5, \n    0.75), data = data2)\n\ntau: [1] 0.25\n\nCoefficients:\n               coefficients lower bd upper bd\n(Intercept)    0.51085      0.31790  0.88835 \nagencySumScore 0.81368      0.61073  1.03613 \n\nCall: rq(formula = recoveryScore ~ agencySumScore, tau = c(0.25, 0.5, \n    0.75), data = data2)\n\ntau: [1] 0.5\n\nCoefficients:\n               coefficients lower bd upper bd\n(Intercept)    1.27624      1.03008  1.37530 \nagencySumScore 0.77012      0.56493  0.87982 \n\nCall: rq(formula = recoveryScore ~ agencySumScore, tau = c(0.25, 0.5, \n    0.75), data = data2)\n\ntau: [1] 0.75\n\nCoefficients:\n               coefficients lower bd upper bd\n(Intercept)    2.06409      1.80116  2.17954 \nagencySumScore 0.81874      0.68975  0.99604 \n```\n:::\n:::\n\n:::\n\n### Quartile parameter plots\n\n::: panel-tabset\n#### Interval OLS\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(parameters(olsIntQ)) +\n  geom_vline(xintercept = 0.75, linetype = 2) +\n  geom_vline(xintercept = 1, linetype = 2) +\n  labs(title = \"OLS quantile regression with interval predictor\",\n       caption = \"Note. Dashed lines indicate 0.75 and 1.0.\") +\n  coord_cartesian(xlim = c(0,1.2))\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-47-1.png){width=1050}\n:::\n:::\n\n#### Interval WLS\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(parameters(wlsIntQ)) +\n  geom_vline(xintercept = 0.75, linetype = 2) +\n  geom_vline(xintercept = 1, linetype = 2) +\n  labs(title = \"WLS quantile regression with interval predictor\",\n       caption = \"Note. Dashed lines indicate 0.75 and 1.0.\") +\n  coord_cartesian(xlim = c(0,1.2))\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-48-1.png){width=1050}\n:::\n:::\n\n#### Ordinal OLS\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(parameters(olsOrdQ)) +\n  geom_vline(xintercept = 0.75, linetype = 2) +\n  geom_vline(xintercept = 1, linetype = 2) +\n  labs(title = \"OLS quantile regression with ordinal sum score predictor\",\n        caption = \"Note. Dashed line indicates 0.25.\") +\n  coord_cartesian(xlim = c(0,1.2))\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-49-1.png){width=1050}\n:::\n:::\n\n:::\n\n\n\n\n### Quintiles\n\nWe need to generate simulated data since variation is low in this dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get item parameters for both\n# generate correlated vectors of thetas, one for each variable\n# https://cran.r-project.org/web/packages/faux/vignettes/rnorm_multi.html\n```\n:::\n\n\n\n::: panel-tabset\n#### Interval \n\n::: {.cell}\n\n```{.r .cell-code}\nolsIntQ <- rq(recoveryScore ~ agencyScore, \n              tau = c(0.2,0.4,0.6,0.8),\n              data = data2)\nsummary(olsIntQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall: rq(formula = recoveryScore ~ agencyScore, tau = c(0.2, 0.4, 0.6, \n    0.8), data = data2)\n\ntau: [1] 0.2\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept)  0.36075     -0.03012  0.44698\nagencyScore  0.76552      0.72249  1.00876\n\nCall: rq(formula = recoveryScore ~ agencyScore, tau = c(0.2, 0.4, 0.6, \n    0.8), data = data2)\n\ntau: [1] 0.4\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 0.94939      0.68695  1.18510 \nagencyScore 0.71408      0.57422  0.91513 \n\nCall: rq(formula = recoveryScore ~ agencyScore, tau = c(0.2, 0.4, 0.6, \n    0.8), data = data2)\n\ntau: [1] 0.6\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 1.66261      1.42847  1.81062 \nagencyScore 0.89217      0.46320  1.01949 \n\nCall: rq(formula = recoveryScore ~ agencyScore, tau = c(0.2, 0.4, 0.6, \n    0.8), data = data2)\n\ntau: [1] 0.8\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 2.32222      1.91357  2.37183 \nagencyScore 1.12309      0.81523  1.39159 \n```\n:::\n:::\n\n\n#### Interval weighted\n\n::: {.cell}\n\n```{.r .cell-code}\nwlsIntQ <- rq(recoveryScore ~ agencyScore, \n              tau = c(0.2,0.4,0.6,0.8),\n              data = data2,\n              weights = 1/data$agencySEM)\nsummary(wlsIntQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall: rq(formula = recoveryScore ~ agencyScore, tau = c(0.2, 0.4, 0.6, \n    0.8), data = data2, weights = 1/data$agencySEM)\n\ntau: [1] 0.2\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 0.40871      0.19600  0.48283 \nagencyScore 0.89181      0.71959  0.98957 \n\nCall: rq(formula = recoveryScore ~ agencyScore, tau = c(0.2, 0.4, 0.6, \n    0.8), data = data2, weights = 1/data$agencySEM)\n\ntau: [1] 0.4\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 1.02134      0.89817  1.24002 \nagencyScore 0.77251      0.62179  0.91729 \n\nCall: rq(formula = recoveryScore ~ agencyScore, tau = c(0.2, 0.4, 0.6, \n    0.8), data = data2, weights = 1/data$agencySEM)\n\ntau: [1] 0.6\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 1.69172      1.39643  1.83068 \nagencyScore 0.90582      0.66346  1.10394 \n\nCall: rq(formula = recoveryScore ~ agencyScore, tau = c(0.2, 0.4, 0.6, \n    0.8), data = data2, weights = 1/data$agencySEM)\n\ntau: [1] 0.8\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 2.32222      1.92972  2.38242 \nagencyScore 1.12309      0.78752  1.21183 \n```\n:::\n:::\n\n\n#### Ordinal\n\n::: {.cell}\n\n```{.r .cell-code}\nolsOrdQ <- rq(recoveryScore ~ agencySumScore, \n              tau = c(0.2,0.4,0.6,0.8),\n              data = data2)\nsummary(olsOrdQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall: rq(formula = recoveryScore ~ agencySumScore, tau = c(0.2, 0.4, \n    0.6, 0.8), data = data2)\n\ntau: [1] 0.2\n\nCoefficients:\n               coefficients lower bd upper bd\n(Intercept)    0.36282      0.19479  0.51771 \nagencySumScore 0.89915      0.64148  1.02005 \n\nCall: rq(formula = recoveryScore ~ agencySumScore, tau = c(0.2, 0.4, \n    0.6, 0.8), data = data2)\n\ntau: [1] 0.4\n\nCoefficients:\n               coefficients lower bd upper bd\n(Intercept)    1.03165      0.67163  1.22585 \nagencySumScore 0.78675      0.65692  0.92257 \n\nCall: rq(formula = recoveryScore ~ agencySumScore, tau = c(0.2, 0.4, \n    0.6, 0.8), data = data2)\n\ntau: [1] 0.6\n\nCoefficients:\n               coefficients lower bd upper bd\n(Intercept)    1.56594      1.51345  1.68881 \nagencySumScore 0.81709      0.54335  0.94448 \n\nCall: rq(formula = recoveryScore ~ agencySumScore, tau = c(0.2, 0.4, \n    0.6, 0.8), data = data2)\n\ntau: [1] 0.8\n\nCoefficients:\n               coefficients lower bd upper bd\n(Intercept)    2.20055      2.08845  2.44756 \nagencySumScore 0.91983      0.73242  1.05846 \n```\n:::\n:::\n\n:::\n\n### Quintile parameter plots\n\n::: panel-tabset\n#### Interval OLS\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(parameters(olsIntQ)) +\n  geom_vline(xintercept = 0.75, linetype = 2) +\n  geom_vline(xintercept = 1, linetype = 2) +\n  labs(title = \"OLS quantile regression with interval predictor\",\n       caption = \"Note. Dashed lines indicate 0.75 and 1.0.\") +\n  coord_cartesian(xlim = c(0,1.2))\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-54-1.png){width=1050}\n:::\n:::\n\n#### Interval WLS\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(parameters(wlsIntQ)) +\n  geom_vline(xintercept = 0.75, linetype = 2) +\n  geom_vline(xintercept = 1, linetype = 2) +\n  labs(title = \"WLS quantile regression with interval predictor\",\n       caption = \"Note. Dashed lines indicate 0.75 and 1.0.\") +\n  coord_cartesian(xlim = c(0,1.2))\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-55-1.png){width=1050}\n:::\n:::\n\n#### Ordinal OLS\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(parameters(olsOrdQ)) +\n  geom_vline(xintercept = 0.75, linetype = 2) +\n  geom_vline(xintercept = 1, linetype = 2) +\n  labs(title = \"OLS quantile regression with ordinal sum score predictor\",\n        caption = \"Note. Dashed line indicates 0.25.\") +\n  coord_cartesian(xlim = c(0,1.2))\n```\n\n::: {.cell-output-display}\n![](WLSregr_files/figure-html/unnamed-chunk-56-1.png){width=1050}\n:::\n:::\n\n:::\n\n\n\n\n\n\n\n\n### Plot predicted\n::: panel-tabset\n####\n\n::: {.cell}\n\n:::\n\n####\n\n::: {.cell}\n\n:::\n\n\n\n:::",
    "supporting": [
      "WLSregr_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}